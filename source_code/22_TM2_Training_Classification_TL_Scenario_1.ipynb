{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koZ3Cl2vI4yM"
   },
   "source": [
    "# **TRANSFER LEARNING - TARGET MODEL 2 - CLASSIFICATION OF CREDIT DEFAULT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVPa7aXAKMBu"
   },
   "source": [
    "# **TensorFlow Installation in GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d4nEZI1KSmt",
    "outputId": "ed8a2706-3640-40f1-d224-3010572f95e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 489.6 MB 20 kB/s \n",
      "\u001b[?25hRequirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.22.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.42.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.37.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (12.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (57.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR8cYEN_IWzm"
   },
   "source": [
    "# **1. Importing Python Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFcw1CoZIdgI",
    "outputId": "cc687195-acd4-4657-d2fe-fd5b44313c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Completed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"Import Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DukpTXKCKwx5"
   },
   "source": [
    "# **2. Importing the Target Model Train and Validation Data csv Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhWyCo6HJKPS",
    "outputId": "2b1a4f89-df69-4c12-af68-9374a5444fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Import Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing the Target Model (TM) Train - Input, Output 1 and Output 2 Data\n",
    "\n",
    "\n",
    "tm_train_X = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_train_final_input_X.csv\")\n",
    "\n",
    "tm_train_y_reg = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_train_final_output_y_reg.csv\")\n",
    "\n",
    "tm_train_y_clas = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_train_final_output_y_clas.csv\")\n",
    "\n",
    "print(\"Data Import Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77nZSw3ZMGaM",
    "outputId": "e6db60c9-463b-4f2c-ea21-439929bac83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Import Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing the Target Model (TM) Validation - Input, Output 1 and Output 2 Data\n",
    "\n",
    "\n",
    "tm_validation_X = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_validation_final_input_X.csv\")\n",
    "\n",
    "tm_validation_y_reg = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_validation_final_output_y_reg.csv\")\n",
    "\n",
    "tm_validation_y_clas = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_validation_final_output_y_clas.csv\")\n",
    "\n",
    "print(\"Data Import Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Mqyl1FiMTR4"
   },
   "source": [
    "# **3. Target Model (TM) - Train Data - Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "rRpsKW7dMbIS",
    "outputId": "e18661a8-59c6-47fe-8876-20726d2307a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419425, 75)\n",
      "(419425, 74)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_rec:0</th>\n",
       "      <th>pub_record:non_zero</th>\n",
       "      <th>delinq_2yrs:0</th>\n",
       "      <th>delinq_2yrs:1</th>\n",
       "      <th>delinq_2yrs:greater_than_1</th>\n",
       "      <th>num_tl_120dpd_2m:0</th>\n",
       "      <th>num_tl_120dpd_2m:non_zero</th>\n",
       "      <th>pub_rec_bankruptcies:0</th>\n",
       "      <th>pub_rec_bankruptcies:non_zero</th>\n",
       "      <th>num_tl_90g_dpd_24m:0</th>\n",
       "      <th>num_tl_90g_dpd_24m:non_zero</th>\n",
       "      <th>num_accts_ever_120_pd:0</th>\n",
       "      <th>num_accts_ever_120_pd:_non_zero</th>\n",
       "      <th>acc_now_delinq:0</th>\n",
       "      <th>acc_now_delinq:non_zero</th>\n",
       "      <th>num_tl_30dpd:0</th>\n",
       "      <th>num_tl_30dpd:non_zero</th>\n",
       "      <th>total_rec_late_fee:0</th>\n",
       "      <th>total_rec_late_fee:non_zero</th>\n",
       "      <th>num_rev_tl_bal_gt_0:0</th>\n",
       "      <th>num_rev_tl_bal_gt_0:1_to_5</th>\n",
       "      <th>num_rev_tl_bal_gt_0:greater_than_5</th>\n",
       "      <th>percent_bc_gt_75:0</th>\n",
       "      <th>percent_bc_gt_75:1_to_75</th>\n",
       "      <th>percent_bc_gt_75:greater_than_75</th>\n",
       "      <th>revol_util:0</th>\n",
       "      <th>revol_util:1_to_30</th>\n",
       "      <th>revol_util:31_to_60</th>\n",
       "      <th>revol_util:greater_than_60</th>\n",
       "      <th>il_util:0</th>\n",
       "      <th>il_util:1_to_90</th>\n",
       "      <th>il_util:greater_than_90</th>\n",
       "      <th>max_bal_bc:0_to_2500</th>\n",
       "      <th>max_bal_bc:2501_to_5000</th>\n",
       "      <th>max_bal_bc:5001_to_10000</th>\n",
       "      <th>max_bal_bc:greater_than_10000</th>\n",
       "      <th>mo_sin_old_rev_tl_op:less_than_24months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:25months_to_60months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:greater_than_60months</th>\n",
       "      <th>months_since_earliest_cr_line:less_than_96months</th>\n",
       "      <th>months_since_earliest_cr_line:97months_to_192months</th>\n",
       "      <th>months_since_earliest_cr_line:greater_than_192months</th>\n",
       "      <th>open_acc:less_than_5</th>\n",
       "      <th>open_acc:6_to_8</th>\n",
       "      <th>open_acc:greater_than_8</th>\n",
       "      <th>num_sats:0_to_5</th>\n",
       "      <th>num_sats:6_to_8</th>\n",
       "      <th>num_sats:greater_than_8</th>\n",
       "      <th>mort_acc:0</th>\n",
       "      <th>mort_acc:1_to_3</th>\n",
       "      <th>mort_acc:greater_than_3</th>\n",
       "      <th>inq_last_6mths:0</th>\n",
       "      <th>inq_last_6mths:1</th>\n",
       "      <th>inq_last_6mths:greater_than_1</th>\n",
       "      <th>open_il_12m:_0</th>\n",
       "      <th>open_il_12m:_1</th>\n",
       "      <th>open_il_12m:greater_than_1</th>\n",
       "      <th>num_tl_op_past_12m:0</th>\n",
       "      <th>num_tl_op_past_12m:1</th>\n",
       "      <th>num_tl_op_past_12m:2</th>\n",
       "      <th>num_tl_op_past_12m:3</th>\n",
       "      <th>num_tl_op_past_12m:greater_than_3</th>\n",
       "      <th>annual_inc:0_to_25000</th>\n",
       "      <th>annual_inc:25001_to_50000</th>\n",
       "      <th>annual_inc:50001_to_75000</th>\n",
       "      <th>annual_inc:75001_to_100000</th>\n",
       "      <th>annual_inc:greater_than_100001</th>\n",
       "      <th>dti:0_to_36</th>\n",
       "      <th>dti:greater_than_36</th>\n",
       "      <th>emp_length_int:less_than_0</th>\n",
       "      <th>emp_length_int:1_to_2</th>\n",
       "      <th>emp_length_int:3_to_5</th>\n",
       "      <th>emp_length_int:6_to_9</th>\n",
       "      <th>emp_length_int:greater_than_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pub_rec:0  pub_record:non_zero  delinq_2yrs:0  delinq_2yrs:1  \\\n",
       "0          1                    0              1              0   \n",
       "1          1                    0              1              0   \n",
       "2          1                    0              1              0   \n",
       "3          1                    0              1              0   \n",
       "4          1                    0              0              1   \n",
       "\n",
       "   delinq_2yrs:greater_than_1  num_tl_120dpd_2m:0  num_tl_120dpd_2m:non_zero  \\\n",
       "0                           0                   1                          0   \n",
       "1                           0                   1                          0   \n",
       "2                           0                   1                          0   \n",
       "3                           0                   1                          0   \n",
       "4                           0                   1                          0   \n",
       "\n",
       "   pub_rec_bankruptcies:0  pub_rec_bankruptcies:non_zero  \\\n",
       "0                       1                              0   \n",
       "1                       1                              0   \n",
       "2                       1                              0   \n",
       "3                       1                              0   \n",
       "4                       1                              0   \n",
       "\n",
       "   num_tl_90g_dpd_24m:0  num_tl_90g_dpd_24m:non_zero  num_accts_ever_120_pd:0  \\\n",
       "0                     1                            0                        1   \n",
       "1                     1                            0                        1   \n",
       "2                     1                            0                        1   \n",
       "3                     1                            0                        1   \n",
       "4                     1                            0                        1   \n",
       "\n",
       "   num_accts_ever_120_pd:_non_zero  acc_now_delinq:0  acc_now_delinq:non_zero  \\\n",
       "0                                0                 1                        0   \n",
       "1                                0                 1                        0   \n",
       "2                                0                 1                        0   \n",
       "3                                0                 1                        0   \n",
       "4                                0                 1                        0   \n",
       "\n",
       "   num_tl_30dpd:0  num_tl_30dpd:non_zero  total_rec_late_fee:0  \\\n",
       "0               1                      0                     1   \n",
       "1               1                      0                     1   \n",
       "2               1                      0                     1   \n",
       "3               1                      0                     1   \n",
       "4               1                      0                     0   \n",
       "\n",
       "   total_rec_late_fee:non_zero  num_rev_tl_bal_gt_0:0  \\\n",
       "0                            0                      0   \n",
       "1                            0                      0   \n",
       "2                            0                      0   \n",
       "3                            0                      0   \n",
       "4                            1                      0   \n",
       "\n",
       "   num_rev_tl_bal_gt_0:1_to_5  num_rev_tl_bal_gt_0:greater_than_5  \\\n",
       "0                           1                                   0   \n",
       "1                           1                                   0   \n",
       "2                           1                                   0   \n",
       "3                           1                                   0   \n",
       "4                           1                                   0   \n",
       "\n",
       "   percent_bc_gt_75:0  percent_bc_gt_75:1_to_75  \\\n",
       "0                   0                         0   \n",
       "1                   0                         1   \n",
       "2                   0                         1   \n",
       "3                   1                         0   \n",
       "4                   0                         0   \n",
       "\n",
       "   percent_bc_gt_75:greater_than_75  revol_util:0  revol_util:1_to_30  \\\n",
       "0                                 1             0                   0   \n",
       "1                                 0             0                   1   \n",
       "2                                 0             0                   0   \n",
       "3                                 0             0                   1   \n",
       "4                                 1             0                   0   \n",
       "\n",
       "   revol_util:31_to_60  revol_util:greater_than_60  il_util:0  \\\n",
       "0                    0                           1          0   \n",
       "1                    0                           0          0   \n",
       "2                    1                           0          0   \n",
       "3                    0                           0          1   \n",
       "4                    0                           1          0   \n",
       "\n",
       "   il_util:1_to_90  il_util:greater_than_90  max_bal_bc:0_to_2500  \\\n",
       "0                1                        0                     0   \n",
       "1                1                        0                     0   \n",
       "2                1                        0                     1   \n",
       "3                0                        0                     1   \n",
       "4                1                        0                     0   \n",
       "\n",
       "   max_bal_bc:2501_to_5000  max_bal_bc:5001_to_10000  \\\n",
       "0                        1                         0   \n",
       "1                        0                         1   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        1                         0   \n",
       "\n",
       "   max_bal_bc:greater_than_10000  mo_sin_old_rev_tl_op:less_than_24months  \\\n",
       "0                              0                                        0   \n",
       "1                              0                                        0   \n",
       "2                              0                                        0   \n",
       "3                              0                                        0   \n",
       "4                              0                                        0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:25months_to_60months  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:greater_than_60months  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "   months_since_earliest_cr_line:less_than_96months  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   months_since_earliest_cr_line:97months_to_192months  \\\n",
       "0                                                  1     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  1     \n",
       "4                                                  0     \n",
       "\n",
       "   months_since_earliest_cr_line:greater_than_192months  open_acc:less_than_5  \\\n",
       "0                                                  0                        0   \n",
       "1                                                  1                        0   \n",
       "2                                                  1                        1   \n",
       "3                                                  0                        0   \n",
       "4                                                  1                        1   \n",
       "\n",
       "   open_acc:6_to_8  open_acc:greater_than_8  num_sats:0_to_5  num_sats:6_to_8  \\\n",
       "0                1                        0                0                1   \n",
       "1                0                        1                0                0   \n",
       "2                0                        0                1                0   \n",
       "3                0                        1                0                0   \n",
       "4                0                        0                1                0   \n",
       "\n",
       "   num_sats:greater_than_8  mort_acc:0  mort_acc:1_to_3  \\\n",
       "0                        0           0                1   \n",
       "1                        1           1                0   \n",
       "2                        0           1                0   \n",
       "3                        1           0                1   \n",
       "4                        0           1                0   \n",
       "\n",
       "   mort_acc:greater_than_3  inq_last_6mths:0  inq_last_6mths:1  \\\n",
       "0                        0                 1                 0   \n",
       "1                        0                 0                 0   \n",
       "2                        0                 1                 0   \n",
       "3                        0                 1                 0   \n",
       "4                        0                 1                 0   \n",
       "\n",
       "   inq_last_6mths:greater_than_1  open_il_12m:_0  open_il_12m:_1  \\\n",
       "0                              0               1               0   \n",
       "1                              1               1               0   \n",
       "2                              0               1               0   \n",
       "3                              0               0               1   \n",
       "4                              0               1               0   \n",
       "\n",
       "   open_il_12m:greater_than_1  num_tl_op_past_12m:0  num_tl_op_past_12m:1  \\\n",
       "0                           0                     0                     0   \n",
       "1                           0                     0                     0   \n",
       "2                           0                     1                     0   \n",
       "3                           0                     0                     0   \n",
       "4                           0                     1                     0   \n",
       "\n",
       "   num_tl_op_past_12m:2  num_tl_op_past_12m:3  \\\n",
       "0                     1                     0   \n",
       "1                     0                     0   \n",
       "2                     0                     0   \n",
       "3                     0                     0   \n",
       "4                     0                     0   \n",
       "\n",
       "   num_tl_op_past_12m:greater_than_3  annual_inc:0_to_25000  \\\n",
       "0                                  0                      0   \n",
       "1                                  1                      0   \n",
       "2                                  0                      1   \n",
       "3                                  1                      0   \n",
       "4                                  0                      0   \n",
       "\n",
       "   annual_inc:25001_to_50000  annual_inc:50001_to_75000  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          1                          0   \n",
       "4                          0                          1   \n",
       "\n",
       "   annual_inc:75001_to_100000  annual_inc:greater_than_100001  dti:0_to_36  \\\n",
       "0                           0                               1            1   \n",
       "1                           1                               0            1   \n",
       "2                           0                               0            1   \n",
       "3                           0                               0            1   \n",
       "4                           0                               0            1   \n",
       "\n",
       "   dti:greater_than_36  emp_length_int:less_than_0  emp_length_int:1_to_2  \\\n",
       "0                    0                           0                      0   \n",
       "1                    0                           0                      0   \n",
       "2                    0                           0                      1   \n",
       "3                    0                           0                      0   \n",
       "4                    0                           0                      0   \n",
       "\n",
       "   emp_length_int:3_to_5  emp_length_int:6_to_9  emp_length_int:greater_than_9  \n",
       "0                      0                      0                              1  \n",
       "1                      0                      0                              1  \n",
       "2                      0                      0                              0  \n",
       "3                      1                      0                              0  \n",
       "4                      0                      0                              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model (TM) Train Input Data Exploration\n",
    "\n",
    "# Checking the Size of the Target Model (SM) Train Input Data\n",
    "\n",
    "print(tm_train_X.shape)\n",
    "\n",
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "tm_train_X.columns[[0, 1, 2]]\n",
    "\n",
    "# Removing the first index column from the dataset\n",
    "\n",
    "tm_train_X.drop(tm_train_X.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Re-checking the size of the dataset\n",
    "\n",
    "print(tm_train_X.shape)\n",
    "\n",
    "# Displying the first 5 data instances\n",
    "\n",
    "tm_train_X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "1zORYWNGNcwI",
    "outputId": "f1803550-2cbc-495a-9c9b-2bd856abdbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419425, 2)\n",
      "(419425, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score\n",
       "0           672\n",
       "1           537\n",
       "2           672\n",
       "3           537\n",
       "4           687"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model (TM) Train Regression Output Data Exploration\n",
    "\n",
    "# Checking the Size of the Target Model (SM) Train Input Data\n",
    "\n",
    "print(tm_train_y_reg.shape)\n",
    "\n",
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "tm_train_y_reg.columns[[0, 1]]\n",
    "\n",
    "# Removing the first index column from the dataset\n",
    "\n",
    "tm_train_y_reg.drop(tm_train_y_reg.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Re-checking the size of the dataset\n",
    "\n",
    "print(tm_train_y_reg.shape)\n",
    "\n",
    "# Displying the first 5 data instances\n",
    "\n",
    "tm_train_y_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "T5G7TmMrNc49",
    "outputId": "ff9012f4-a845-4e90-e264-868537b59670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419425, 2)\n",
      "(419425, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_default\n",
       "0               0\n",
       "1               1\n",
       "2               0\n",
       "3               1\n",
       "4               1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model (TM) Train Classification Output Data Exploration\n",
    "\n",
    "# Checking the Size of the Target Model (SM) Train Input Data\n",
    "\n",
    "print(tm_train_y_clas.shape)\n",
    "\n",
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "tm_train_y_clas.columns[[0, 1]]\n",
    "\n",
    "# Removing the first index column from the dataset\n",
    "\n",
    "tm_train_y_clas.drop(tm_train_y_clas.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Re-checking the size of the dataset\n",
    "\n",
    "print(tm_train_y_clas.shape)\n",
    "\n",
    "# Displying the first 5 data instances\n",
    "\n",
    "tm_train_y_clas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XESQFDm4N6BL"
   },
   "source": [
    "# **4. Target Model (TM) - Validation Data - Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "xl4otQo9N6BW",
    "outputId": "687c06c6-fc39-4894-f66a-02a7b30b6124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83885, 75)\n",
      "(83885, 74)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_rec:0</th>\n",
       "      <th>pub_record:non_zero</th>\n",
       "      <th>delinq_2yrs:0</th>\n",
       "      <th>delinq_2yrs:1</th>\n",
       "      <th>delinq_2yrs:greater_than_1</th>\n",
       "      <th>num_tl_120dpd_2m:0</th>\n",
       "      <th>num_tl_120dpd_2m:non_zero</th>\n",
       "      <th>pub_rec_bankruptcies:0</th>\n",
       "      <th>pub_rec_bankruptcies:non_zero</th>\n",
       "      <th>num_tl_90g_dpd_24m:0</th>\n",
       "      <th>num_tl_90g_dpd_24m:non_zero</th>\n",
       "      <th>num_accts_ever_120_pd:0</th>\n",
       "      <th>num_accts_ever_120_pd:_non_zero</th>\n",
       "      <th>acc_now_delinq:0</th>\n",
       "      <th>acc_now_delinq:non_zero</th>\n",
       "      <th>num_tl_30dpd:0</th>\n",
       "      <th>num_tl_30dpd:non_zero</th>\n",
       "      <th>total_rec_late_fee:0</th>\n",
       "      <th>total_rec_late_fee:non_zero</th>\n",
       "      <th>num_rev_tl_bal_gt_0:0</th>\n",
       "      <th>num_rev_tl_bal_gt_0:1_to_5</th>\n",
       "      <th>num_rev_tl_bal_gt_0:greater_than_5</th>\n",
       "      <th>percent_bc_gt_75:0</th>\n",
       "      <th>percent_bc_gt_75:1_to_75</th>\n",
       "      <th>percent_bc_gt_75:greater_than_75</th>\n",
       "      <th>revol_util:0_to_15</th>\n",
       "      <th>revol_util:16_to_30</th>\n",
       "      <th>revol_util:31_to_60</th>\n",
       "      <th>revol_util:greater_than_60</th>\n",
       "      <th>il_util:0</th>\n",
       "      <th>il_util:1_to_100</th>\n",
       "      <th>il_util:greater_than_100</th>\n",
       "      <th>max_bal_bc:0_to_2500</th>\n",
       "      <th>max_bal_bc:2501_to_5000</th>\n",
       "      <th>max_bal_bc:5001_to_10000</th>\n",
       "      <th>max_bal_bc:greater_than_10000</th>\n",
       "      <th>mo_sin_old_rev_tl_op:less_than_24months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:25months_to_60months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:greater_than_60months</th>\n",
       "      <th>months_since_earliest_cr_line:less_than_120months</th>\n",
       "      <th>months_since_earliest_cr_line:121months_to_240months</th>\n",
       "      <th>months_since_earliest_cr_line:greater_than_240months</th>\n",
       "      <th>open_acc:less_than_5</th>\n",
       "      <th>open_acc:6_to_8</th>\n",
       "      <th>open_acc:greater_than_8</th>\n",
       "      <th>num_sats:0_to_5</th>\n",
       "      <th>num_sats:6_to_8</th>\n",
       "      <th>num_sats:greater_than_8</th>\n",
       "      <th>mort_acc:0</th>\n",
       "      <th>mort_acc:1_to_3</th>\n",
       "      <th>mort_acc:greater_than_3</th>\n",
       "      <th>inq_last_6mths:0</th>\n",
       "      <th>inq_last_6mths:1</th>\n",
       "      <th>inq_last_6mths:greater_than_1</th>\n",
       "      <th>open_il_12m:_0</th>\n",
       "      <th>open_il_12m:_1</th>\n",
       "      <th>open_il_12m:greater_than_1</th>\n",
       "      <th>num_tl_op_past_12m:0</th>\n",
       "      <th>num_tl_op_past_12m:1</th>\n",
       "      <th>num_tl_op_past_12m:2</th>\n",
       "      <th>num_tl_op_past_12m:3</th>\n",
       "      <th>num_tl_op_past_12m:greater_than_3</th>\n",
       "      <th>annual_inc:0_to_25000</th>\n",
       "      <th>annual_inc:25001_to_50000</th>\n",
       "      <th>annual_inc:50001_to_75000</th>\n",
       "      <th>annual_inc:75001_to_100000</th>\n",
       "      <th>annual_inc:greater_than_100001</th>\n",
       "      <th>dti:0_to_36</th>\n",
       "      <th>dti:greater_than_36</th>\n",
       "      <th>emp_length_int:less_than_0</th>\n",
       "      <th>emp_length_int:1_to_2</th>\n",
       "      <th>emp_length_int:3_to_5</th>\n",
       "      <th>emp_length_int:6_to_9</th>\n",
       "      <th>emp_length_int:greater_than_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pub_rec:0  pub_record:non_zero  delinq_2yrs:0  delinq_2yrs:1  \\\n",
       "0          0                    1              1              0   \n",
       "1          1                    0              1              0   \n",
       "2          1                    0              1              0   \n",
       "3          1                    0              1              0   \n",
       "4          1                    0              1              0   \n",
       "\n",
       "   delinq_2yrs:greater_than_1  num_tl_120dpd_2m:0  num_tl_120dpd_2m:non_zero  \\\n",
       "0                           0                   1                          0   \n",
       "1                           0                   1                          0   \n",
       "2                           0                   1                          0   \n",
       "3                           0                   1                          0   \n",
       "4                           0                   1                          0   \n",
       "\n",
       "   pub_rec_bankruptcies:0  pub_rec_bankruptcies:non_zero  \\\n",
       "0                       1                              0   \n",
       "1                       1                              0   \n",
       "2                       1                              0   \n",
       "3                       1                              0   \n",
       "4                       1                              0   \n",
       "\n",
       "   num_tl_90g_dpd_24m:0  num_tl_90g_dpd_24m:non_zero  num_accts_ever_120_pd:0  \\\n",
       "0                     1                            0                        0   \n",
       "1                     1                            0                        0   \n",
       "2                     1                            0                        1   \n",
       "3                     1                            0                        1   \n",
       "4                     1                            0                        0   \n",
       "\n",
       "   num_accts_ever_120_pd:_non_zero  acc_now_delinq:0  acc_now_delinq:non_zero  \\\n",
       "0                                1                 1                        0   \n",
       "1                                1                 1                        0   \n",
       "2                                0                 1                        0   \n",
       "3                                0                 1                        0   \n",
       "4                                1                 1                        0   \n",
       "\n",
       "   num_tl_30dpd:0  num_tl_30dpd:non_zero  total_rec_late_fee:0  \\\n",
       "0               1                      0                     1   \n",
       "1               1                      0                     1   \n",
       "2               1                      0                     1   \n",
       "3               1                      0                     1   \n",
       "4               1                      0                     1   \n",
       "\n",
       "   total_rec_late_fee:non_zero  num_rev_tl_bal_gt_0:0  \\\n",
       "0                            0                      0   \n",
       "1                            0                      0   \n",
       "2                            0                      0   \n",
       "3                            0                      0   \n",
       "4                            0                      0   \n",
       "\n",
       "   num_rev_tl_bal_gt_0:1_to_5  num_rev_tl_bal_gt_0:greater_than_5  \\\n",
       "0                           0                                   1   \n",
       "1                           1                                   0   \n",
       "2                           1                                   0   \n",
       "3                           0                                   1   \n",
       "4                           1                                   0   \n",
       "\n",
       "   percent_bc_gt_75:0  percent_bc_gt_75:1_to_75  \\\n",
       "0                   0                         1   \n",
       "1                   0                         0   \n",
       "2                   0                         0   \n",
       "3                   1                         0   \n",
       "4                   0                         0   \n",
       "\n",
       "   percent_bc_gt_75:greater_than_75  revol_util:0_to_15  revol_util:16_to_30  \\\n",
       "0                                 0                   0                    0   \n",
       "1                                 1                   0                    0   \n",
       "2                                 1                   1                    0   \n",
       "3                                 0                   0                    0   \n",
       "4                                 1                   0                    0   \n",
       "\n",
       "   revol_util:31_to_60  revol_util:greater_than_60  il_util:0  \\\n",
       "0                    1                           0          0   \n",
       "1                    0                           1          0   \n",
       "2                    0                           0          0   \n",
       "3                    1                           0          0   \n",
       "4                    0                           1          1   \n",
       "\n",
       "   il_util:1_to_100  il_util:greater_than_100  max_bal_bc:0_to_2500  \\\n",
       "0                 1                         0                     0   \n",
       "1                 1                         0                     1   \n",
       "2                 1                         0                     1   \n",
       "3                 1                         0                     0   \n",
       "4                 0                         0                     0   \n",
       "\n",
       "   max_bal_bc:2501_to_5000  max_bal_bc:5001_to_10000  \\\n",
       "0                        0                         0   \n",
       "1                        0                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         1   \n",
       "\n",
       "   max_bal_bc:greater_than_10000  mo_sin_old_rev_tl_op:less_than_24months  \\\n",
       "0                              1                                        0   \n",
       "1                              0                                        0   \n",
       "2                              0                                        0   \n",
       "3                              1                                        0   \n",
       "4                              0                                        0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:25months_to_60months  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          1   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:greater_than_60months  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           0   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "   months_since_earliest_cr_line:less_than_120months  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "   months_since_earliest_cr_line:121months_to_240months  \\\n",
       "0                                                  0      \n",
       "1                                                  1      \n",
       "2                                                  1      \n",
       "3                                                  1      \n",
       "4                                                  1      \n",
       "\n",
       "   months_since_earliest_cr_line:greater_than_240months  open_acc:less_than_5  \\\n",
       "0                                                  1                        0   \n",
       "1                                                  0                        0   \n",
       "2                                                  0                        0   \n",
       "3                                                  0                        0   \n",
       "4                                                  0                        1   \n",
       "\n",
       "   open_acc:6_to_8  open_acc:greater_than_8  num_sats:0_to_5  num_sats:6_to_8  \\\n",
       "0                0                        1                0                0   \n",
       "1                1                        0                0                1   \n",
       "2                1                        0                0                1   \n",
       "3                0                        1                0                0   \n",
       "4                0                        0                1                0   \n",
       "\n",
       "   num_sats:greater_than_8  mort_acc:0  mort_acc:1_to_3  \\\n",
       "0                        1           0                0   \n",
       "1                        0           0                1   \n",
       "2                        0           0                1   \n",
       "3                        1           0                1   \n",
       "4                        0           0                1   \n",
       "\n",
       "   mort_acc:greater_than_3  inq_last_6mths:0  inq_last_6mths:1  \\\n",
       "0                        1                 0                 1   \n",
       "1                        0                 1                 0   \n",
       "2                        0                 1                 0   \n",
       "3                        0                 0                 1   \n",
       "4                        0                 1                 0   \n",
       "\n",
       "   inq_last_6mths:greater_than_1  open_il_12m:_0  open_il_12m:_1  \\\n",
       "0                              0               1               0   \n",
       "1                              0               1               0   \n",
       "2                              0               0               0   \n",
       "3                              0               0               0   \n",
       "4                              0               1               0   \n",
       "\n",
       "   open_il_12m:greater_than_1  num_tl_op_past_12m:0  num_tl_op_past_12m:1  \\\n",
       "0                           0                     1                     0   \n",
       "1                           0                     1                     0   \n",
       "2                           1                     0                     0   \n",
       "3                           1                     0                     0   \n",
       "4                           0                     1                     0   \n",
       "\n",
       "   num_tl_op_past_12m:2  num_tl_op_past_12m:3  \\\n",
       "0                     0                     0   \n",
       "1                     0                     0   \n",
       "2                     0                     1   \n",
       "3                     0                     0   \n",
       "4                     0                     0   \n",
       "\n",
       "   num_tl_op_past_12m:greater_than_3  annual_inc:0_to_25000  \\\n",
       "0                                  0                      0   \n",
       "1                                  0                      0   \n",
       "2                                  0                      0   \n",
       "3                                  1                      0   \n",
       "4                                  0                      0   \n",
       "\n",
       "   annual_inc:25001_to_50000  annual_inc:50001_to_75000  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          1   \n",
       "3                          0                          0   \n",
       "4                          0                          1   \n",
       "\n",
       "   annual_inc:75001_to_100000  annual_inc:greater_than_100001  dti:0_to_36  \\\n",
       "0                           0                               1            1   \n",
       "1                           1                               0            1   \n",
       "2                           0                               0            1   \n",
       "3                           1                               0            1   \n",
       "4                           0                               0            1   \n",
       "\n",
       "   dti:greater_than_36  emp_length_int:less_than_0  emp_length_int:1_to_2  \\\n",
       "0                    0                           0                      0   \n",
       "1                    0                           0                      0   \n",
       "2                    0                           0                      1   \n",
       "3                    0                           0                      0   \n",
       "4                    0                           0                      0   \n",
       "\n",
       "   emp_length_int:3_to_5  emp_length_int:6_to_9  emp_length_int:greater_than_9  \n",
       "0                      0                      0                              1  \n",
       "1                      1                      0                              0  \n",
       "2                      0                      0                              0  \n",
       "3                      0                      0                              1  \n",
       "4                      1                      0                              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model (TM) Validation Input Data Exploration\n",
    "\n",
    "# Checking the Size of the Target Model (SM) Train Input Data\n",
    "\n",
    "print(tm_validation_X.shape)\n",
    "\n",
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "tm_validation_X.columns[[0, 1, 2]]\n",
    "\n",
    "# Removing the first index column from the dataset\n",
    "\n",
    "tm_validation_X.drop(tm_validation_X.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Re-checking the size of the dataset\n",
    "\n",
    "print(tm_validation_X.shape)\n",
    "\n",
    "# Displying the first 5 data instances\n",
    "\n",
    "tm_validation_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "3NDwHIJ2N6BX",
    "outputId": "5aff8140-7f57-44c8-8201-35219f3b4886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83885, 2)\n",
      "(83885, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score\n",
       "0           757\n",
       "1           722\n",
       "2           672\n",
       "3           702\n",
       "4           727"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model (TM) Validation Regression Output Data Exploration\n",
    "\n",
    "# Checking the Size of the Target Model (SM) Train Input Data\n",
    "\n",
    "print(tm_validation_y_reg.shape)\n",
    "\n",
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "tm_validation_y_reg.columns[[0, 1]]\n",
    "\n",
    "# Removing the first index column from the dataset\n",
    "\n",
    "tm_validation_y_reg.drop(tm_validation_y_reg.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Re-checking the size of the dataset\n",
    "\n",
    "print(tm_validation_y_reg.shape)\n",
    "\n",
    "# Displying the first 5 data instances\n",
    "\n",
    "tm_validation_y_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "1-V5QqOYN6BY",
    "outputId": "41af1ba7-12ca-4d76-e721-6ba5ad3ffab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83885, 2)\n",
      "(83885, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_default\n",
       "0               0\n",
       "1               0\n",
       "2               0\n",
       "3               0\n",
       "4               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model (TM) Validation Classification Output Data Exploration\n",
    "\n",
    "# Checking the Size of the Target Model (SM) Train Input Data\n",
    "\n",
    "print(tm_validation_y_clas.shape)\n",
    "\n",
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "tm_validation_y_clas.columns[[0, 1]]\n",
    "\n",
    "# Removing the first index column from the dataset\n",
    "\n",
    "tm_validation_y_clas.drop(tm_validation_y_clas.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Re-checking the size of the dataset\n",
    "\n",
    "print(tm_validation_y_clas.shape)\n",
    "\n",
    "# Displying the first 5 data instances\n",
    "\n",
    "tm_validation_y_clas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izCdgpFuS53y"
   },
   "source": [
    "# **5. Importing the Base Model (Source Model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apbrLKhpTB_7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Loading an Existing Trained Model\n",
    "\n",
    "source_model_path = \"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/models/source_model/1_sm_adam_relu_sigmoid_4_0.001_inputsize.h5\"\n",
    "\n",
    "source_model = load_model(source_model_path)\n",
    "\n",
    "print(\"Pre-Trained Source Model Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2eoE5JTUTHm"
   },
   "outputs": [],
   "source": [
    "# Verifying the Summary of the Existing Pre-Trained Source Model\n",
    "\n",
    "source_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJQRChpX9mPa"
   },
   "source": [
    "# **6. Transfer Learning of the Source Model into the Target Model : Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16G_SSMmyO-S"
   },
   "outputs": [],
   "source": [
    "# Freezing the Source Model to avoid updating the weights during the Target Model Training\n",
    "\n",
    "source_model.trainable = False\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26p2WoYIv4ML"
   },
   "outputs": [],
   "source": [
    "# Removing the Output (Last) Layer from the Source Model and Creating a Base Model\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = Model(inputs=source_model.input, outputs=source_model.layers[-2].output)\n",
    "\n",
    "print(\"Execution Completed\")                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQjiyG-YttW7"
   },
   "outputs": [],
   "source": [
    "# Verifying the Summary of the Base Model after removing the Output (Last) Layer to use the Source Model as Feature Extractor\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZGGo3vi07WF"
   },
   "source": [
    "**As we can see; output (last) layer is removed from the base model for transfer learning feature extraction purposes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Intnv2F-I34"
   },
   "source": [
    "# **7. Transfer Learning of the Source Model into the Target Model : Feature Extraction - Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTqmSzMw-I4C"
   },
   "outputs": [],
   "source": [
    "# Defining the Target Model from the Pre-Trained Source Model\n",
    "\n",
    "'''\n",
    "inputs = base_model\n",
    "output_reg = keras.layers.Dense(1, activation='linear')\n",
    "output_clas = keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "outputs = [output_reg, output_clas]\n",
    "\n",
    "target_model = tf.keras.Model(inputs=inputs, outputs=output_reg)\n",
    "'''\n",
    "\n",
    "target_model_2 = tf.keras.Sequential([\n",
    "                                    base_model,\n",
    "                                    #keras.layers.Dense(1, activation='linear')\n",
    "                                    #keras.layers.Dense(1)\n",
    "                                    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the Model\n",
    "\n",
    "base_lr_2 = 0.001\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=base_lr_2)\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = 'accuracy'\n",
    "\n",
    "target_model_2.compile(\n",
    "    optimizer=optim,\n",
    "    loss=loss,\n",
    "    metrics=[metrics])\n",
    "\n",
    "print(\"Execution Completed\")                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmkftcxt-I4D"
   },
   "outputs": [],
   "source": [
    "# Verifying the Summary of the Target Model (with Pre-Trained Source Model as Feature Extractor)\n",
    "\n",
    "target_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ua0vli0N-I4D"
   },
   "outputs": [],
   "source": [
    "len(target_model_2.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX9e7Op9x7y7"
   },
   "source": [
    "# **!!!!!Importing Target Model Trained until Previous Epochs Steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_wXAHWdyLgq",
    "outputId": "65bf9469-5e50-4d88-d39a-dfecaebf8b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Model Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Loading the Target Model 1 to Continue Training\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/models/target_model/tm_model_2_clas_fe_retrain_2_600_final/tm_model_2_clas_fe_retrain_2_600_final.h5\"\n",
    "\n",
    "target_model_2 = load_model(model_path)\n",
    "\n",
    "print(\"Target Model Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvJCTI1n9gE7",
    "outputId": "2406dd41-194d-4160-c0e8-0edacdf4331c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_2 (Functional)        (None, 60)                19506     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,567\n",
      "Trainable params: 61\n",
      "Non-trainable params: 19,506\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Verifying the Summary of the Existing Pre-Trained Model\n",
    "\n",
    "target_model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q9nE_CVzVEP"
   },
   "source": [
    "**As we can see; pre-trained traget model 1 is loaded to continue with further training.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5f178gr81l8"
   },
   "source": [
    "# **8. Target Model Training - With Source Model as Feature Extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqZLqNZS81mK",
    "outputId": "9d464770-5e59-4cbb-e449-1a99a7a02352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2502/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2503/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2504/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2505/5000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2506/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2507/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2508/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2509/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2510/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2511/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2512/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2513/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2514/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2515/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2516/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2517/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2518/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2519/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2520/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2521/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2522/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2523/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2524/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2525/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2526/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2527/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2528/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2529/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2530/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2531/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2532/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2533/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2534/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2535/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2536/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2537/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2538/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2539/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2540/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2541/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2542/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2543/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2544/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2545/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2546/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2547/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2548/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2549/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2550/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2551/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2552/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2553/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2554/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2555/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2556/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2557/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2558/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2559/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2560/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2561/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2562/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2563/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2564/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2565/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2566/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2567/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2568/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2569/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2570/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2571/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2572/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2573/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2574/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2575/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2576/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2577/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2578/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2579/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2580/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2581/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2582/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2583/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2584/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2585/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2586/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2587/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2588/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2589/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2590/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2591/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2592/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2593/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2594/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2595/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2596/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2597/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2598/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2599/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2600/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2601/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2602/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2603/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2604/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2605/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2606/5000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2607/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2608/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2609/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2610/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2611/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2612/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2613/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2614/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2615/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2616/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2617/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2618/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2619/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2620/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2621/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2622/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2623/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2624/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2625/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2626/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2627/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2628/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2629/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2630/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2631/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2632/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2633/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2634/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2635/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2636/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2637/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2638/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2639/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2640/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2641/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2642/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2643/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2644/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2645/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2646/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2647/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2648/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2649/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2650/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2651/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2652/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2653/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2654/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2655/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2656/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2657/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2658/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2659/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2660/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2661/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2662/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2663/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2664/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2665/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2666/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2667/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2668/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2669/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2670/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2671/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2672/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2673/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2674/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2675/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2676/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2677/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2678/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2679/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2680/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2681/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2682/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2683/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2684/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2685/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2686/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2687/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2688/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2689/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2690/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2691/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2692/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2693/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2694/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2695/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2696/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2697/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2698/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2699/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2700/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2701/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2702/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2703/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2704/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2705/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2706/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2707/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2708/5000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2709/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2710/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2711/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2712/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2713/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2714/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2715/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2716/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2717/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2718/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2719/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2720/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2721/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2722/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2723/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2724/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2725/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2726/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2727/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2728/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2729/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2730/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2731/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2732/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2733/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2734/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2735/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2736/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2737/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2738/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2739/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2740/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2741/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2742/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2743/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2744/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2745/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2746/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2747/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2748/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2749/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2750/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2751/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2752/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2753/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2754/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2755/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2756/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2757/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2758/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2759/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2760/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2761/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2762/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2763/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2764/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2765/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2766/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2767/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2768/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2769/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2770/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2771/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2772/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2773/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2774/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2775/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2776/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2777/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2778/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2779/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2780/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2781/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2782/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2783/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2784/5000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2785/5000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2786/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2787/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2788/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2789/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2790/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2791/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2792/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2793/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2794/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2795/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2796/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2797/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2798/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2799/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2800/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2801/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2802/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2803/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2804/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2805/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2806/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2807/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2808/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2809/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2810/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2811/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2812/5000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2813/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2814/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2815/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2816/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2817/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2818/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2819/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2820/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2821/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2822/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2823/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2824/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2825/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2826/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2827/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2828/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2829/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2830/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2831/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2832/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2833/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2834/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2835/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2836/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2837/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2838/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2839/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2840/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2841/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2842/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2843/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2844/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2845/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2846/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2847/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2848/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2849/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2850/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2851/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2852/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2853/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2854/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2855/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2856/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2857/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2858/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2859/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2860/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2861/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2862/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2863/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2864/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2865/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2866/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2867/5000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2868/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2869/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2870/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2871/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2872/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2873/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2874/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2875/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2876/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2877/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2878/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2879/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2880/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2881/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2882/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2883/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2884/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2885/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2886/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2887/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2888/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2889/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2890/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2891/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2892/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2893/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2894/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2895/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2896/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2897/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2898/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2899/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2900/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2901/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2902/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2903/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2904/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2905/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2906/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2907/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2908/5000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2909/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2910/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2911/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2912/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2913/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2914/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2915/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2916/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2917/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2918/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2919/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2920/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2921/5000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2922/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2923/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2924/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2925/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2926/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2927/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2928/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2929/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2930/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2931/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2932/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2933/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2934/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2935/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2936/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2937/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2938/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2939/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2940/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2941/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2942/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2943/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2944/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2945/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2946/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2947/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2948/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2949/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2950/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2951/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2952/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2953/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2954/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2955/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2956/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2957/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2958/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2959/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2960/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2961/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2962/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2963/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2964/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2965/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2966/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2967/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2968/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2969/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2970/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2971/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2972/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2973/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2974/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2975/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2976/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2977/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2978/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2979/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2980/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2981/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2982/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2983/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2984/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2985/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2986/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2987/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2988/5000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2989/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2990/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2991/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2992/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2993/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2994/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2995/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2996/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2997/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2998/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 2999/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3000/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3001/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3002/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3003/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3004/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3005/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3006/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3007/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3008/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3009/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3010/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3011/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3012/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3013/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3014/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3015/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3016/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3017/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3018/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3019/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3020/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3021/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3022/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3023/5000\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3024/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3025/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3026/5000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3027/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3028/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3029/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3030/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3031/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3032/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3033/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3034/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3035/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3036/5000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3037/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3038/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3039/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3040/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3041/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3042/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3043/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3044/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3045/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3046/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3047/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3048/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3049/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3050/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3051/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3052/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3053/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3054/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3055/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3056/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3057/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3058/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3059/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3060/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3061/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3062/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3063/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3064/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3065/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3066/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3067/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3068/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3069/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3070/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3071/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3072/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3073/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3074/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3075/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3076/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3077/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3078/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3079/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3080/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3081/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3082/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3083/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3084/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3085/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3086/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3087/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3088/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3089/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3090/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3091/5000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3092/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3093/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3094/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3095/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3096/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3097/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3098/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3099/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3100/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3101/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3102/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3103/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3104/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3105/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3106/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3107/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3108/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3109/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3110/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3111/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3112/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3113/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3114/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3115/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3116/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3117/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3118/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3119/5000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3120/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3121/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3122/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3123/5000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3124/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3125/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3126/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3127/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3128/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3129/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3130/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3131/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3132/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3133/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3134/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3135/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3136/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3137/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3138/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3139/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3140/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3141/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3142/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3143/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3144/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3145/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3146/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3147/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3148/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3149/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3150/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3151/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3152/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3153/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3154/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3155/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3156/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3157/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3158/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3159/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3160/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3161/5000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3162/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3163/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3164/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3165/5000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3166/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3167/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3168/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3169/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3170/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3171/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3172/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3173/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3174/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3175/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3176/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3177/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3178/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3179/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3180/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3181/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3182/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3183/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3184/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3185/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3186/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3187/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3188/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3189/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3190/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3191/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3192/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3193/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3194/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3195/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3196/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3197/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3198/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3199/5000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3200/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3201/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3202/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3203/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3204/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3205/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3206/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3207/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3208/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3209/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3210/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3211/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3212/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3213/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3214/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3215/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3216/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3217/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3218/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3219/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3220/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3221/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3222/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3223/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3224/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3225/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3226/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3227/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3228/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3229/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3230/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3231/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3232/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3233/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3234/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3235/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3236/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3237/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3238/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3239/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3240/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3241/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3242/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3243/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3244/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3245/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3246/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3247/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3248/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3249/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3250/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3251/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3252/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3253/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3254/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3255/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3256/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3257/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3258/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3259/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3260/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3261/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3262/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3263/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3264/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3265/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3266/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3267/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3268/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3269/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3270/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3271/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3272/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3273/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3274/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3275/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3276/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3277/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3278/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3279/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3280/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3281/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3282/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3283/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3284/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3285/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3286/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3287/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3288/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3289/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3290/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3291/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3292/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3293/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3294/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3295/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3296/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3297/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3298/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3299/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3300/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3301/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3302/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3303/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3304/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3305/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3306/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3307/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3308/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3309/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3310/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3311/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3312/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3313/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3314/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3315/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3316/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3317/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3318/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3319/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3320/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3321/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3322/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3323/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3324/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3325/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3326/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3327/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3328/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3329/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3330/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3331/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3332/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3333/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3334/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3335/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3336/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3337/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3338/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3339/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3340/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3341/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3342/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3343/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3344/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3345/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3346/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3347/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3348/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3349/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3350/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3351/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3352/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3353/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3354/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3355/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3356/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3357/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3358/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3359/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3360/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3361/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3362/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3363/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3364/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3365/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3366/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3367/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3368/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3369/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3370/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3371/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3372/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3373/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3374/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3375/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3376/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3377/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3378/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3379/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3380/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3381/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3382/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3383/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3384/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3385/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3386/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3387/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3388/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3389/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3390/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3391/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3392/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3393/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3394/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3395/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3396/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3397/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3398/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3399/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3400/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3401/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3402/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3403/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3404/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3405/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3406/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3407/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3408/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3409/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3410/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3411/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3412/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3413/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3414/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3415/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3416/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3417/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3418/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3419/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3420/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3421/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3422/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3423/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3424/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3425/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3426/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3427/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3428/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3429/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3430/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3431/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3432/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3433/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3434/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3435/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3436/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3437/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3438/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3439/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3440/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3441/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3442/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3443/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3444/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3445/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3446/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3447/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3448/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3449/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3450/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3451/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3452/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3453/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3454/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3455/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3456/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3457/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3458/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3459/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3460/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3461/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3462/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3463/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3464/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3465/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3466/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3467/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3468/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3469/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3470/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3471/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3472/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3473/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3474/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3475/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3476/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3477/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3478/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3479/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3480/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3481/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3482/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3483/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3484/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3485/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3486/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3487/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3488/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3489/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3490/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3491/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3492/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3493/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3494/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3495/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3496/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3497/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3498/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3499/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3500/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3501/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3502/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3503/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3504/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3505/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3506/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3507/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3508/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3509/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3510/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3511/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3512/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3513/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3514/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3515/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3516/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3517/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3518/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3519/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3520/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3521/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3522/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3523/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3524/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3525/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3526/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3527/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3528/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3529/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3530/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3531/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3532/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3533/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3534/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3535/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3536/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3537/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3538/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3539/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3540/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3541/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3542/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3543/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3544/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3545/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3546/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3547/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3548/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3549/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3550/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3551/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3552/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3553/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3554/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3555/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3556/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3557/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3558/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3559/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3560/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3561/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3562/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3563/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3564/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3565/5000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3566/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3567/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3568/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3569/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3570/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3571/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3572/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3573/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3574/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3575/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3576/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3577/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3578/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3579/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3580/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3581/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3582/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3583/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3584/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3585/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3586/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3587/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3588/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3589/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3590/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3591/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3592/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3593/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3594/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3595/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3596/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3597/5000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3598/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3599/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3600/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3601/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3602/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3603/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3604/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3605/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3606/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3607/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3608/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3609/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3610/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3611/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3612/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3613/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3614/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3615/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3616/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3617/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3618/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3619/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3620/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3621/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3622/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3623/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3624/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3625/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3626/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3627/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3628/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3629/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3630/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3631/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3632/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3633/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3634/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3635/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3636/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3637/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3638/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3639/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3640/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3641/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3642/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3643/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3644/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3645/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3646/5000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3647/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3648/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3649/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3650/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3651/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3652/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3653/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3654/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3655/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3656/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3657/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3658/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3659/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3660/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3661/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3662/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3663/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3664/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3665/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3666/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3667/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3668/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3669/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3670/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3671/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3672/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3673/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3674/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3675/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3676/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3677/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3678/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3679/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3680/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3681/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3682/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3683/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3684/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3685/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3686/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3687/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3688/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3689/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3690/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3691/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3692/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3693/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3694/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3695/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3696/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3697/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3698/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3699/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3700/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3701/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3702/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3703/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3704/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3705/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3706/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3707/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3708/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3709/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3710/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3711/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3712/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3713/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3714/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3715/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3716/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3717/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3718/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3719/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3720/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3721/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3722/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3723/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3724/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3725/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3726/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3727/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3728/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3729/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3730/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3731/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3732/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3733/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3734/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3735/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3736/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3737/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3738/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3739/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3740/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3741/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3742/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3743/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3744/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3745/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3746/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3747/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3748/5000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3749/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3750/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3751/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3752/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3753/5000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3754/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3755/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3756/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3757/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3758/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3759/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3760/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3761/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3762/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3763/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3764/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3765/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3766/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3767/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3768/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3769/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3770/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3771/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3772/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3773/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3774/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3775/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3776/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3777/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3778/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3779/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3780/5000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3781/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3782/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3783/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3784/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3785/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3786/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3787/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3788/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3789/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3790/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3791/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3792/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3793/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3794/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3795/5000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3796/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3292 - val_accuracy: 0.8909\n",
      "Epoch 3797/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3295 - val_accuracy: 0.8910\n",
      "Epoch 3798/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3259 - accuracy: 0.8921 - val_loss: 0.3292 - val_accuracy: 0.8909\n",
      "Epoch 3799/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3292 - val_accuracy: 0.8909\n",
      "Epoch 3800/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3259 - accuracy: 0.8920 - val_loss: 0.3294 - val_accuracy: 0.8909\n",
      "Epoch 3801/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8921 - val_loss: 0.3294 - val_accuracy: 0.8909\n",
      "Epoch 3802/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8921 - val_loss: 0.3292 - val_accuracy: 0.8909\n",
      "Epoch 3803/5000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3292 - val_accuracy: 0.8909\n",
      "Epoch 3804/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3805/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3294 - val_accuracy: 0.8909\n",
      "Epoch 3806/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8921 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3807/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3292 - val_accuracy: 0.8909\n",
      "Epoch 3808/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3809/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8910\n",
      "Epoch 3810/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3811/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3812/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3813/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3814/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3815/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3816/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3817/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3818/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3819/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3820/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3821/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3822/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3823/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3824/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3825/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3826/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3827/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3828/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3829/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3830/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3831/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3832/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3833/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3834/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3835/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3836/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3837/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3838/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3839/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3840/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3841/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3842/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3843/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3844/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3845/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3846/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3847/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3848/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3849/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3850/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3851/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3852/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3853/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3854/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3855/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3856/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3857/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3858/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3859/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3860/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3861/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3862/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3863/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3864/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3865/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3866/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3867/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3868/5000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3869/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3870/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3871/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3872/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3873/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3874/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3875/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3876/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3877/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3878/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3879/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3880/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3881/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3882/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3883/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3884/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3885/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3886/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3887/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3888/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3889/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3890/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3891/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3892/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3893/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3894/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3895/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3896/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3897/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3898/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3899/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3900/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3901/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3902/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3903/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3904/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3905/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3906/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3907/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3908/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3909/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3910/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3911/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3912/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3913/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3914/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3915/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3916/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3917/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3918/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3919/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3920/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3921/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3922/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3923/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3924/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3925/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3926/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3927/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3928/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3929/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3930/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3931/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3932/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3933/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3934/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3935/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3936/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3937/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3938/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3939/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3940/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3941/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3942/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3943/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3944/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3945/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3946/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3947/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3948/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3949/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3950/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3951/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3952/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3953/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3954/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3955/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3956/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3957/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3958/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3959/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3960/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3961/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3962/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3963/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3964/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3965/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3966/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3967/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3968/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3969/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3970/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3971/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3972/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3973/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3974/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3975/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3976/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3977/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3978/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3979/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3980/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3981/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3982/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3983/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3984/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3985/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3986/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3987/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3988/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3989/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3990/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3991/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3992/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3993/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3994/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3995/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3996/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3997/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3998/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 3999/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4000/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4001/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4002/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4003/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4004/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4005/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4006/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4007/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4008/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4009/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4010/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4011/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4012/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4013/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4014/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4015/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4016/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4017/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4018/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4019/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4020/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4021/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4022/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4023/5000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4024/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4025/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4026/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4027/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4028/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4029/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4030/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4031/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4032/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4033/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4034/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4035/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4036/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4037/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4038/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4039/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4040/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4041/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4042/5000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4043/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4044/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4045/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4046/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4047/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4048/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4049/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4050/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4051/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4052/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4053/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4054/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4055/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4056/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4057/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4058/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4059/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4060/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4061/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4062/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4063/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4064/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4065/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4066/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4067/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4068/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4069/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4070/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4071/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4072/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4073/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4074/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4075/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4076/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4077/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4078/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4079/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4080/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4081/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4082/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4083/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4084/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4085/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4086/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4087/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4088/5000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4089/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4090/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4091/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4092/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4093/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4094/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4095/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4096/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4097/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4098/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4099/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4100/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4101/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4102/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4103/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4104/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4105/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4106/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4107/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4108/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4109/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4110/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4111/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4112/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4113/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4114/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4115/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4116/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4117/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4118/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4119/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4120/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4121/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4122/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4123/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4124/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4125/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4126/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4127/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4128/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4129/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4130/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4131/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4132/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4133/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4134/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4135/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4136/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4137/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4138/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4139/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4140/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4141/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4142/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4143/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4144/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4145/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4146/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4147/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4148/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4149/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4150/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4151/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4152/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4153/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4154/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4155/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4156/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4157/5000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4158/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4159/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4160/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4161/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4162/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4163/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4164/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4165/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4166/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4167/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4168/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4169/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4170/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4171/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4172/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4173/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4174/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4175/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4176/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4177/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4178/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4179/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4180/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4181/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4182/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4183/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4184/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4185/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4186/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4187/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4188/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4189/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4190/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4191/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4192/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4193/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4194/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4195/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4196/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4197/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4198/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4199/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4200/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4201/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4202/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4203/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4204/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4205/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4206/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4207/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4208/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4209/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4210/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4211/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4212/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4213/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4214/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4215/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4216/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4217/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4218/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4219/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4220/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4221/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4222/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4223/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4224/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4225/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4226/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4227/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4228/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4229/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4230/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4231/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4232/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4233/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4234/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4235/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4236/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4237/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4238/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4239/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4240/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4241/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4242/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4243/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4244/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4245/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4246/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4247/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4248/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4249/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4250/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4251/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4252/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4253/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4254/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4255/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4256/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4257/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4258/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4259/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4260/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4261/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4262/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4263/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4264/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4265/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4266/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4267/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4268/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4269/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4270/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4271/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4272/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4273/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4274/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4275/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4276/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4277/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4278/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4279/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4280/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4281/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4282/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4283/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4284/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4285/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4286/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4287/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4288/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4289/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4290/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4291/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4292/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4293/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4294/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4295/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4296/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4297/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4298/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4299/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4300/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4301/5000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4302/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4303/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4304/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4305/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4306/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4307/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4308/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4309/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4310/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4311/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4312/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4313/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4314/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4315/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4316/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4317/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4318/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4319/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4320/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4321/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4322/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4323/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4324/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4325/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4326/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4327/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4328/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4329/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4330/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4331/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4332/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4333/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4334/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4335/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4336/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4337/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4338/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4339/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4340/5000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4341/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4342/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4343/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4344/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4345/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4346/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4347/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4348/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4349/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4350/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4351/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4352/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4353/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4354/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4355/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4356/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4357/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4358/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4359/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4360/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4361/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4362/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4363/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4364/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4365/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4366/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4367/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4368/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4369/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4370/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4371/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4372/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4373/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4374/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4375/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4376/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4377/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4378/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4379/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4380/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4381/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4382/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4383/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4384/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4385/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4386/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4387/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4388/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4389/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4390/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4391/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4392/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4393/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4394/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4395/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4396/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4397/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4398/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4399/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4400/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4401/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4402/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4403/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4404/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4405/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4406/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4407/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4408/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4409/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4410/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4411/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4412/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4413/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4414/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4415/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4416/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4417/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4418/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4419/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4420/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4421/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4422/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4423/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4424/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4425/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4426/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4427/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4428/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4429/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4430/5000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4431/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4432/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4433/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4434/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4435/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4436/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4437/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4438/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4439/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4440/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4441/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4442/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4443/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4444/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4445/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4446/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4447/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4448/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4449/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4450/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4451/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4452/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4453/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4454/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4455/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4456/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4457/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4458/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4459/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4460/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4461/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4462/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4463/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4464/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4465/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4466/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4467/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4468/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4469/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4470/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4471/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4472/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4473/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4474/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4475/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4476/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4477/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4478/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4479/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4480/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4481/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4482/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4483/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4484/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4485/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4486/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4487/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4488/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4489/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4490/5000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4491/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4492/5000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4493/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4494/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4495/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4496/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4497/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4498/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4499/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4500/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4501/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4502/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4503/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4504/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4505/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4506/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4507/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4508/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4509/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4510/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4511/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4512/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4513/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4514/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4515/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4516/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4517/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4518/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4519/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4520/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4521/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4522/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4523/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4524/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4525/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4526/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4527/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4528/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4529/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4530/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4531/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4532/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4533/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4534/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4535/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4536/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4537/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4538/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4539/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4540/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4541/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4542/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4543/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4544/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4545/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4546/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4547/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4548/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4549/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4550/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4551/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4552/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4553/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4554/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4555/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4556/5000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4557/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4558/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4559/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4560/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4561/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4562/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4563/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4564/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4565/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4566/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4567/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4568/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4569/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4570/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4571/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4572/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4573/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4574/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4575/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4576/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4577/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4578/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4579/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4580/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4581/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4582/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4583/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4584/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4585/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4586/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4587/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4588/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4589/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4590/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4591/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4592/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4593/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4594/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4595/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4596/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4597/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4598/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4599/5000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4600/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4601/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4602/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4603/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4604/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4605/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4606/5000\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4607/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4608/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4609/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4610/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4611/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4612/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4613/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4614/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4615/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4616/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4617/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4618/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4619/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4620/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4621/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4622/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4623/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4624/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4625/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4626/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4627/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4628/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4629/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4630/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4631/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4632/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4633/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4634/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4635/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4636/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4637/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4638/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4639/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4640/5000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4641/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4642/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4643/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4644/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4645/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4646/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4647/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4648/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4649/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4650/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4651/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4652/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4653/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4654/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4655/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4656/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4657/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4658/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4659/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4660/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4661/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4662/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4663/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4664/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4665/5000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4666/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4667/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4668/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4669/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4670/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4671/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4672/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4673/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4674/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4675/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4676/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4677/5000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4678/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4679/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4680/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4681/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4682/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4683/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4684/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4685/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4686/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4687/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4688/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4689/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4690/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4691/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4692/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4693/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4694/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4695/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4696/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4697/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4698/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4699/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4700/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4701/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4702/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4703/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4704/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4705/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4706/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4707/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4708/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4709/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4710/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4711/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4712/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4713/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4714/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4715/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4716/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4717/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4718/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4719/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4720/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4721/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4722/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4723/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4724/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4725/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4726/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4727/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4728/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4729/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4730/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4731/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4732/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4733/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4734/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4735/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4736/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4737/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4738/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4739/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4740/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4741/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4742/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4743/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4744/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4745/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4746/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4747/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4748/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4749/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4750/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4751/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4752/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4753/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4754/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4755/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4756/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4757/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4758/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4759/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4760/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4761/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4762/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4763/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4764/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4765/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4766/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4767/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4768/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4769/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4770/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4771/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4772/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4773/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4774/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4775/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4776/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4777/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4778/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4779/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4780/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4781/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4782/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4783/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4784/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4785/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4786/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4787/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4788/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4789/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4790/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4791/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4792/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4793/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4794/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4795/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4796/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4797/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4798/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4799/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4800/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4801/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4802/5000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4803/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4804/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4805/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4806/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4807/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4808/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4809/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4810/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4811/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4812/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4813/5000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4814/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4815/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4816/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4817/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4818/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4819/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4820/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4821/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4822/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4823/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4824/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4825/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4826/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4827/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4828/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4829/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4830/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4831/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4832/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4833/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4834/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4835/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4836/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4837/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4838/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4839/5000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4840/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4841/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4842/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4843/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4844/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4845/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4846/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4847/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4848/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4849/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4850/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4851/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4852/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4853/5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4854/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4855/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4856/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4857/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4858/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4859/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4860/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4861/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4862/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4863/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4864/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4865/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4866/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4867/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4868/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4869/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4870/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4871/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4872/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4873/5000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4874/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4875/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4876/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4877/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4878/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4879/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4880/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4881/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4882/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4883/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4884/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4885/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4886/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4887/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4888/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4889/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4890/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4891/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4892/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4893/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4894/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4895/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4896/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4897/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4898/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4899/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4900/5000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4901/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4902/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4903/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4904/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4905/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4906/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4907/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4908/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4909/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4910/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4911/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4912/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4913/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4914/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4915/5000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4916/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4917/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4918/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4919/5000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4920/5000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4921/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4922/5000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4923/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4924/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4925/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4926/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4927/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4928/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4929/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4930/5000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4931/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4932/5000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4933/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4934/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4935/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4936/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4937/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4938/5000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4939/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4940/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4941/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4942/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4943/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4944/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4945/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4946/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4947/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4948/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4949/5000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4950/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4951/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4952/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4953/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4954/5000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4955/5000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4956/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4957/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4958/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4959/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4960/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4961/5000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4962/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4963/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4964/5000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4965/5000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4966/5000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4967/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4968/5000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4969/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4970/5000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4971/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4972/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4973/5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4974/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4975/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4976/5000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4977/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4978/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4979/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4980/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4981/5000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4982/5000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4983/5000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4984/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4985/5000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4986/5000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4987/5000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4988/5000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4989/5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4990/5000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4991/5000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4992/5000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4993/5000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4994/5000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4995/5000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4996/5000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4997/5000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4998/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 4999/5000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Epoch 5000/5000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3258 - accuracy: 0.8920 - val_loss: 0.3293 - val_accuracy: 0.8909\n",
      "Model Training Completed.....\n"
     ]
    }
   ],
   "source": [
    "# Target Model Training - With Source Model as Feature Extractor\n",
    "\n",
    "# Training Configurations\n",
    "\n",
    "input_data_size = tm_train_X.shape[0]\n",
    "\n",
    "epochs_2 = 5000\n",
    "batch_size_2 = input_data_size\n",
    "\n",
    "# Tensorboard Configuration\n",
    "\n",
    "log_dir_path = \"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/logs/tm_2_clas_fe_retrain_2/\"\n",
    "\n",
    "tb_callback_tm_2 = tf.keras.callbacks.TensorBoard(log_dir=log_dir_path, \n",
    "                                                histogram_freq=1)\n",
    "\n",
    "\n",
    "print(\"Model Training Started.....\")\n",
    "\n",
    "history = target_model_2.fit(tm_train_X, tm_train_y_clas,\n",
    "                            validation_data=(tm_validation_X, tm_validation_y_clas),\n",
    "                            epochs=epochs_2,\n",
    "                            batch_size=batch_size_2, \n",
    "                            callbacks=[tb_callback_tm_2])\n",
    "\n",
    "print(\"Model Training Completed.....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IvWkYf285_y"
   },
   "source": [
    "# **9. Target Model - Validation Predictions - Classification - \"Credit Default**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xr0drYIy85_z"
   },
   "outputs": [],
   "source": [
    "# Predicting the Target \"Credit Default\" on the Validation Data\n",
    "\n",
    "tm2_y_pred = target_model_2.predict(tm_validation_X, batch_size=1)\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvHj0wlL85_z"
   },
   "outputs": [],
   "source": [
    "# Verifying the Count of Prediction Outcomes on the Validation Data\n",
    "\n",
    "print(\"Total Output Actuals on the Target Model 2 Validation Data: \", tm_validation_y_clas.shape[0])\n",
    "print(\"Total Output Predictions on the Target Model 2 Validation Data: \", len(tm2_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOGPBHcJ85_0"
   },
   "outputs": [],
   "source": [
    "# Comparing the Actual and Prediction Results for the first 10 Validation Data Instances\n",
    "\n",
    "print(\"Target Model 2 Validation Actuals\")\n",
    "print(tm_validation_y_clas[:10])\n",
    "\n",
    "print(\"Target Model 2 Validation Predictions\")\n",
    "print(tm2_y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBHYYdcg88qQ"
   },
   "source": [
    "# **10. Target Model - Visualising the Performance Metrics (Loss)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbH6qOgB88qS"
   },
   "outputs": [],
   "source": [
    "hist_tm2 = pd.DataFrame(history.history)\n",
    "hist_tm2['epoch'] = history.epoch\n",
    "hist_tm2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UykZNjy88qT"
   },
   "outputs": [],
   "source": [
    "hist_tm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsxRSqR888qU"
   },
   "outputs": [],
   "source": [
    "def tm_plot_loss_tm2(history):\n",
    "  plt.plot(history.history['loss'], label='Loss')\n",
    "  plt.plot(history.history['val_loss'], label='Validation_Loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Loss]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "tm_plot_loss_tm2(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63-FtZQGZ8R5"
   },
   "source": [
    "# **11. Target Model 2 - Actuals versus Predictions Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EyMFVAvaH0y"
   },
   "outputs": [],
   "source": [
    "# Converting probability predictions numpy array into a dataframe\n",
    "\n",
    "tm2_y_pred_df = pd.DataFrame(tm2_y_pred, columns=['Credit_Default_Probability_Prediction'])\n",
    "tm2_y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfUsbRI0fnpN"
   },
   "outputs": [],
   "source": [
    "tm2_y_pred_df['Credit_Default_Class_Prediction'] = np.where( tm2_y_pred_df['Credit_Default_Probability_Prediction'] > 0.5, 1, 0)\n",
    "\n",
    "print(\"Missing Values in the New Column 'Credit_Default_Class_Prediction':\", tm2_y_pred_df['Credit_Default_Class_Prediction'].isna().sum())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Displaying a sample of 10 random actuals and its respective predictions\n",
    "tm2_y_pred_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cB8qeJjXiHHP"
   },
   "outputs": [],
   "source": [
    "# Verifying the Size and the Missing Values (if any) Count of the Credit Default Actual (Ground-Truth) Dataframe and the Predictions Dataframe\n",
    "\n",
    "print(tm_validation_y_clas.shape)\n",
    "print(tm2_y_pred_df.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(tm_validation_y_clas.isna().sum())\n",
    "print(tm2_y_pred_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdYHSrhZgbDS"
   },
   "outputs": [],
   "source": [
    "# Concatenating the Credit Default Actual (Ground-Truth) Dataframe and the Predictions Dataframe\n",
    "\n",
    "frames = [tm_validation_y_clas, tm2_y_pred_df]\n",
    "\n",
    "tm2_results = pd.concat(frames, axis=1)\n",
    "\n",
    "# Renaming the \n",
    "tm2_results.rename(columns = {'credit_default':'Credit_Default_Class_Actual'}, inplace = True)\n",
    "\n",
    "# Displaying a sample of 10 random results\n",
    "tm2_results.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fU5UP5AecBv"
   },
   "source": [
    "# **12. Exporting a Copy of the Credit Default Output Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYVIX4XmecB7"
   },
   "outputs": [],
   "source": [
    "# Exporting a copy of Credit Default Actuals and Predictions DataFrame as a csv file\n",
    "\n",
    "tm2_results.to_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/output/tm_model_2_classification_1500b_predictions.csv\")\n",
    "\n",
    "print(\"Data Export Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHsdhd8Ci1IF"
   },
   "source": [
    "# **13. Target Model 2 - Metrics Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSHRaF2ei-nT"
   },
   "outputs": [],
   "source": [
    "# Target Model 2 - Classification Report \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "tm2_classification_report = classification_report(tm2_results['Credit_Default_Class_Actual'], tm2_results['Credit_Default_Class_Prediction'])\n",
    "\n",
    "print(tm2_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKWqCaDBkQr2"
   },
   "outputs": [],
   "source": [
    "# Target Model 2 - Confusion Matrix\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "tm2_cm = tf.math.confusion_matrix(labels=tm2_results['Credit_Default_Class_Actual'], predictions=tm2_results['Credit_Default_Class_Prediction'])\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "sn.heatmap(tm2_cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3W39avKPkoiQ"
   },
   "outputs": [],
   "source": [
    "# Target Model 2 - ROC, AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tm2_auc = roc_auc_score(tm2_results['Credit_Default_Class_Actual'], tm2_results['Credit_Default_Class_Prediction'])\n",
    "\n",
    "print(\"Target Model ROC AUC: \", tm2_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg8hRySuZu1y"
   },
   "source": [
    "# **14. Saving the Finalised Target Model 2 - Classification of \"Credit_Default\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IHleWCAZxEZ",
    "outputId": "30eda2c5-1af5-411f-bc49-ba0abfea2b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "# Saving the Target Model 2 - Classification of \"Credit_Default\"\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "target_model_2.save('tm_model_2_clas_fe_retrain_2_5000_final.h5')\n",
    "\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cdPT4n7qFz2",
    "outputId": "bebeb670-4a8b-4be4-dc7a-d93bed6d879c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x7f1f8b61c910>>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model 2 Summarisation\n",
    "\n",
    "target_model_2.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkasX2tPhg59"
   },
   "source": [
    "# **15. Saving the Finalised Target Model 2 Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_i8qDWLhtzW",
    "outputId": "096a91bb-b0a2-4047-f75c-84c77dc0c032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "# Saving the Model Weights\n",
    "\n",
    "target_model_2.save_weights(\"tm_model_2_clas_fe_retrain_2_5000_final_weights\")\n",
    "\n",
    "print(\"Model Weights Saved Successfully\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "HVPa7aXAKMBu",
    "TR8cYEN_IWzm",
    "DukpTXKCKwx5",
    "2Mqyl1FiMTR4",
    "XESQFDm4N6BL",
    "izCdgpFuS53y",
    "iJQRChpX9mPa",
    "4Intnv2F-I34",
    "RX9e7Op9x7y7",
    "6IvWkYf285_y",
    "BBHYYdcg88qQ",
    "63-FtZQGZ8R5",
    "1fU5UP5AecBv",
    "kHsdhd8Ci1IF"
   ],
   "machine_shape": "hm",
   "name": "TL_Target_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
