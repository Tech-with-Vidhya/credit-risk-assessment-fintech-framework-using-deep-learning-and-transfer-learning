{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TL_Target_Model_2_Clas_Tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HVPa7aXAKMBu",
        "TR8cYEN_IWzm",
        "DukpTXKCKwx5",
        "2Mqyl1FiMTR4",
        "XESQFDm4N6BL",
        "izCdgpFuS53y",
        "iJQRChpX9mPa",
        "4Intnv2F-I34",
        "RX9e7Op9x7y7",
        "6IvWkYf285_y",
        "BBHYYdcg88qQ",
        "63-FtZQGZ8R5",
        "1fU5UP5AecBv",
        "kHsdhd8Ci1IF"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koZ3Cl2vI4yM"
      },
      "source": [
        "# **TRANSFER LEARNING - TARGET MODEL 2 - CLASSIFICATION OF CREDIT DEFAULT - MODIFIED**\n",
        "\n",
        "## **REMOVING LAYERS OF THE SOURCE MODEL TO CREATE THE BASE MODEL FOR TARGET MODEL 2 - CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVPa7aXAKMBu"
      },
      "source": [
        "# **TensorFlow Installation in GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d4nEZI1KSmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9083816c-0b75-4e14-e90a-44dea369b772"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.42.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (12.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.22.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR8cYEN_IWzm"
      },
      "source": [
        "# **1. Importing Python Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFcw1CoZIdgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0226336-ebcf-4127-fa9e-16e1f43bf12e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Import Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DukpTXKCKwx5"
      },
      "source": [
        "# **2. Importing the Target Model Train and Validation Data csv Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhWyCo6HJKPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465c4495-ce30-499c-b77e-fe9f78c246a4"
      },
      "source": [
        "# Importing the Target Model (TM) Train - Input, Output 1 and Output 2 Data\n",
        "\n",
        "\n",
        "tm_train_X = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_train_final_input_X.csv\")\n",
        "\n",
        "tm_train_y_reg = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_train_final_output_y_reg.csv\")\n",
        "\n",
        "tm_train_y_clas = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_train_final_output_y_clas.csv\")\n",
        "\n",
        "print(\"Data Import Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Import Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77nZSw3ZMGaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42383cf-1de4-4664-ec72-32c55050905a"
      },
      "source": [
        "# Importing the Target Model (TM) Validation - Input, Output 1 and Output 2 Data\n",
        "\n",
        "\n",
        "tm_validation_X = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_validation_final_input_X.csv\")\n",
        "\n",
        "tm_validation_y_reg = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_validation_final_output_y_reg.csv\")\n",
        "\n",
        "tm_validation_y_clas = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/target_model_final_data/tm_validation_final_output_y_clas.csv\")\n",
        "\n",
        "print(\"Data Import Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Import Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mqyl1FiMTR4"
      },
      "source": [
        "# **3. Target Model (TM) - Train Data - Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRpsKW7dMbIS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "67b43381-86c2-4224-df76-392471db0a2a"
      },
      "source": [
        "# Target Model (TM) Train Input Data Exploration\n",
        "\n",
        "# Checking the Size of the Target Model (SM) Train Input Data\n",
        "\n",
        "print(tm_train_X.shape)\n",
        "\n",
        "# Sets the pandas dataframe options to display all columns/ rows.\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "# Checking the first 3 column names of the dataset\n",
        "\n",
        "tm_train_X.columns[[0, 1, 2]]\n",
        "\n",
        "# Removing the first index column from the dataset\n",
        "\n",
        "tm_train_X.drop(tm_train_X.columns[0], axis = 1, inplace = True)\n",
        "\n",
        "# Re-checking the size of the dataset\n",
        "\n",
        "print(tm_train_X.shape)\n",
        "\n",
        "# Displying the first 5 data instances\n",
        "\n",
        "tm_train_X.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(419425, 75)\n",
            "(419425, 74)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pub_rec:0</th>\n",
              "      <th>pub_record:non_zero</th>\n",
              "      <th>delinq_2yrs:0</th>\n",
              "      <th>delinq_2yrs:1</th>\n",
              "      <th>delinq_2yrs:greater_than_1</th>\n",
              "      <th>num_tl_120dpd_2m:0</th>\n",
              "      <th>num_tl_120dpd_2m:non_zero</th>\n",
              "      <th>pub_rec_bankruptcies:0</th>\n",
              "      <th>pub_rec_bankruptcies:non_zero</th>\n",
              "      <th>num_tl_90g_dpd_24m:0</th>\n",
              "      <th>num_tl_90g_dpd_24m:non_zero</th>\n",
              "      <th>num_accts_ever_120_pd:0</th>\n",
              "      <th>num_accts_ever_120_pd:_non_zero</th>\n",
              "      <th>acc_now_delinq:0</th>\n",
              "      <th>acc_now_delinq:non_zero</th>\n",
              "      <th>num_tl_30dpd:0</th>\n",
              "      <th>num_tl_30dpd:non_zero</th>\n",
              "      <th>total_rec_late_fee:0</th>\n",
              "      <th>total_rec_late_fee:non_zero</th>\n",
              "      <th>num_rev_tl_bal_gt_0:0</th>\n",
              "      <th>num_rev_tl_bal_gt_0:1_to_5</th>\n",
              "      <th>num_rev_tl_bal_gt_0:greater_than_5</th>\n",
              "      <th>percent_bc_gt_75:0</th>\n",
              "      <th>percent_bc_gt_75:1_to_75</th>\n",
              "      <th>percent_bc_gt_75:greater_than_75</th>\n",
              "      <th>revol_util:0</th>\n",
              "      <th>revol_util:1_to_30</th>\n",
              "      <th>revol_util:31_to_60</th>\n",
              "      <th>revol_util:greater_than_60</th>\n",
              "      <th>il_util:0</th>\n",
              "      <th>il_util:1_to_90</th>\n",
              "      <th>il_util:greater_than_90</th>\n",
              "      <th>max_bal_bc:0_to_2500</th>\n",
              "      <th>max_bal_bc:2501_to_5000</th>\n",
              "      <th>max_bal_bc:5001_to_10000</th>\n",
              "      <th>max_bal_bc:greater_than_10000</th>\n",
              "      <th>mo_sin_old_rev_tl_op:less_than_24months</th>\n",
              "      <th>mo_sin_old_rev_tl_op:25months_to_60months</th>\n",
              "      <th>mo_sin_old_rev_tl_op:greater_than_60months</th>\n",
              "      <th>months_since_earliest_cr_line:less_than_96months</th>\n",
              "      <th>months_since_earliest_cr_line:97months_to_192months</th>\n",
              "      <th>months_since_earliest_cr_line:greater_than_192months</th>\n",
              "      <th>open_acc:less_than_5</th>\n",
              "      <th>open_acc:6_to_8</th>\n",
              "      <th>open_acc:greater_than_8</th>\n",
              "      <th>num_sats:0_to_5</th>\n",
              "      <th>num_sats:6_to_8</th>\n",
              "      <th>num_sats:greater_than_8</th>\n",
              "      <th>mort_acc:0</th>\n",
              "      <th>mort_acc:1_to_3</th>\n",
              "      <th>mort_acc:greater_than_3</th>\n",
              "      <th>inq_last_6mths:0</th>\n",
              "      <th>inq_last_6mths:1</th>\n",
              "      <th>inq_last_6mths:greater_than_1</th>\n",
              "      <th>open_il_12m:_0</th>\n",
              "      <th>open_il_12m:_1</th>\n",
              "      <th>open_il_12m:greater_than_1</th>\n",
              "      <th>num_tl_op_past_12m:0</th>\n",
              "      <th>num_tl_op_past_12m:1</th>\n",
              "      <th>num_tl_op_past_12m:2</th>\n",
              "      <th>num_tl_op_past_12m:3</th>\n",
              "      <th>num_tl_op_past_12m:greater_than_3</th>\n",
              "      <th>annual_inc:0_to_25000</th>\n",
              "      <th>annual_inc:25001_to_50000</th>\n",
              "      <th>annual_inc:50001_to_75000</th>\n",
              "      <th>annual_inc:75001_to_100000</th>\n",
              "      <th>annual_inc:greater_than_100001</th>\n",
              "      <th>dti:0_to_36</th>\n",
              "      <th>dti:greater_than_36</th>\n",
              "      <th>emp_length_int:less_than_0</th>\n",
              "      <th>emp_length_int:1_to_2</th>\n",
              "      <th>emp_length_int:3_to_5</th>\n",
              "      <th>emp_length_int:6_to_9</th>\n",
              "      <th>emp_length_int:greater_than_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pub_rec:0  pub_record:non_zero  delinq_2yrs:0  delinq_2yrs:1  \\\n",
              "0          1                    0              1              0   \n",
              "1          1                    0              1              0   \n",
              "2          1                    0              1              0   \n",
              "3          1                    0              1              0   \n",
              "4          1                    0              0              1   \n",
              "\n",
              "   delinq_2yrs:greater_than_1  num_tl_120dpd_2m:0  num_tl_120dpd_2m:non_zero  \\\n",
              "0                           0                   1                          0   \n",
              "1                           0                   1                          0   \n",
              "2                           0                   1                          0   \n",
              "3                           0                   1                          0   \n",
              "4                           0                   1                          0   \n",
              "\n",
              "   pub_rec_bankruptcies:0  pub_rec_bankruptcies:non_zero  \\\n",
              "0                       1                              0   \n",
              "1                       1                              0   \n",
              "2                       1                              0   \n",
              "3                       1                              0   \n",
              "4                       1                              0   \n",
              "\n",
              "   num_tl_90g_dpd_24m:0  num_tl_90g_dpd_24m:non_zero  num_accts_ever_120_pd:0  \\\n",
              "0                     1                            0                        1   \n",
              "1                     1                            0                        1   \n",
              "2                     1                            0                        1   \n",
              "3                     1                            0                        1   \n",
              "4                     1                            0                        1   \n",
              "\n",
              "   num_accts_ever_120_pd:_non_zero  acc_now_delinq:0  acc_now_delinq:non_zero  \\\n",
              "0                                0                 1                        0   \n",
              "1                                0                 1                        0   \n",
              "2                                0                 1                        0   \n",
              "3                                0                 1                        0   \n",
              "4                                0                 1                        0   \n",
              "\n",
              "   num_tl_30dpd:0  num_tl_30dpd:non_zero  total_rec_late_fee:0  \\\n",
              "0               1                      0                     1   \n",
              "1               1                      0                     1   \n",
              "2               1                      0                     1   \n",
              "3               1                      0                     1   \n",
              "4               1                      0                     0   \n",
              "\n",
              "   total_rec_late_fee:non_zero  num_rev_tl_bal_gt_0:0  \\\n",
              "0                            0                      0   \n",
              "1                            0                      0   \n",
              "2                            0                      0   \n",
              "3                            0                      0   \n",
              "4                            1                      0   \n",
              "\n",
              "   num_rev_tl_bal_gt_0:1_to_5  num_rev_tl_bal_gt_0:greater_than_5  \\\n",
              "0                           1                                   0   \n",
              "1                           1                                   0   \n",
              "2                           1                                   0   \n",
              "3                           1                                   0   \n",
              "4                           1                                   0   \n",
              "\n",
              "   percent_bc_gt_75:0  percent_bc_gt_75:1_to_75  \\\n",
              "0                   0                         0   \n",
              "1                   0                         1   \n",
              "2                   0                         1   \n",
              "3                   1                         0   \n",
              "4                   0                         0   \n",
              "\n",
              "   percent_bc_gt_75:greater_than_75  revol_util:0  revol_util:1_to_30  \\\n",
              "0                                 1             0                   0   \n",
              "1                                 0             0                   1   \n",
              "2                                 0             0                   0   \n",
              "3                                 0             0                   1   \n",
              "4                                 1             0                   0   \n",
              "\n",
              "   revol_util:31_to_60  revol_util:greater_than_60  il_util:0  \\\n",
              "0                    0                           1          0   \n",
              "1                    0                           0          0   \n",
              "2                    1                           0          0   \n",
              "3                    0                           0          1   \n",
              "4                    0                           1          0   \n",
              "\n",
              "   il_util:1_to_90  il_util:greater_than_90  max_bal_bc:0_to_2500  \\\n",
              "0                1                        0                     0   \n",
              "1                1                        0                     0   \n",
              "2                1                        0                     1   \n",
              "3                0                        0                     1   \n",
              "4                1                        0                     0   \n",
              "\n",
              "   max_bal_bc:2501_to_5000  max_bal_bc:5001_to_10000  \\\n",
              "0                        1                         0   \n",
              "1                        0                         1   \n",
              "2                        0                         0   \n",
              "3                        0                         0   \n",
              "4                        1                         0   \n",
              "\n",
              "   max_bal_bc:greater_than_10000  mo_sin_old_rev_tl_op:less_than_24months  \\\n",
              "0                              0                                        0   \n",
              "1                              0                                        0   \n",
              "2                              0                                        0   \n",
              "3                              0                                        0   \n",
              "4                              0                                        0   \n",
              "\n",
              "   mo_sin_old_rev_tl_op:25months_to_60months  \\\n",
              "0                                          0   \n",
              "1                                          0   \n",
              "2                                          0   \n",
              "3                                          0   \n",
              "4                                          0   \n",
              "\n",
              "   mo_sin_old_rev_tl_op:greater_than_60months  \\\n",
              "0                                           1   \n",
              "1                                           1   \n",
              "2                                           1   \n",
              "3                                           1   \n",
              "4                                           1   \n",
              "\n",
              "   months_since_earliest_cr_line:less_than_96months  \\\n",
              "0                                                 0   \n",
              "1                                                 0   \n",
              "2                                                 0   \n",
              "3                                                 0   \n",
              "4                                                 0   \n",
              "\n",
              "   months_since_earliest_cr_line:97months_to_192months  \\\n",
              "0                                                  1     \n",
              "1                                                  0     \n",
              "2                                                  0     \n",
              "3                                                  1     \n",
              "4                                                  0     \n",
              "\n",
              "   months_since_earliest_cr_line:greater_than_192months  open_acc:less_than_5  \\\n",
              "0                                                  0                        0   \n",
              "1                                                  1                        0   \n",
              "2                                                  1                        1   \n",
              "3                                                  0                        0   \n",
              "4                                                  1                        1   \n",
              "\n",
              "   open_acc:6_to_8  open_acc:greater_than_8  num_sats:0_to_5  num_sats:6_to_8  \\\n",
              "0                1                        0                0                1   \n",
              "1                0                        1                0                0   \n",
              "2                0                        0                1                0   \n",
              "3                0                        1                0                0   \n",
              "4                0                        0                1                0   \n",
              "\n",
              "   num_sats:greater_than_8  mort_acc:0  mort_acc:1_to_3  \\\n",
              "0                        0           0                1   \n",
              "1                        1           1                0   \n",
              "2                        0           1                0   \n",
              "3                        1           0                1   \n",
              "4                        0           1                0   \n",
              "\n",
              "   mort_acc:greater_than_3  inq_last_6mths:0  inq_last_6mths:1  \\\n",
              "0                        0                 1                 0   \n",
              "1                        0                 0                 0   \n",
              "2                        0                 1                 0   \n",
              "3                        0                 1                 0   \n",
              "4                        0                 1                 0   \n",
              "\n",
              "   inq_last_6mths:greater_than_1  open_il_12m:_0  open_il_12m:_1  \\\n",
              "0                              0               1               0   \n",
              "1                              1               1               0   \n",
              "2                              0               1               0   \n",
              "3                              0               0               1   \n",
              "4                              0               1               0   \n",
              "\n",
              "   open_il_12m:greater_than_1  num_tl_op_past_12m:0  num_tl_op_past_12m:1  \\\n",
              "0                           0                     0                     0   \n",
              "1                           0                     0                     0   \n",
              "2                           0                     1                     0   \n",
              "3                           0                     0                     0   \n",
              "4                           0                     1                     0   \n",
              "\n",
              "   num_tl_op_past_12m:2  num_tl_op_past_12m:3  \\\n",
              "0                     1                     0   \n",
              "1                     0                     0   \n",
              "2                     0                     0   \n",
              "3                     0                     0   \n",
              "4                     0                     0   \n",
              "\n",
              "   num_tl_op_past_12m:greater_than_3  annual_inc:0_to_25000  \\\n",
              "0                                  0                      0   \n",
              "1                                  1                      0   \n",
              "2                                  0                      1   \n",
              "3                                  1                      0   \n",
              "4                                  0                      0   \n",
              "\n",
              "   annual_inc:25001_to_50000  annual_inc:50001_to_75000  \\\n",
              "0                          0                          0   \n",
              "1                          0                          0   \n",
              "2                          0                          0   \n",
              "3                          1                          0   \n",
              "4                          0                          1   \n",
              "\n",
              "   annual_inc:75001_to_100000  annual_inc:greater_than_100001  dti:0_to_36  \\\n",
              "0                           0                               1            1   \n",
              "1                           1                               0            1   \n",
              "2                           0                               0            1   \n",
              "3                           0                               0            1   \n",
              "4                           0                               0            1   \n",
              "\n",
              "   dti:greater_than_36  emp_length_int:less_than_0  emp_length_int:1_to_2  \\\n",
              "0                    0                           0                      0   \n",
              "1                    0                           0                      0   \n",
              "2                    0                           0                      1   \n",
              "3                    0                           0                      0   \n",
              "4                    0                           0                      0   \n",
              "\n",
              "   emp_length_int:3_to_5  emp_length_int:6_to_9  emp_length_int:greater_than_9  \n",
              "0                      0                      0                              1  \n",
              "1                      0                      0                              1  \n",
              "2                      0                      0                              0  \n",
              "3                      1                      0                              0  \n",
              "4                      0                      0                              1  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zORYWNGNcwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "51957f01-715e-4774-aee2-a464e20ff89b"
      },
      "source": [
        "# Target Model (TM) Train Regression Output Data Exploration\n",
        "\n",
        "# Checking the Size of the Target Model (SM) Train Input Data\n",
        "\n",
        "print(tm_train_y_reg.shape)\n",
        "\n",
        "# Sets the pandas dataframe options to display all columns/ rows.\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "# Checking the first 3 column names of the dataset\n",
        "\n",
        "tm_train_y_reg.columns[[0, 1]]\n",
        "\n",
        "# Removing the first index column from the dataset\n",
        "\n",
        "tm_train_y_reg.drop(tm_train_y_reg.columns[0], axis = 1, inplace = True)\n",
        "\n",
        "# Re-checking the size of the dataset\n",
        "\n",
        "print(tm_train_y_reg.shape)\n",
        "\n",
        "# Displying the first 5 data instances\n",
        "\n",
        "tm_train_y_reg.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(419425, 2)\n",
            "(419425, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   credit_score\n",
              "0           672\n",
              "1           537\n",
              "2           672\n",
              "3           537\n",
              "4           687"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5G7TmMrNc49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "de64baf0-a6f4-42a4-b315-572bb3b1c225"
      },
      "source": [
        "# Target Model (TM) Train Classification Output Data Exploration\n",
        "\n",
        "# Checking the Size of the Target Model (SM) Train Input Data\n",
        "\n",
        "print(tm_train_y_clas.shape)\n",
        "\n",
        "# Sets the pandas dataframe options to display all columns/ rows.\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "# Checking the first 3 column names of the dataset\n",
        "\n",
        "tm_train_y_clas.columns[[0, 1]]\n",
        "\n",
        "# Removing the first index column from the dataset\n",
        "\n",
        "tm_train_y_clas.drop(tm_train_y_clas.columns[0], axis = 1, inplace = True)\n",
        "\n",
        "# Re-checking the size of the dataset\n",
        "\n",
        "print(tm_train_y_clas.shape)\n",
        "\n",
        "# Displaying the Class 0 (Credit Non-Default) and Class 1 (Credit Default) Distribution\n",
        "\n",
        "print(tm_train_y_clas.value_counts())\n",
        "\n",
        "# Displying the first 5 data instances\n",
        "\n",
        "tm_train_y_clas.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(419425, 2)\n",
            "(419425, 1)\n",
            "credit_default\n",
            "0                 374200\n",
            "1                  45225\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit_default</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   credit_default\n",
              "0               0\n",
              "1               1\n",
              "2               0\n",
              "3               1\n",
              "4               1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESQFDm4N6BL"
      },
      "source": [
        "# **4. Target Model (TM) - Validation Data - Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl4otQo9N6BW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "f3775885-e83e-4a8e-fe1c-32a889a8b41d"
      },
      "source": [
        "# Target Model (TM) Validation Input Data Exploration\n",
        "\n",
        "# Checking the Size of the Target Model (SM) Train Input Data\n",
        "\n",
        "print(tm_validation_X.shape)\n",
        "\n",
        "# Sets the pandas dataframe options to display all columns/ rows.\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "# Checking the first 3 column names of the dataset\n",
        "\n",
        "tm_validation_X.columns[[0, 1, 2]]\n",
        "\n",
        "# Removing the first index column from the dataset\n",
        "\n",
        "tm_validation_X.drop(tm_validation_X.columns[0], axis = 1, inplace = True)\n",
        "\n",
        "# Re-checking the size of the dataset\n",
        "\n",
        "print(tm_validation_X.shape)\n",
        "\n",
        "# Displying the first 5 data instances\n",
        "\n",
        "tm_validation_X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(83885, 75)\n",
            "(83885, 74)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pub_rec:0</th>\n",
              "      <th>pub_record:non_zero</th>\n",
              "      <th>delinq_2yrs:0</th>\n",
              "      <th>delinq_2yrs:1</th>\n",
              "      <th>delinq_2yrs:greater_than_1</th>\n",
              "      <th>num_tl_120dpd_2m:0</th>\n",
              "      <th>num_tl_120dpd_2m:non_zero</th>\n",
              "      <th>pub_rec_bankruptcies:0</th>\n",
              "      <th>pub_rec_bankruptcies:non_zero</th>\n",
              "      <th>num_tl_90g_dpd_24m:0</th>\n",
              "      <th>num_tl_90g_dpd_24m:non_zero</th>\n",
              "      <th>num_accts_ever_120_pd:0</th>\n",
              "      <th>num_accts_ever_120_pd:_non_zero</th>\n",
              "      <th>acc_now_delinq:0</th>\n",
              "      <th>acc_now_delinq:non_zero</th>\n",
              "      <th>num_tl_30dpd:0</th>\n",
              "      <th>num_tl_30dpd:non_zero</th>\n",
              "      <th>total_rec_late_fee:0</th>\n",
              "      <th>total_rec_late_fee:non_zero</th>\n",
              "      <th>num_rev_tl_bal_gt_0:0</th>\n",
              "      <th>num_rev_tl_bal_gt_0:1_to_5</th>\n",
              "      <th>num_rev_tl_bal_gt_0:greater_than_5</th>\n",
              "      <th>percent_bc_gt_75:0</th>\n",
              "      <th>percent_bc_gt_75:1_to_75</th>\n",
              "      <th>percent_bc_gt_75:greater_than_75</th>\n",
              "      <th>revol_util:0_to_15</th>\n",
              "      <th>revol_util:16_to_30</th>\n",
              "      <th>revol_util:31_to_60</th>\n",
              "      <th>revol_util:greater_than_60</th>\n",
              "      <th>il_util:0</th>\n",
              "      <th>il_util:1_to_100</th>\n",
              "      <th>il_util:greater_than_100</th>\n",
              "      <th>max_bal_bc:0_to_2500</th>\n",
              "      <th>max_bal_bc:2501_to_5000</th>\n",
              "      <th>max_bal_bc:5001_to_10000</th>\n",
              "      <th>max_bal_bc:greater_than_10000</th>\n",
              "      <th>mo_sin_old_rev_tl_op:less_than_24months</th>\n",
              "      <th>mo_sin_old_rev_tl_op:25months_to_60months</th>\n",
              "      <th>mo_sin_old_rev_tl_op:greater_than_60months</th>\n",
              "      <th>months_since_earliest_cr_line:less_than_120months</th>\n",
              "      <th>months_since_earliest_cr_line:121months_to_240months</th>\n",
              "      <th>months_since_earliest_cr_line:greater_than_240months</th>\n",
              "      <th>open_acc:less_than_5</th>\n",
              "      <th>open_acc:6_to_8</th>\n",
              "      <th>open_acc:greater_than_8</th>\n",
              "      <th>num_sats:0_to_5</th>\n",
              "      <th>num_sats:6_to_8</th>\n",
              "      <th>num_sats:greater_than_8</th>\n",
              "      <th>mort_acc:0</th>\n",
              "      <th>mort_acc:1_to_3</th>\n",
              "      <th>mort_acc:greater_than_3</th>\n",
              "      <th>inq_last_6mths:0</th>\n",
              "      <th>inq_last_6mths:1</th>\n",
              "      <th>inq_last_6mths:greater_than_1</th>\n",
              "      <th>open_il_12m:_0</th>\n",
              "      <th>open_il_12m:_1</th>\n",
              "      <th>open_il_12m:greater_than_1</th>\n",
              "      <th>num_tl_op_past_12m:0</th>\n",
              "      <th>num_tl_op_past_12m:1</th>\n",
              "      <th>num_tl_op_past_12m:2</th>\n",
              "      <th>num_tl_op_past_12m:3</th>\n",
              "      <th>num_tl_op_past_12m:greater_than_3</th>\n",
              "      <th>annual_inc:0_to_25000</th>\n",
              "      <th>annual_inc:25001_to_50000</th>\n",
              "      <th>annual_inc:50001_to_75000</th>\n",
              "      <th>annual_inc:75001_to_100000</th>\n",
              "      <th>annual_inc:greater_than_100001</th>\n",
              "      <th>dti:0_to_36</th>\n",
              "      <th>dti:greater_than_36</th>\n",
              "      <th>emp_length_int:less_than_0</th>\n",
              "      <th>emp_length_int:1_to_2</th>\n",
              "      <th>emp_length_int:3_to_5</th>\n",
              "      <th>emp_length_int:6_to_9</th>\n",
              "      <th>emp_length_int:greater_than_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pub_rec:0  pub_record:non_zero  delinq_2yrs:0  delinq_2yrs:1  \\\n",
              "0          0                    1              1              0   \n",
              "1          1                    0              1              0   \n",
              "2          1                    0              1              0   \n",
              "3          1                    0              1              0   \n",
              "4          1                    0              1              0   \n",
              "\n",
              "   delinq_2yrs:greater_than_1  num_tl_120dpd_2m:0  num_tl_120dpd_2m:non_zero  \\\n",
              "0                           0                   1                          0   \n",
              "1                           0                   1                          0   \n",
              "2                           0                   1                          0   \n",
              "3                           0                   1                          0   \n",
              "4                           0                   1                          0   \n",
              "\n",
              "   pub_rec_bankruptcies:0  pub_rec_bankruptcies:non_zero  \\\n",
              "0                       1                              0   \n",
              "1                       1                              0   \n",
              "2                       1                              0   \n",
              "3                       1                              0   \n",
              "4                       1                              0   \n",
              "\n",
              "   num_tl_90g_dpd_24m:0  num_tl_90g_dpd_24m:non_zero  num_accts_ever_120_pd:0  \\\n",
              "0                     1                            0                        0   \n",
              "1                     1                            0                        0   \n",
              "2                     1                            0                        1   \n",
              "3                     1                            0                        1   \n",
              "4                     1                            0                        0   \n",
              "\n",
              "   num_accts_ever_120_pd:_non_zero  acc_now_delinq:0  acc_now_delinq:non_zero  \\\n",
              "0                                1                 1                        0   \n",
              "1                                1                 1                        0   \n",
              "2                                0                 1                        0   \n",
              "3                                0                 1                        0   \n",
              "4                                1                 1                        0   \n",
              "\n",
              "   num_tl_30dpd:0  num_tl_30dpd:non_zero  total_rec_late_fee:0  \\\n",
              "0               1                      0                     1   \n",
              "1               1                      0                     1   \n",
              "2               1                      0                     1   \n",
              "3               1                      0                     1   \n",
              "4               1                      0                     1   \n",
              "\n",
              "   total_rec_late_fee:non_zero  num_rev_tl_bal_gt_0:0  \\\n",
              "0                            0                      0   \n",
              "1                            0                      0   \n",
              "2                            0                      0   \n",
              "3                            0                      0   \n",
              "4                            0                      0   \n",
              "\n",
              "   num_rev_tl_bal_gt_0:1_to_5  num_rev_tl_bal_gt_0:greater_than_5  \\\n",
              "0                           0                                   1   \n",
              "1                           1                                   0   \n",
              "2                           1                                   0   \n",
              "3                           0                                   1   \n",
              "4                           1                                   0   \n",
              "\n",
              "   percent_bc_gt_75:0  percent_bc_gt_75:1_to_75  \\\n",
              "0                   0                         1   \n",
              "1                   0                         0   \n",
              "2                   0                         0   \n",
              "3                   1                         0   \n",
              "4                   0                         0   \n",
              "\n",
              "   percent_bc_gt_75:greater_than_75  revol_util:0_to_15  revol_util:16_to_30  \\\n",
              "0                                 0                   0                    0   \n",
              "1                                 1                   0                    0   \n",
              "2                                 1                   1                    0   \n",
              "3                                 0                   0                    0   \n",
              "4                                 1                   0                    0   \n",
              "\n",
              "   revol_util:31_to_60  revol_util:greater_than_60  il_util:0  \\\n",
              "0                    1                           0          0   \n",
              "1                    0                           1          0   \n",
              "2                    0                           0          0   \n",
              "3                    1                           0          0   \n",
              "4                    0                           1          1   \n",
              "\n",
              "   il_util:1_to_100  il_util:greater_than_100  max_bal_bc:0_to_2500  \\\n",
              "0                 1                         0                     0   \n",
              "1                 1                         0                     1   \n",
              "2                 1                         0                     1   \n",
              "3                 1                         0                     0   \n",
              "4                 0                         0                     0   \n",
              "\n",
              "   max_bal_bc:2501_to_5000  max_bal_bc:5001_to_10000  \\\n",
              "0                        0                         0   \n",
              "1                        0                         0   \n",
              "2                        0                         0   \n",
              "3                        0                         0   \n",
              "4                        0                         1   \n",
              "\n",
              "   max_bal_bc:greater_than_10000  mo_sin_old_rev_tl_op:less_than_24months  \\\n",
              "0                              1                                        0   \n",
              "1                              0                                        0   \n",
              "2                              0                                        0   \n",
              "3                              1                                        0   \n",
              "4                              0                                        0   \n",
              "\n",
              "   mo_sin_old_rev_tl_op:25months_to_60months  \\\n",
              "0                                          0   \n",
              "1                                          0   \n",
              "2                                          1   \n",
              "3                                          0   \n",
              "4                                          0   \n",
              "\n",
              "   mo_sin_old_rev_tl_op:greater_than_60months  \\\n",
              "0                                           1   \n",
              "1                                           1   \n",
              "2                                           0   \n",
              "3                                           1   \n",
              "4                                           1   \n",
              "\n",
              "   months_since_earliest_cr_line:less_than_120months  \\\n",
              "0                                                  0   \n",
              "1                                                  0   \n",
              "2                                                  0   \n",
              "3                                                  0   \n",
              "4                                                  0   \n",
              "\n",
              "   months_since_earliest_cr_line:121months_to_240months  \\\n",
              "0                                                  0      \n",
              "1                                                  1      \n",
              "2                                                  1      \n",
              "3                                                  1      \n",
              "4                                                  1      \n",
              "\n",
              "   months_since_earliest_cr_line:greater_than_240months  open_acc:less_than_5  \\\n",
              "0                                                  1                        0   \n",
              "1                                                  0                        0   \n",
              "2                                                  0                        0   \n",
              "3                                                  0                        0   \n",
              "4                                                  0                        1   \n",
              "\n",
              "   open_acc:6_to_8  open_acc:greater_than_8  num_sats:0_to_5  num_sats:6_to_8  \\\n",
              "0                0                        1                0                0   \n",
              "1                1                        0                0                1   \n",
              "2                1                        0                0                1   \n",
              "3                0                        1                0                0   \n",
              "4                0                        0                1                0   \n",
              "\n",
              "   num_sats:greater_than_8  mort_acc:0  mort_acc:1_to_3  \\\n",
              "0                        1           0                0   \n",
              "1                        0           0                1   \n",
              "2                        0           0                1   \n",
              "3                        1           0                1   \n",
              "4                        0           0                1   \n",
              "\n",
              "   mort_acc:greater_than_3  inq_last_6mths:0  inq_last_6mths:1  \\\n",
              "0                        1                 0                 1   \n",
              "1                        0                 1                 0   \n",
              "2                        0                 1                 0   \n",
              "3                        0                 0                 1   \n",
              "4                        0                 1                 0   \n",
              "\n",
              "   inq_last_6mths:greater_than_1  open_il_12m:_0  open_il_12m:_1  \\\n",
              "0                              0               1               0   \n",
              "1                              0               1               0   \n",
              "2                              0               0               0   \n",
              "3                              0               0               0   \n",
              "4                              0               1               0   \n",
              "\n",
              "   open_il_12m:greater_than_1  num_tl_op_past_12m:0  num_tl_op_past_12m:1  \\\n",
              "0                           0                     1                     0   \n",
              "1                           0                     1                     0   \n",
              "2                           1                     0                     0   \n",
              "3                           1                     0                     0   \n",
              "4                           0                     1                     0   \n",
              "\n",
              "   num_tl_op_past_12m:2  num_tl_op_past_12m:3  \\\n",
              "0                     0                     0   \n",
              "1                     0                     0   \n",
              "2                     0                     1   \n",
              "3                     0                     0   \n",
              "4                     0                     0   \n",
              "\n",
              "   num_tl_op_past_12m:greater_than_3  annual_inc:0_to_25000  \\\n",
              "0                                  0                      0   \n",
              "1                                  0                      0   \n",
              "2                                  0                      0   \n",
              "3                                  1                      0   \n",
              "4                                  0                      0   \n",
              "\n",
              "   annual_inc:25001_to_50000  annual_inc:50001_to_75000  \\\n",
              "0                          0                          0   \n",
              "1                          0                          0   \n",
              "2                          0                          1   \n",
              "3                          0                          0   \n",
              "4                          0                          1   \n",
              "\n",
              "   annual_inc:75001_to_100000  annual_inc:greater_than_100001  dti:0_to_36  \\\n",
              "0                           0                               1            1   \n",
              "1                           1                               0            1   \n",
              "2                           0                               0            1   \n",
              "3                           1                               0            1   \n",
              "4                           0                               0            1   \n",
              "\n",
              "   dti:greater_than_36  emp_length_int:less_than_0  emp_length_int:1_to_2  \\\n",
              "0                    0                           0                      0   \n",
              "1                    0                           0                      0   \n",
              "2                    0                           0                      1   \n",
              "3                    0                           0                      0   \n",
              "4                    0                           0                      0   \n",
              "\n",
              "   emp_length_int:3_to_5  emp_length_int:6_to_9  emp_length_int:greater_than_9  \n",
              "0                      0                      0                              1  \n",
              "1                      1                      0                              0  \n",
              "2                      0                      0                              0  \n",
              "3                      0                      0                              1  \n",
              "4                      1                      0                              0  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NDwHIJ2N6BX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "45a14a8f-e11a-48c4-ddf2-5a78aa5c6227"
      },
      "source": [
        "# Target Model (TM) Validation Regression Output Data Exploration\n",
        "\n",
        "# Checking the Size of the Target Model (SM) Train Input Data\n",
        "\n",
        "print(tm_validation_y_reg.shape)\n",
        "\n",
        "# Sets the pandas dataframe options to display all columns/ rows.\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "# Checking the first 3 column names of the dataset\n",
        "\n",
        "tm_validation_y_reg.columns[[0, 1]]\n",
        "\n",
        "# Removing the first index column from the dataset\n",
        "\n",
        "tm_validation_y_reg.drop(tm_validation_y_reg.columns[0], axis = 1, inplace = True)\n",
        "\n",
        "# Re-checking the size of the dataset\n",
        "\n",
        "print(tm_validation_y_reg.shape)\n",
        "\n",
        "# Displying the first 5 data instances\n",
        "\n",
        "tm_validation_y_reg.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(83885, 2)\n",
            "(83885, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   credit_score\n",
              "0           757\n",
              "1           722\n",
              "2           672\n",
              "3           702\n",
              "4           727"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-V5QqOYN6BY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "8cb0493e-6947-4fa3-f2b6-dadef7b6579f"
      },
      "source": [
        "# Target Model (TM) Validation Classification Output Data Exploration\n",
        "\n",
        "# Checking the Size of the Target Model (SM) Train Input Data\n",
        "\n",
        "print(tm_validation_y_clas.shape)\n",
        "\n",
        "# Sets the pandas dataframe options to display all columns/ rows.\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "# Checking the first 3 column names of the dataset\n",
        "\n",
        "tm_validation_y_clas.columns[[0, 1]]\n",
        "\n",
        "# Removing the first index column from the dataset\n",
        "\n",
        "tm_validation_y_clas.drop(tm_validation_y_clas.columns[0], axis = 1, inplace = True)\n",
        "\n",
        "# Re-checking the size of the dataset\n",
        "\n",
        "print(tm_validation_y_clas.shape)\n",
        "\n",
        "# Displying the first 5 data instances\n",
        "\n",
        "tm_validation_y_clas.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(83885, 2)\n",
            "(83885, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit_default</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   credit_default\n",
              "0               0\n",
              "1               0\n",
              "2               0\n",
              "3               0\n",
              "4               0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izCdgpFuS53y"
      },
      "source": [
        "# **5. Importing the Base Model (Source Model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apbrLKhpTB_7"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Loading an Existing Trained Model\n",
        "\n",
        "source_model_path = \"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/models/source_model/1_sm_adam_relu_sigmoid_4_0.001_inputsize.h5\"\n",
        "\n",
        "source_model = load_model(source_model_path)\n",
        "\n",
        "print(\"Pre-Trained Source Model Loaded Successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2eoE5JTUTHm"
      },
      "source": [
        "# Verifying the Summary of the Existing Pre-Trained Source Model\n",
        "\n",
        "source_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJQRChpX9mPa"
      },
      "source": [
        "# **6. Transfer Learning of the Source Model into the Target Model : Configurations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16G_SSMmyO-S"
      },
      "source": [
        "# Freezing the Source Model to avoid updating the weights during the Target Model Training\n",
        "\n",
        "source_model.trainable = False\n",
        "\n",
        "print(\"Execution Completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26p2WoYIv4ML"
      },
      "source": [
        "# Retaining only the Input Layer and the First Hidden Layer, Removed 2nd, 3rd, 4th Hidden Layers and Removed Output Layer from the Source Model and Creating a Base Model\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "base_model = Model(inputs=source_model.input, outputs=source_model.layers[0].output)\n",
        "\n",
        "print(\"Execution Completed\")                                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQjiyG-YttW7"
      },
      "source": [
        "# Verifying the Summary of the Base Model after removing the Output (Last) Layer to use the Source Model as Feature Extractor\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZGGo3vi07WF"
      },
      "source": [
        "**As we can see; only the input layer and the first hidden layer are retained in the base model and rest of the other 3 hidden layers along with the output layer are removed. This will serve the purpose of re-using the source model with modifications for feature extraction purposes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Intnv2F-I34"
      },
      "source": [
        "# **7. Transfer Learning of the Source Model into the Target Model : Feature Extraction - Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTqmSzMw-I4C"
      },
      "source": [
        "# Defining the Target Model from the Pre-Trained Source Model\n",
        "\n",
        "'''\n",
        "inputs = base_model\n",
        "output_reg = keras.layers.Dense(1, activation='linear')\n",
        "output_clas = keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "outputs = [output_reg, output_clas]\n",
        "\n",
        "target_model = tf.keras.Model(inputs=inputs, outputs=output_reg)\n",
        "'''\n",
        "\n",
        "target_model_2 = tf.keras.Sequential([\n",
        "                                    base_model,\n",
        "                                    #keras.layers.Dense(1, activation='linear')\n",
        "                                    #keras.layers.Dense(1)\n",
        "                                    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compiling the Model\n",
        "\n",
        "base_lr_2 = 0.001\n",
        "\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=base_lr_2)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = 'accuracy'\n",
        "\n",
        "target_model_2.compile(\n",
        "    optimizer=optim,\n",
        "    loss=loss,\n",
        "    metrics=[metrics])\n",
        "\n",
        "print(\"Execution Completed\")                                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmkftcxt-I4D"
      },
      "source": [
        "# Verifying the Summary of the Target Model (with Pre-Trained Source Model as Feature Extractor)\n",
        "\n",
        "target_model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua0vli0N-I4D"
      },
      "source": [
        "len(target_model_2.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX9e7Op9x7y7"
      },
      "source": [
        "# **!!!!!Importing Target Model Trained until Previous Epochs Steps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_wXAHWdyLgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb632689-d893-455f-9873-f0316ab96a85"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Loading the Target Model 1 to Continue Training\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/models/target_model/tm_model_2_clas_fe_mod_retrain_2_1000_final/tm_model_2_clas_fe_mod_retrain_2_1000_final.h5\"\n",
        "\n",
        "target_model_2 = load_model(model_path)\n",
        "\n",
        "print(\"Target Model Loaded Successfully\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Model Loaded Successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvJCTI1n9gE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a539bb69-9268-4f7b-ad5e-fd54c73aa452"
      },
      "source": [
        "# Verifying the Summary of the Existing Pre-Trained Model\n",
        "\n",
        "target_model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model_2 (Functional)        (None, 74)                5550      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 75        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,625\n",
            "Trainable params: 75\n",
            "Non-trainable params: 5,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q9nE_CVzVEP"
      },
      "source": [
        "**As we can see; pre-trained traget model 1 is loaded to continue with further training.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5f178gr81l8"
      },
      "source": [
        "# **8. Target Model Training - With Source Model as Feature Extractor and Customised Target Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqZLqNZS81mK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a89124-6e44-431a-e24e-4152907ca47c"
      },
      "source": [
        "# Target Model Training - With Source Model as Feature Extractor with Modifications for Target Model 2\n",
        "\n",
        "# Training Configurations\n",
        "\n",
        "input_data_size = tm_train_X.shape[0]\n",
        "\n",
        "epochs_2 = 6000\n",
        "batch_size_2 = input_data_size\n",
        "\n",
        "# Tensorboard Configuration\n",
        "\n",
        "log_dir_path = \"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/logs/tm_model_2_clas_fe_mod_retrain_2_final/\"\n",
        "\n",
        "tb_callback_tm_2 = tf.keras.callbacks.TensorBoard(log_dir=log_dir_path, \n",
        "                                                histogram_freq=1)\n",
        "\n",
        "\n",
        "print(\"Model Training Started.....\")\n",
        "\n",
        "history = target_model_2.fit(tm_train_X, tm_train_y_clas,\n",
        "                             validation_data=(tm_validation_X, tm_validation_y_clas),\n",
        "                             epochs=epochs_2,\n",
        "                             batch_size=batch_size_2, \n",
        "                             callbacks=[tb_callback_tm_2])\n",
        "\n",
        "print(\"Model Training Completed.....\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3502/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3503/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3504/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3505/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3506/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3507/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3508/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3509/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3510/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3511/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3512/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3513/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3514/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3515/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3516/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3517/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3518/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3519/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3520/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3521/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3522/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3523/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3524/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3525/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3526/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3527/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3528/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3529/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3530/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3531/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3532/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3533/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3534/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3535/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3536/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3537/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3538/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3539/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3540/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3541/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3542/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3543/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3544/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3545/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3546/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3547/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3548/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3549/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3550/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3551/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3552/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3553/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3554/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3555/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3556/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3557/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3558/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3559/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3560/6000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3561/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3562/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3563/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3564/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3565/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3566/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3567/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3568/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3569/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3570/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3571/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3572/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3573/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3574/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3575/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3576/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3577/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3578/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3579/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3580/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3581/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3582/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3583/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3584/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3585/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3586/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3587/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3588/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3589/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3590/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3591/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3592/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3593/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3594/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3595/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3596/6000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3597/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3598/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3599/6000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3600/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3601/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3602/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3603/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3604/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3605/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3606/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3607/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3608/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3609/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3610/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3611/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3612/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3613/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3614/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3615/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3616/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3617/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3618/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3619/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3620/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3621/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3622/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3623/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3624/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3625/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3626/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3627/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3628/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3629/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3630/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3631/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3632/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3633/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3634/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3635/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3636/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3637/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3638/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3639/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3640/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3641/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3642/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3643/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3644/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3645/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3646/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3647/6000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3648/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3649/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3650/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3651/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3652/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3653/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3654/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3655/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3656/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3657/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3658/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3659/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3660/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3661/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3662/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3663/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3664/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3665/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3666/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3667/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3668/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3669/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3670/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3671/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3672/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3673/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3674/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3675/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3676/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3677/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3678/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3679/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3680/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3681/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3682/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3683/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3684/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3685/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3686/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3687/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3688/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3689/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3690/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3691/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3692/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3693/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3694/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3695/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3696/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3697/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3698/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3699/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3700/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3701/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3702/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3703/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3704/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3705/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3706/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3707/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3708/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3709/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3710/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3711/6000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3712/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3713/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3714/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3715/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3716/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3717/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3718/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3719/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3720/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3721/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3722/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3723/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3724/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3725/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3726/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3727/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3728/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3729/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3730/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3731/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3732/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3733/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3734/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3735/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3736/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3737/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3738/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3739/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3740/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3741/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3742/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3743/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3744/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3745/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3746/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3747/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3748/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3749/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3750/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3751/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3752/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3753/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3754/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3755/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3756/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3757/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3758/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3759/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3760/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3761/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3762/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3763/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3764/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3765/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3766/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3767/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3768/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3769/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3770/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3771/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3772/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3773/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3774/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3775/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3776/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3777/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3778/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3779/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3780/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3781/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3782/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3783/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3784/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3785/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3786/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3787/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3788/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3789/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3790/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3791/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3792/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3793/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3794/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3795/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3796/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3797/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3798/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3799/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3800/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3801/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3802/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3803/6000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3804/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3805/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3806/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3807/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3808/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3809/6000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3810/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3811/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3812/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3813/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3814/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3815/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3816/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3817/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3818/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3819/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3820/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3821/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3822/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3823/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3824/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3825/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3826/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3827/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3828/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3829/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3830/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3831/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3832/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3833/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3834/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3835/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3836/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3837/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3838/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3839/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3840/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3841/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3842/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3843/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3844/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3845/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3846/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3847/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3848/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3849/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3850/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3851/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3852/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3853/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3854/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3855/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3856/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3857/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3858/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3859/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3860/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3861/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3862/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3863/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3864/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3865/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3866/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3867/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3868/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3869/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3870/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3871/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3872/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3873/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3874/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3875/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3876/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3877/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3878/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3879/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3880/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3881/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3882/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3883/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3884/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3885/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3886/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3887/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3888/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3889/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3890/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3891/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3892/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3893/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3894/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3895/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3896/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3897/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3898/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3899/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3900/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3901/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3902/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3903/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3904/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3905/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3906/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3907/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3908/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3909/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3910/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3911/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3912/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3913/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3914/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3915/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3916/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3917/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3918/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3919/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3920/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3921/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3922/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3923/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3924/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3925/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3926/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3927/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3928/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3929/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3930/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3931/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3932/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3933/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3934/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3935/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3936/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3937/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3938/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3939/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3940/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3941/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3942/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3943/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3944/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3945/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3946/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3947/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3948/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3949/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3950/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3951/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3952/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3953/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3954/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3955/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3956/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3957/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3958/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3959/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3960/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3961/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3962/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3963/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3964/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3965/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3966/6000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3967/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3968/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3969/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3970/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3971/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3972/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3973/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3974/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3975/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3976/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3977/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3978/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3979/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3980/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3981/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3982/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3983/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3984/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3985/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3986/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3987/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3988/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3989/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3990/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3991/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3992/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3993/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3994/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3995/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3996/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3997/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 3998/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 3999/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4000/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4001/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4002/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4003/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4004/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4005/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4006/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4007/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4008/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4009/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4010/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4011/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4012/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4013/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4014/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4015/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4016/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4017/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4018/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4019/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4020/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4021/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4022/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4023/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4024/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4025/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4026/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4027/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4028/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4029/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4030/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4031/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4032/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4033/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4034/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4035/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4036/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4037/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4038/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4039/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4040/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4041/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4042/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4043/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4044/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4045/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4046/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4047/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4048/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4049/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4050/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4051/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4052/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4053/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4054/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4055/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4056/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4057/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4058/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4059/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4060/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4061/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4062/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4063/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4064/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4065/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4066/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4067/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4068/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4069/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4070/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4071/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4072/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4073/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4074/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4075/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4076/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4077/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4078/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4079/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4080/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4081/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4082/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4083/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4084/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4085/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4086/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4087/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4088/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4089/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4090/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4091/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4092/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4093/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4094/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4095/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4096/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4097/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4098/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4099/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4100/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4101/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4102/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4103/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4104/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4105/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4106/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4107/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4108/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4109/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4110/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4111/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4112/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4113/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4114/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4115/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4116/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4117/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4118/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4119/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4120/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4121/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4122/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4123/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4124/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4125/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4126/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4127/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4128/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4129/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4130/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4131/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4132/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4133/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4134/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4135/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4136/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4137/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4138/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4139/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4140/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4141/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4142/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4143/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4144/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4145/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4146/6000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4147/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4148/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4149/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4150/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4151/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4152/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4153/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4154/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4155/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4156/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4157/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4158/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4159/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4160/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4161/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4162/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4163/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4164/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4165/6000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4166/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4167/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4168/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4169/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4170/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4171/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4172/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4173/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4174/6000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4175/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4176/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4177/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4178/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4179/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4180/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4181/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4182/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4183/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4184/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4185/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4186/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4187/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4188/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4189/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4190/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4191/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4192/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4193/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4194/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4195/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4196/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4197/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4198/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4199/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4200/6000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4201/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4202/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4203/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4204/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4205/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4206/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4207/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4208/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4209/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4210/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4211/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4212/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4213/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4214/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4215/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4216/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4217/6000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4218/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4219/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4220/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4221/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4222/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4223/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4224/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4225/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4226/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4227/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4228/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4229/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4230/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4231/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4232/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4233/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4234/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4235/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4236/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4237/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4238/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4239/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4240/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4241/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4242/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4243/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4244/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4245/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4246/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4247/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4248/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4249/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4250/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4251/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4252/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4253/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4254/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4255/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4256/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4257/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4258/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4259/6000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4260/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4261/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4262/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4263/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4264/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4265/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4266/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4267/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4268/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4269/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4270/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4271/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4272/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4273/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4274/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4275/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4276/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4277/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4278/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4279/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4280/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4281/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4282/6000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4283/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4284/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4285/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4286/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4287/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4288/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4289/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4290/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4291/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4292/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4293/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4294/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4295/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4296/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4297/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4298/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4299/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4300/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4301/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4302/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4303/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4304/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4305/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4306/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4307/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4308/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4309/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4310/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4311/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4312/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4313/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4314/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4315/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4316/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4317/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4318/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4319/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4320/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4321/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4322/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4323/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4324/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4325/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4326/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4327/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4328/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4329/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4330/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4331/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4332/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4333/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4334/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4335/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4336/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4337/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4338/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4339/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4340/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4341/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4342/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4343/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4344/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4345/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4346/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4347/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4348/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4349/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4350/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4351/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4352/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4353/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4354/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4355/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4356/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4357/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4358/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4359/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4360/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4361/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4362/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4363/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4364/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4365/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4366/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4367/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4368/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4369/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4370/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4371/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4372/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4373/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4374/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4375/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4376/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4377/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4378/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4379/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4380/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4381/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4382/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4383/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4384/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4385/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4386/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4387/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4388/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4389/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4390/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4391/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4392/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4393/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4394/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4395/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4396/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4397/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4398/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4399/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4400/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4401/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4402/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4403/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4404/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4405/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4406/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4407/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4408/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4409/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4410/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4411/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4412/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4413/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4414/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4415/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4416/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4417/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4418/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4419/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4420/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4421/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4422/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4423/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4424/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4425/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4426/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4427/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4428/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4429/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4430/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4431/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4432/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4433/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4434/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4435/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4436/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4437/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4438/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4439/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4440/6000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4441/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4442/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4443/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4444/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4445/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4446/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4447/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4448/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4449/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4450/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4451/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4452/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4453/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4454/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4455/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4456/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4457/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4458/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4459/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4460/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4461/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4462/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4463/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4464/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4465/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4466/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4467/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4468/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4469/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4470/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4471/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4472/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4473/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4474/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4475/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4476/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4477/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4478/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4479/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4480/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4481/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4482/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4483/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4484/6000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4485/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4486/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4487/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4488/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4489/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4490/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4491/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4492/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4493/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4494/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4495/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4496/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4497/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4498/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4499/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4500/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4501/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4502/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4503/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4504/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4505/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4506/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4507/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4508/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4509/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4510/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4511/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4512/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4513/6000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4514/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4515/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4516/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4517/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4518/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4519/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4520/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4521/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4522/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4523/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4524/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4525/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4526/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4527/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4528/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4529/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4530/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4531/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4532/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4533/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4534/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4535/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4536/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4537/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4538/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4539/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4540/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4541/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4542/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4543/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4544/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4545/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4546/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4547/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4548/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4549/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4550/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4551/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4552/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4553/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4554/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4555/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4556/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4557/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4558/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4559/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4560/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4561/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4562/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4563/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4564/6000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4565/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4566/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4567/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4568/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4569/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4570/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4571/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4572/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4573/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4574/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4575/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4576/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4577/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4578/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4579/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4580/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4581/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4582/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4583/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4584/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4585/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4586/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4587/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4588/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4589/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4590/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4591/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4592/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4593/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4594/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4595/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4596/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4597/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4598/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4599/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4600/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4601/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4602/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4603/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4604/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4605/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4606/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4607/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4608/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4609/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4610/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4611/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4612/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4613/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4614/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4615/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4616/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4617/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4618/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4619/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4620/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4621/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4622/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4623/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4624/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4625/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4626/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4627/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4628/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4629/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4630/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4631/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4632/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4633/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4634/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4635/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4636/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4637/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4638/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4639/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4640/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4641/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4642/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4643/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4644/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4645/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4646/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4647/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4648/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4649/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4650/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4651/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4652/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4653/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4654/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4655/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4656/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4657/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4658/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4659/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4660/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4661/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4662/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4663/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4664/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4665/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4666/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4667/6000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4668/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4669/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4670/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4671/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4672/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4673/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4674/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4675/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4676/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4677/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4678/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4679/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4680/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4681/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4682/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4683/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4684/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4685/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4686/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4687/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4688/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4689/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4690/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4691/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4692/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4693/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4694/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4695/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4696/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4697/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4698/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4699/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4700/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4701/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4702/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4703/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4704/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4705/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4706/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4707/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4708/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4709/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4710/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4711/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4712/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4713/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4714/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4715/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4716/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4717/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4718/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4719/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4720/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4721/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4722/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4723/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4724/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4725/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4726/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4727/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4728/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4729/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4730/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4731/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4732/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4733/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4734/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4735/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4736/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4737/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4738/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4739/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4740/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4741/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4742/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4743/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4744/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4745/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4746/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4747/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4748/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4749/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4750/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4751/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4752/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4753/6000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4754/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4755/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4756/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4757/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4758/6000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4759/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4760/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4761/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4762/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4763/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4764/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4765/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4766/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4767/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4768/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4769/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4770/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4771/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4772/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4773/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4774/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4775/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4776/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4777/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4778/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4779/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4780/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4781/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4782/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4783/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4784/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4785/6000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4786/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4787/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4788/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4789/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4790/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4791/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4792/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4793/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4794/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4795/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4796/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4797/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4798/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4799/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4800/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4801/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4802/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4803/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4804/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4805/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4806/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4807/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4808/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4809/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4810/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4811/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4812/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4813/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4814/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4815/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4816/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4817/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4818/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4819/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4820/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4821/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4822/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4823/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4824/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4825/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4826/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4827/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4828/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4829/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4830/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4831/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4832/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4833/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4834/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4835/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4836/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4837/6000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4838/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4839/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4840/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4841/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4842/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4843/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4844/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4845/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4846/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4847/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4848/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4849/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4850/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4851/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4852/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4853/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4854/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4855/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4856/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4857/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4858/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4859/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4860/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4861/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4862/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4863/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4864/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4865/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4866/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4867/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4868/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4869/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4870/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4871/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4872/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4873/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4874/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4875/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4876/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4877/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4878/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4879/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4880/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4881/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4882/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4883/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4884/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4885/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4886/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4887/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4888/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4889/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4890/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4891/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4892/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4893/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4894/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4895/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4896/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4897/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4898/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4899/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4900/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4901/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4902/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4903/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4904/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4905/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4906/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4907/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4908/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4909/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4910/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4911/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4912/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4913/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4914/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4915/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4916/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4917/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4918/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4919/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4920/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4921/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4922/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4923/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4924/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4925/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4926/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4927/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4928/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4929/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4930/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4931/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4932/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4933/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4934/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4935/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4936/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4937/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4938/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4939/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4940/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4941/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4942/6000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4943/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4944/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4945/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4946/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4947/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4948/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4949/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4950/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4951/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4952/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4953/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4954/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4955/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4956/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4957/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4958/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4959/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4960/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4961/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4962/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4963/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4964/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4965/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4966/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4967/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4968/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4969/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4970/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4971/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4972/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4973/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4974/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4975/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4976/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4977/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4978/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4979/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4980/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4981/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4982/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4983/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4984/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4985/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4986/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4987/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4988/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4989/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4990/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4991/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4992/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4993/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4994/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 4995/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4996/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4997/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4998/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 4999/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5000/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5001/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5002/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5003/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5004/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5005/6000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5006/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5007/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5008/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5009/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5010/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5011/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5012/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5013/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5014/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5015/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5016/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5017/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5018/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5019/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5020/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5021/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5022/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5023/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5024/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5025/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5026/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5027/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5028/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5029/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5030/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5031/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5032/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5033/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5034/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5035/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5036/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5037/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5038/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5039/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5040/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5041/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5042/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5043/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5044/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5045/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5046/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5047/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5048/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5049/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5050/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5051/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5052/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5053/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5054/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5055/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5056/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5057/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5058/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5059/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5060/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5061/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5062/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5063/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5064/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5065/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5066/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5067/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5068/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5069/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5070/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5071/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5072/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5073/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5074/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5075/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5076/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5077/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5078/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5079/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5080/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5081/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5082/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5083/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5084/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5085/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5086/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5087/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5088/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5089/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5090/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5091/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5092/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5093/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5094/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5095/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5096/6000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5097/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5098/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5099/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5100/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5101/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5102/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5103/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5104/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5105/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5106/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5107/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5108/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5109/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5110/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5111/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5112/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5113/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5114/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5115/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5116/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5117/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5118/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5119/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5120/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5121/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5122/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5123/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5124/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5125/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5126/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5127/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5128/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5129/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5130/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5131/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5132/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5133/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5134/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5135/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5136/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5137/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5138/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5139/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5140/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5141/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5142/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5143/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5144/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5145/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5146/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5147/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5148/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5149/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5150/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5151/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5152/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5153/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5154/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5155/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5156/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5157/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5158/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5159/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5160/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5161/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5162/6000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5163/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5164/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5165/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5166/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5167/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5168/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5169/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5170/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5171/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5172/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5173/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5174/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5175/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5176/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5177/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5178/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5179/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5180/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5181/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5182/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5183/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5184/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5185/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5186/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5187/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5188/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5189/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5190/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5191/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5192/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5193/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5194/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5195/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5196/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5197/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5198/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5199/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5200/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5201/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5202/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5203/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5204/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5205/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5206/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5207/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5208/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5209/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5210/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5211/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5212/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5213/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5214/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5215/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5216/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5217/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5218/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5219/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5220/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5221/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5222/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5223/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5224/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5225/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5226/6000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5227/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5228/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5229/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5230/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5231/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5232/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5233/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5234/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5235/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5236/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5237/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5238/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5239/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5240/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5241/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5242/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5243/6000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5244/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5245/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5246/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5247/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5248/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5249/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5250/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5251/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5252/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5253/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5254/6000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5255/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5256/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5257/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5258/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5259/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5260/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5261/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5262/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5263/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5264/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5265/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5266/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5267/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5268/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5269/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5270/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5271/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5272/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5273/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5274/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5275/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5276/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5277/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5278/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5279/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5280/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5281/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5282/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5283/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5284/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5285/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5286/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5287/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5288/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5289/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5290/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5291/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5292/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5293/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5294/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5295/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5296/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5297/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5298/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5299/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5300/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5301/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5302/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5303/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5304/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5305/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5306/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5307/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5308/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5309/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5310/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5311/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5312/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5313/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5314/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5315/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5316/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5317/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5318/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5319/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5320/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5321/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5322/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5323/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5324/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5325/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5326/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5327/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5328/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5329/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5330/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5331/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5332/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5333/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5334/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5335/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5336/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5337/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5338/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5339/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5340/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5341/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5342/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5343/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5344/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5345/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5346/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5347/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5348/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5349/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5350/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5351/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5352/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5353/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5354/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5355/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5356/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5357/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5358/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5359/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5360/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5361/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5362/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5363/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5364/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5365/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5366/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5367/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5368/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5369/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5370/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5371/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5372/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5373/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5374/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5375/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5376/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5377/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5378/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5379/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5380/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5381/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5382/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5383/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5384/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5385/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5386/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5387/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5388/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5389/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5390/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5391/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5392/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5393/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5394/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5395/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5396/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5397/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5398/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5399/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5400/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5401/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5402/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5403/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5404/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5405/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5406/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5407/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5408/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5409/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5410/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5411/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5412/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5413/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5414/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5415/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5416/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5417/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5418/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5419/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5420/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5421/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5422/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5423/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5424/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5425/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5426/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5427/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5428/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5429/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5430/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5431/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5432/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5433/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5434/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5435/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5436/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5437/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5438/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5439/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5440/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5441/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5442/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5443/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5444/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5445/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5446/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5447/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5448/6000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5449/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5450/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5451/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5452/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5453/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5454/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5455/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5456/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5457/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5458/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5459/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5460/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5461/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5462/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5463/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5464/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5465/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5466/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5467/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5468/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5469/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5470/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5471/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5472/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5473/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5474/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5475/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5476/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5477/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5478/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5479/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5480/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5481/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5482/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5483/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5484/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5485/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5486/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5487/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5488/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5489/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5490/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5491/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5492/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5493/6000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5494/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5495/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5496/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5497/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5498/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5499/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5500/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5501/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5502/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5503/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5504/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5505/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5506/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5507/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5508/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5509/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5510/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5511/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5512/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5513/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5514/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5515/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5516/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5517/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5518/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5519/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5520/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5521/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5522/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5523/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5524/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5525/6000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5526/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5527/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5528/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5529/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5530/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5531/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5532/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5533/6000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5534/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5535/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5536/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5537/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5538/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5539/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5540/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5541/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5542/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5543/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5544/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5545/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5546/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5547/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5548/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5549/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5550/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5551/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5552/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5553/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5554/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5555/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5556/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5557/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5558/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5559/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5560/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5561/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5562/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5563/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5564/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5565/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5566/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5567/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5568/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5569/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5570/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5571/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5572/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5573/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5574/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5575/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5576/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5577/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5578/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5579/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5580/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5581/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5582/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5583/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5584/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5585/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5586/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5587/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5588/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5589/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5590/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5591/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5592/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5593/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5594/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5595/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5596/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5597/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5598/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5599/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5600/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5601/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5602/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5603/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5604/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5605/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5606/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5607/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5608/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5609/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5610/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5611/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5612/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5613/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5614/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5615/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5616/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5617/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5618/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5619/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5620/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5621/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5622/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5623/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5624/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5625/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5626/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5627/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5628/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5629/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5630/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5631/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5632/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5633/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5634/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5635/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5636/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5637/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5638/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5639/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5640/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5641/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5642/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5643/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5644/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5645/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5646/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5647/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5648/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5649/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5650/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5651/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5652/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5653/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5654/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5655/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5656/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5657/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5658/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5659/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5660/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5661/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5662/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5663/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5664/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5665/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5666/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5667/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5668/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5669/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5670/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5671/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5672/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5673/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5674/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5675/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5676/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5677/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5678/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5679/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5680/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5681/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5682/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5683/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5684/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5685/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5686/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5687/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5688/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5689/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5690/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5691/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5692/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5693/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5694/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5695/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5696/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5697/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5698/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5699/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5700/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5701/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5702/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5703/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5704/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5705/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5706/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5707/6000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5708/6000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5709/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5710/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5711/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5712/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5713/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5714/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5715/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5716/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5717/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5718/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5719/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5720/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5721/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5722/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5723/6000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5724/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5725/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5726/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5727/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5728/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5729/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5730/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5731/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5732/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5733/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5734/6000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5735/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5736/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5737/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5738/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5739/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5740/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5741/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5742/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5743/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5744/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5745/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5746/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5747/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5748/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5749/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5750/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5751/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5752/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5753/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5754/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5755/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5756/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5757/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5758/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5759/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5760/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5761/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5762/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5763/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5764/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5765/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5766/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5767/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5768/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5769/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5770/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5771/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5772/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5773/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5774/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5775/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5776/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5777/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5778/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5779/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5780/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5781/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5782/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5783/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5784/6000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5785/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5786/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5787/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5788/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5789/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5790/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5791/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5792/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5793/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5794/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5795/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5796/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5797/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5798/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5799/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5800/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5801/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5802/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5803/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5804/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5805/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5806/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5807/6000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5808/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5809/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5810/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5811/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5812/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5813/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5814/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5815/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5816/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5817/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5818/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5819/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5820/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5821/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5822/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5823/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5824/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5825/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5826/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5827/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5828/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5829/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5830/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5831/6000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5832/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5833/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5834/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5835/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5836/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5837/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5838/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5839/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5840/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5841/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5842/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5843/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5844/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5845/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5846/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5847/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5848/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5849/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5850/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5851/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5852/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5853/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5854/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5855/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5856/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5857/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5858/6000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5859/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5860/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5861/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5862/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5863/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5864/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5865/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5866/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5867/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5868/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5869/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5870/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5871/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5872/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5873/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5874/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5875/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5876/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5877/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5878/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5879/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5880/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5881/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5882/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5883/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5884/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5885/6000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5886/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5887/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5888/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5889/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5890/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5891/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5892/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5893/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5894/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5895/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5896/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5897/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5898/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5899/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5900/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5901/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5902/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5903/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5904/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5905/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5906/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5907/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5908/6000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5909/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5910/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5911/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5912/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5913/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5914/6000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5915/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5916/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5917/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5918/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5919/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5920/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5921/6000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5922/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5923/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5924/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5925/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5926/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5927/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5928/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5929/6000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5930/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5931/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5932/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5933/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5934/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5935/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5936/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5937/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5938/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5939/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5940/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5941/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8910\n",
            "Epoch 5942/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5943/6000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5944/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5945/6000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5946/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5947/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5948/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5949/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5950/6000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5951/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5952/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5953/6000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5954/6000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5955/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5956/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5957/6000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5958/6000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5959/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5960/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5961/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5962/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5963/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5964/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5965/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5966/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5967/6000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5968/6000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5969/6000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5970/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5971/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5972/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5973/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5974/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5975/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5976/6000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5977/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5978/6000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5979/6000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5980/6000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5981/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5982/6000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5983/6000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5984/6000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5985/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5986/6000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5987/6000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5988/6000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5989/6000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5990/6000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5991/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5992/6000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5993/6000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5994/6000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5995/6000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5996/6000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5997/6000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5998/6000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 5999/6000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Epoch 6000/6000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3160 - accuracy: 0.8926 - val_loss: 0.3205 - val_accuracy: 0.8909\n",
            "Model Training Completed.....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IvWkYf285_y"
      },
      "source": [
        "# **9. Target Model - Validation Predictions - Classification - \"Credit Default**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr0drYIy85_z"
      },
      "source": [
        "# Predicting the Target \"Credit Default\" on the Validation Data\n",
        "\n",
        "tm2_y_pred = target_model_2.predict(tm_validation_X, batch_size=1)\n",
        "\n",
        "print(\"Execution Completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvHj0wlL85_z"
      },
      "source": [
        "# Verifying the Count of Prediction Outcomes on the Validation Data\n",
        "\n",
        "print(\"Total Output Actuals on the Target Model 2 Validation Data: \", tm_validation_y_clas.shape[0])\n",
        "print(\"Total Output Predictions on the Target Model 2 Validation Data: \", len(tm2_y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOGPBHcJ85_0"
      },
      "source": [
        "# Comparing the Actual and Prediction Results for the first 10 Validation Data Instances\n",
        "\n",
        "print(\"Target Model 2 Validation Actuals\")\n",
        "print(tm_validation_y_clas[:10])\n",
        "\n",
        "print(\"Target Model 2 Validation Predictions\")\n",
        "print(tm2_y_pred[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBHYYdcg88qQ"
      },
      "source": [
        "# **10. Target Model - Visualising the Performance Metrics (Loss)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbH6qOgB88qS"
      },
      "source": [
        "hist_tm2 = pd.DataFrame(history.history)\n",
        "hist_tm2['epoch'] = history.epoch\n",
        "hist_tm2.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UykZNjy88qT"
      },
      "source": [
        "hist_tm2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsxRSqR888qU"
      },
      "source": [
        "def tm_plot_loss_tm2(history):\n",
        "  plt.plot(history.history['loss'], label='Loss')\n",
        "  plt.plot(history.history['val_loss'], label='Validation_Loss')\n",
        "  plt.ylim([0, 10])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [Loss]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "tm_plot_loss_tm2(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63-FtZQGZ8R5"
      },
      "source": [
        "# **11. Target Model 2 - Actuals versus Predictions Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EyMFVAvaH0y"
      },
      "source": [
        "# Converting probability predictions numpy array into a dataframe\n",
        "\n",
        "tm2_y_pred_df = pd.DataFrame(tm2_y_pred, columns=['Credit_Default_Probability_Prediction'])\n",
        "tm2_y_pred_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfUsbRI0fnpN"
      },
      "source": [
        "tm2_y_pred_df['Credit_Default_Class_Prediction'] = np.where( tm2_y_pred_df['Credit_Default_Probability_Prediction'] > 0.5, 1, 0)\n",
        "\n",
        "print(\"Missing Values in the New Column 'Credit_Default_Class_Prediction':\", tm2_y_pred_df['Credit_Default_Class_Prediction'].isna().sum())\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Displaying a sample of 10 random actuals and its respective predictions\n",
        "tm2_y_pred_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB8qeJjXiHHP"
      },
      "source": [
        "# Verifying the Size and the Missing Values (if any) Count of the Credit Default Actual (Ground-Truth) Dataframe and the Predictions Dataframe\n",
        "\n",
        "print(tm_validation_y_clas.shape)\n",
        "print(tm2_y_pred_df.shape)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(tm_validation_y_clas.isna().sum())\n",
        "print(tm2_y_pred_df.isna().sum())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdYHSrhZgbDS"
      },
      "source": [
        "# Concatenating the Credit Default Actual (Ground-Truth) Dataframe and the Predictions Dataframe\n",
        "\n",
        "frames = [tm_validation_y_clas, tm2_y_pred_df]\n",
        "\n",
        "tm2_results = pd.concat(frames, axis=1)\n",
        "\n",
        "# Renaming the \"Credit_Default\" Column Name\n",
        "tm2_results.rename(columns = {'credit_default':'Credit_Default_Class_Actual'}, inplace = True)\n",
        "\n",
        "# Displaying a sample of 10 random results\n",
        "tm2_results.sample(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fU5UP5AecBv"
      },
      "source": [
        "# **12. Exporting a Copy of the Credit Default Output Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYVIX4XmecB7"
      },
      "source": [
        "# Exporting a copy of Credit Default Actuals and Predictions DataFrame as a csv file\n",
        "\n",
        "tm2_results.to_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/output/tm_model_2_classification_tune_1_4000b_final_predictions.csv\")\n",
        "\n",
        "print(\"Data Export Completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHsdhd8Ci1IF"
      },
      "source": [
        "# **13. Target Model 2 - Metrics Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSHRaF2ei-nT"
      },
      "source": [
        "# Target Model 2 - Classification Report \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "tm2_classification_report = classification_report(tm2_results['Credit_Default_Class_Actual'], tm2_results['Credit_Default_Class_Prediction'])\n",
        "\n",
        "print(tm2_classification_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKWqCaDBkQr2"
      },
      "source": [
        "# Target Model 2 - Confusion Matrix\n",
        "\n",
        "import seaborn as sn\n",
        "\n",
        "tm2_cm = tf.math.confusion_matrix(labels=tm2_results['Credit_Default_Class_Actual'], predictions=tm2_results['Credit_Default_Class_Prediction'])\n",
        "\n",
        "plt.figure(figsize = (8, 6))\n",
        "sn.heatmap(tm2_cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W39avKPkoiQ"
      },
      "source": [
        "# Target Model 2 - ROC, AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "tm2_auc = roc_auc_score(tm2_results['Credit_Default_Class_Actual'], tm2_results['Credit_Default_Class_Prediction'])\n",
        "\n",
        "print(\"Target Model ROC AUC: \", tm2_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg8hRySuZu1y"
      },
      "source": [
        "# **14. Saving the Finalised Target Model 2 - Classification of \"Credit_Default\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IHleWCAZxEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c637d492-b8d4-4c20-a6a5-606c499a5a0c"
      },
      "source": [
        "# Saving the Target Model 2 - Classification of \"Credit_Default\"\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "target_model_2.save('tm_model_2_clas_fe_mod_retrain_2_6000_final.h5')\n",
        "\n",
        "print(\"Model Saved Successfully\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved Successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdPT4n7qFz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12272d8-8950-43d6-ee00-7b42cc0e9dc6"
      },
      "source": [
        "# Target Model 2 Summarisation\n",
        "\n",
        "target_model_2.summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x7fadd693a710>>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkasX2tPhg59"
      },
      "source": [
        "# **15. Saving the Finalised Target Model 2 Weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_i8qDWLhtzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae8525c-4cc6-46f7-b1d5-fbedd8715923"
      },
      "source": [
        "# Saving the Model Weights\n",
        "\n",
        "target_model_2.save_weights(\"tm_model_2_clas_fe_mod_retrain_2_6000_final_weights\")\n",
        "\n",
        "print(\"Model Weights Saved Successfully\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Weights Saved Successfully\n"
          ]
        }
      ]
    }
  ]
}