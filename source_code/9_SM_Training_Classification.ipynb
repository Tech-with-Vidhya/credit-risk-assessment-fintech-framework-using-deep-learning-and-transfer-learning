{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chbx1P5TItIM"
   },
   "source": [
    "# **CREDIT RISK SCORING - SOURCE MODEL (SM) - DEEP LEARNING - MODEL TRAINING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qQ8EMyrR5sJ"
   },
   "source": [
    "## **TensorFlow Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z05F-RkhGo-a",
    "outputId": "55a7dcd2-22bb-43cf-84c1-7dd6674bbdf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 489.6 MB 9.6 kB/s \n",
      "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (12.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.41.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.22.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.37.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (57.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.8.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.6.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR8cYEN_IWzm"
   },
   "source": [
    "# **1. Importing Python Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFcw1CoZIdgI",
    "outputId": "907cca48-f237-4ed6-fb61-6fc73fb44467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Completed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"Import Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML7ZvboLNbjk"
   },
   "source": [
    "# **2. Importing the Source Model Train, Validation Input and Train Output csv Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGAtyJTdMe_h",
    "outputId": "06cc89b7-fdae-4548-f82a-2b01c5290d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Import Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing the Source Model (SM) Train Input Data\n",
    "\n",
    "sm_train_X = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/source_model_final_data/sm_train_final_input_X.csv\")\n",
    "\n",
    "print(\"Data Import Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOnkgawpN-Mu",
    "outputId": "76250894-5a8f-4ee7-9479-b673790e71e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Import Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing the Source Model (SM) Train Output Data\n",
    "\n",
    "sm_train_y = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/source_model_final_data/sm_train_final_output_y.csv\")\n",
    "\n",
    "print(\"Data Import Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnMDm97QO1Ny",
    "outputId": "7b8705cc-7128-4c35-a746-4e935f961f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Import Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing the Source Model (SM) Validation Input Data\n",
    "\n",
    "sm_validation_X = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/source_model_final_data/sm_validation_final_input_X.csv\")\n",
    "\n",
    "print(\"Data Import Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V18KXgXxO1V4",
    "outputId": "06ca753f-358d-41ba-ffe6-abec108fc7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Import Completed\n"
     ]
    }
   ],
   "source": [
    "# Importing the Source Model (SM) Validation Output Data\n",
    "\n",
    "sm_validation_y = pd.read_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/data/source_model_final_data/sm_validation_final_output_y.csv\")\n",
    "\n",
    "print(\"Data Import Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8MGnNxRPQGC"
   },
   "source": [
    "# **3. Source Model (SM) Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9VMPP84PUqC",
    "outputId": "32e33cfb-1a6e-4031-d439-924d60ec1286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(565726, 75)\n",
      "(565726, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking the Size of the Source Model (SM) Train Input and Output Data\n",
    "\n",
    "print(sm_train_X.shape)\n",
    "print(sm_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMmhdac2Ph8d",
    "outputId": "dde062af-e53d-452f-a344-33b98f58cd9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83885, 75)\n",
      "(83885, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking the Size of the Source Model (SM) Validation Input and Output Data\n",
    "\n",
    "print(sm_validation_X.shape)\n",
    "print(sm_validation_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAj04F3UPvyu"
   },
   "source": [
    "### **Source Model (SM) Train Input Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPLYaOXPP2dY",
    "outputId": "4415e0d5-5eba-4387-b593-21a265c3030c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YMwySKUQT_K",
    "outputId": "ef18993d-89d2-4370-9301-adfaee0ef869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'pub_rec:0', 'pub_record:non_zero'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "sm_train_X.columns[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tltckdH7QUHH",
    "outputId": "24808844-0aa3-4dee-a8a3-ca7118ca2060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Removing the first index column from the dataset\n",
    "\n",
    "sm_train_X.drop(sm_train_X.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3BqlFARQUKM",
    "outputId": "273d19c6-603c-452d-9df4-2fefc83d4727"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565726, 74)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-checking the size of the dataset\n",
    "\n",
    "sm_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMxliTNqShjY",
    "outputId": "58051f1b-38d2-43ac-93ae-dd994f818213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_rec:0 ..... int64\n",
      "pub_record:non_zero ..... int64\n",
      "delinq_2yrs:0 ..... int64\n",
      "delinq_2yrs:1 ..... int64\n",
      "delinq_2yrs:greater_than_1 ..... int64\n",
      "num_tl_120dpd_2m:0 ..... int64\n",
      "num_tl_120dpd_2m:non_zero ..... int64\n",
      "pub_rec_bankruptcies:0 ..... int64\n",
      "pub_rec_bankruptcies:non_zero ..... int64\n",
      "num_tl_90g_dpd_24m:0 ..... int64\n",
      "num_tl_90g_dpd_24m:non_zero ..... int64\n",
      "num_accts_ever_120_pd:0 ..... int64\n",
      "num_accts_ever_120_pd:_non_zero ..... int64\n",
      "acc_now_delinq:0 ..... int64\n",
      "acc_now_delinq:non_zero ..... int64\n",
      "num_tl_30dpd:0 ..... int64\n",
      "num_tl_30dpd:non_zero ..... int64\n",
      "total_rec_late_fee:0 ..... int64\n",
      "total_rec_late_fee:non_zero ..... int64\n",
      "num_rev_tl_bal_gt_0:0 ..... int64\n",
      "num_rev_tl_bal_gt_0:1_to_5 ..... int64\n",
      "num_rev_tl_bal_gt_0:greater_than_5 ..... int64\n",
      "percent_bc_gt_75:0 ..... int64\n",
      "percent_bc_gt_75:1_to_75 ..... int64\n",
      "percent_bc_gt_75:greater_than_75 ..... int64\n",
      "revol_util:0 ..... int64\n",
      "revol_util:1_to_30 ..... int64\n",
      "revol_util:31_to_60 ..... int64\n",
      "revol_util:greater_than_60 ..... int64\n",
      "il_util:0 ..... int64\n",
      "il_util:1_to_40 ..... int64\n",
      "il_util:greater_than_40 ..... int64\n",
      "max_bal_bc:0 ..... int64\n",
      "max_bal_bc:1_to_5000 ..... int64\n",
      "max_bal_bc:5001_to_10000 ..... int64\n",
      "max_bal_bc:greater_than_10000 ..... int64\n",
      "mo_sin_old_rev_tl_op:less_than_6months ..... int64\n",
      "mo_sin_old_rev_tl_op:7months_to_24months ..... int64\n",
      "mo_sin_old_rev_tl_op:greater_than_24months ..... int64\n",
      "months_since_earliest_cr_line:less_than_78months ..... int64\n",
      "months_since_earliest_cr_line:79months_to_96months ..... int64\n",
      "months_since_earliest_cr_line:greater_than_96months ..... int64\n",
      "open_acc:less_than_5 ..... int64\n",
      "open_acc:6_to_8 ..... int64\n",
      "open_acc:greater_than_8 ..... int64\n",
      "num_sats:0_to_5 ..... int64\n",
      "num_sats:6_to_8 ..... int64\n",
      "num_sats:greater_than_8 ..... int64\n",
      "mort_acc:0 ..... int64\n",
      "mort_acc:1_to_3 ..... int64\n",
      "mort_acc:greater_than_3 ..... int64\n",
      "inq_last_6mths:0 ..... int64\n",
      "inq_last_6mths:1 ..... int64\n",
      "inq_last_6mths:greater_than_1 ..... int64\n",
      "open_il_12m:_0 ..... int64\n",
      "open_il_12m:_1 ..... int64\n",
      "open_il_12m:greater_than_1 ..... int64\n",
      "num_tl_op_past_12m:0 ..... int64\n",
      "num_tl_op_past_12m:1 ..... int64\n",
      "num_tl_op_past_12m:2 ..... int64\n",
      "num_tl_op_past_12m:3 ..... int64\n",
      "num_tl_op_past_12m:greater_than_3 ..... int64\n",
      "annual_inc:0_to_25000 ..... int64\n",
      "annual_inc:25001_to_50000 ..... int64\n",
      "annual_inc:50001_to_75000 ..... int64\n",
      "annual_inc:75001_to_100000 ..... int64\n",
      "annual_inc:greater_than_100001 ..... int64\n",
      "dti:0_to_36 ..... int64\n",
      "dti:greater_than_36 ..... int64\n",
      "emp_length_int:less_than_0 ..... int64\n",
      "emp_length_int:1_to_2 ..... int64\n",
      "emp_length_int:3_to_5 ..... int64\n",
      "emp_length_int:6_to_9 ..... int64\n",
      "emp_length_int:greater_than_9 ..... int64\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of the Input Features in the Source Model (SM) Train Input Data\n",
    "\n",
    "for feat in sm_train_X:\n",
    "    print(feat, \".....\", sm_train_X.dtypes[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "NwpX2LrzQe3D",
    "outputId": "8a41b6ad-367c-4db0-f462-2ffd5a446fd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_rec:0</th>\n",
       "      <th>pub_record:non_zero</th>\n",
       "      <th>delinq_2yrs:0</th>\n",
       "      <th>delinq_2yrs:1</th>\n",
       "      <th>delinq_2yrs:greater_than_1</th>\n",
       "      <th>num_tl_120dpd_2m:0</th>\n",
       "      <th>num_tl_120dpd_2m:non_zero</th>\n",
       "      <th>pub_rec_bankruptcies:0</th>\n",
       "      <th>pub_rec_bankruptcies:non_zero</th>\n",
       "      <th>num_tl_90g_dpd_24m:0</th>\n",
       "      <th>num_tl_90g_dpd_24m:non_zero</th>\n",
       "      <th>num_accts_ever_120_pd:0</th>\n",
       "      <th>num_accts_ever_120_pd:_non_zero</th>\n",
       "      <th>acc_now_delinq:0</th>\n",
       "      <th>acc_now_delinq:non_zero</th>\n",
       "      <th>num_tl_30dpd:0</th>\n",
       "      <th>num_tl_30dpd:non_zero</th>\n",
       "      <th>total_rec_late_fee:0</th>\n",
       "      <th>total_rec_late_fee:non_zero</th>\n",
       "      <th>num_rev_tl_bal_gt_0:0</th>\n",
       "      <th>num_rev_tl_bal_gt_0:1_to_5</th>\n",
       "      <th>num_rev_tl_bal_gt_0:greater_than_5</th>\n",
       "      <th>percent_bc_gt_75:0</th>\n",
       "      <th>percent_bc_gt_75:1_to_75</th>\n",
       "      <th>percent_bc_gt_75:greater_than_75</th>\n",
       "      <th>revol_util:0</th>\n",
       "      <th>revol_util:1_to_30</th>\n",
       "      <th>revol_util:31_to_60</th>\n",
       "      <th>revol_util:greater_than_60</th>\n",
       "      <th>il_util:0</th>\n",
       "      <th>il_util:1_to_40</th>\n",
       "      <th>il_util:greater_than_40</th>\n",
       "      <th>max_bal_bc:0</th>\n",
       "      <th>max_bal_bc:1_to_5000</th>\n",
       "      <th>max_bal_bc:5001_to_10000</th>\n",
       "      <th>max_bal_bc:greater_than_10000</th>\n",
       "      <th>mo_sin_old_rev_tl_op:less_than_6months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:7months_to_24months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:greater_than_24months</th>\n",
       "      <th>months_since_earliest_cr_line:less_than_78months</th>\n",
       "      <th>months_since_earliest_cr_line:79months_to_96months</th>\n",
       "      <th>months_since_earliest_cr_line:greater_than_96months</th>\n",
       "      <th>open_acc:less_than_5</th>\n",
       "      <th>open_acc:6_to_8</th>\n",
       "      <th>open_acc:greater_than_8</th>\n",
       "      <th>num_sats:0_to_5</th>\n",
       "      <th>num_sats:6_to_8</th>\n",
       "      <th>num_sats:greater_than_8</th>\n",
       "      <th>mort_acc:0</th>\n",
       "      <th>mort_acc:1_to_3</th>\n",
       "      <th>mort_acc:greater_than_3</th>\n",
       "      <th>inq_last_6mths:0</th>\n",
       "      <th>inq_last_6mths:1</th>\n",
       "      <th>inq_last_6mths:greater_than_1</th>\n",
       "      <th>open_il_12m:_0</th>\n",
       "      <th>open_il_12m:_1</th>\n",
       "      <th>open_il_12m:greater_than_1</th>\n",
       "      <th>num_tl_op_past_12m:0</th>\n",
       "      <th>num_tl_op_past_12m:1</th>\n",
       "      <th>num_tl_op_past_12m:2</th>\n",
       "      <th>num_tl_op_past_12m:3</th>\n",
       "      <th>num_tl_op_past_12m:greater_than_3</th>\n",
       "      <th>annual_inc:0_to_25000</th>\n",
       "      <th>annual_inc:25001_to_50000</th>\n",
       "      <th>annual_inc:50001_to_75000</th>\n",
       "      <th>annual_inc:75001_to_100000</th>\n",
       "      <th>annual_inc:greater_than_100001</th>\n",
       "      <th>dti:0_to_36</th>\n",
       "      <th>dti:greater_than_36</th>\n",
       "      <th>emp_length_int:less_than_0</th>\n",
       "      <th>emp_length_int:1_to_2</th>\n",
       "      <th>emp_length_int:3_to_5</th>\n",
       "      <th>emp_length_int:6_to_9</th>\n",
       "      <th>emp_length_int:greater_than_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pub_rec:0  pub_record:non_zero  delinq_2yrs:0  delinq_2yrs:1  \\\n",
       "0          1                    0              1              0   \n",
       "1          1                    0              1              0   \n",
       "2          1                    0              1              0   \n",
       "3          0                    1              1              0   \n",
       "4          1                    0              0              1   \n",
       "\n",
       "   delinq_2yrs:greater_than_1  num_tl_120dpd_2m:0  num_tl_120dpd_2m:non_zero  \\\n",
       "0                           0                   1                          0   \n",
       "1                           0                   1                          0   \n",
       "2                           0                   1                          0   \n",
       "3                           0                   1                          0   \n",
       "4                           0                   1                          0   \n",
       "\n",
       "   pub_rec_bankruptcies:0  pub_rec_bankruptcies:non_zero  \\\n",
       "0                       1                              0   \n",
       "1                       1                              0   \n",
       "2                       1                              0   \n",
       "3                       0                              1   \n",
       "4                       1                              0   \n",
       "\n",
       "   num_tl_90g_dpd_24m:0  num_tl_90g_dpd_24m:non_zero  num_accts_ever_120_pd:0  \\\n",
       "0                     1                            0                        1   \n",
       "1                     1                            0                        1   \n",
       "2                     1                            0                        0   \n",
       "3                     1                            0                        1   \n",
       "4                     1                            0                        1   \n",
       "\n",
       "   num_accts_ever_120_pd:_non_zero  acc_now_delinq:0  acc_now_delinq:non_zero  \\\n",
       "0                                0                 1                        0   \n",
       "1                                0                 1                        0   \n",
       "2                                1                 1                        0   \n",
       "3                                0                 1                        0   \n",
       "4                                0                 1                        0   \n",
       "\n",
       "   num_tl_30dpd:0  num_tl_30dpd:non_zero  total_rec_late_fee:0  \\\n",
       "0               1                      0                     1   \n",
       "1               1                      0                     1   \n",
       "2               1                      0                     1   \n",
       "3               1                      0                     1   \n",
       "4               1                      0                     1   \n",
       "\n",
       "   total_rec_late_fee:non_zero  num_rev_tl_bal_gt_0:0  \\\n",
       "0                            0                      0   \n",
       "1                            0                      0   \n",
       "2                            0                      0   \n",
       "3                            0                      0   \n",
       "4                            0                      0   \n",
       "\n",
       "   num_rev_tl_bal_gt_0:1_to_5  num_rev_tl_bal_gt_0:greater_than_5  \\\n",
       "0                           0                                   1   \n",
       "1                           1                                   0   \n",
       "2                           1                                   0   \n",
       "3                           1                                   0   \n",
       "4                           1                                   0   \n",
       "\n",
       "   percent_bc_gt_75:0  percent_bc_gt_75:1_to_75  \\\n",
       "0                   1                         0   \n",
       "1                   0                         1   \n",
       "2                   0                         0   \n",
       "3                   0                         1   \n",
       "4                   0                         1   \n",
       "\n",
       "   percent_bc_gt_75:greater_than_75  revol_util:0  revol_util:1_to_30  \\\n",
       "0                                 0             0                   1   \n",
       "1                                 0             0                   0   \n",
       "2                                 1             0                   0   \n",
       "3                                 0             0                   0   \n",
       "4                                 0             0                   0   \n",
       "\n",
       "   revol_util:31_to_60  revol_util:greater_than_60  il_util:0  \\\n",
       "0                    0                           0          1   \n",
       "1                    0                           1          1   \n",
       "2                    1                           0          1   \n",
       "3                    0                           1          0   \n",
       "4                    0                           1          1   \n",
       "\n",
       "   il_util:1_to_40  il_util:greater_than_40  max_bal_bc:0  \\\n",
       "0                0                        0             0   \n",
       "1                0                        0             0   \n",
       "2                0                        0             1   \n",
       "3                0                        1             0   \n",
       "4                0                        0             1   \n",
       "\n",
       "   max_bal_bc:1_to_5000  max_bal_bc:5001_to_10000  \\\n",
       "0                     0                         1   \n",
       "1                     0                         0   \n",
       "2                     0                         0   \n",
       "3                     1                         0   \n",
       "4                     0                         0   \n",
       "\n",
       "   max_bal_bc:greater_than_10000  mo_sin_old_rev_tl_op:less_than_6months  \\\n",
       "0                              0                                       0   \n",
       "1                              1                                       0   \n",
       "2                              0                                       0   \n",
       "3                              0                                       0   \n",
       "4                              0                                       0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:7months_to_24months  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:greater_than_24months  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "   months_since_earliest_cr_line:less_than_78months  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   months_since_earliest_cr_line:79months_to_96months  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   months_since_earliest_cr_line:greater_than_96months  open_acc:less_than_5  \\\n",
       "0                                                  1                       0   \n",
       "1                                                  1                       0   \n",
       "2                                                  1                       0   \n",
       "3                                                  1                       0   \n",
       "4                                                  1                       0   \n",
       "\n",
       "   open_acc:6_to_8  open_acc:greater_than_8  num_sats:0_to_5  num_sats:6_to_8  \\\n",
       "0                0                        1                0                0   \n",
       "1                1                        0                0                1   \n",
       "2                1                        0                0                1   \n",
       "3                1                        0                0                1   \n",
       "4                0                        1                0                0   \n",
       "\n",
       "   num_sats:greater_than_8  mort_acc:0  mort_acc:1_to_3  \\\n",
       "0                        1           0                1   \n",
       "1                        0           0                1   \n",
       "2                        0           1                0   \n",
       "3                        0           1                0   \n",
       "4                        1           0                1   \n",
       "\n",
       "   mort_acc:greater_than_3  inq_last_6mths:0  inq_last_6mths:1  \\\n",
       "0                        0                 0                 1   \n",
       "1                        0                 1                 0   \n",
       "2                        0                 0                 1   \n",
       "3                        0                 0                 1   \n",
       "4                        0                 1                 0   \n",
       "\n",
       "   inq_last_6mths:greater_than_1  open_il_12m:_0  open_il_12m:_1  \\\n",
       "0                              0               1               0   \n",
       "1                              0               1               0   \n",
       "2                              0               1               0   \n",
       "3                              0               1               0   \n",
       "4                              0               1               0   \n",
       "\n",
       "   open_il_12m:greater_than_1  num_tl_op_past_12m:0  num_tl_op_past_12m:1  \\\n",
       "0                           0                     0                     0   \n",
       "1                           0                     0                     1   \n",
       "2                           0                     0                     0   \n",
       "3                           0                     0                     0   \n",
       "4                           0                     0                     0   \n",
       "\n",
       "   num_tl_op_past_12m:2  num_tl_op_past_12m:3  \\\n",
       "0                     0                     0   \n",
       "1                     0                     0   \n",
       "2                     1                     0   \n",
       "3                     0                     0   \n",
       "4                     1                     0   \n",
       "\n",
       "   num_tl_op_past_12m:greater_than_3  annual_inc:0_to_25000  \\\n",
       "0                                  1                      0   \n",
       "1                                  0                      0   \n",
       "2                                  0                      0   \n",
       "3                                  1                      0   \n",
       "4                                  0                      0   \n",
       "\n",
       "   annual_inc:25001_to_50000  annual_inc:50001_to_75000  \\\n",
       "0                          0                          1   \n",
       "1                          0                          1   \n",
       "2                          0                          1   \n",
       "3                          0                          1   \n",
       "4                          0                          0   \n",
       "\n",
       "   annual_inc:75001_to_100000  annual_inc:greater_than_100001  dti:0_to_36  \\\n",
       "0                           0                               0            1   \n",
       "1                           0                               0            1   \n",
       "2                           0                               0            1   \n",
       "3                           0                               0            1   \n",
       "4                           1                               0            1   \n",
       "\n",
       "   dti:greater_than_36  emp_length_int:less_than_0  emp_length_int:1_to_2  \\\n",
       "0                    0                           0                      1   \n",
       "1                    0                           1                      0   \n",
       "2                    0                           1                      0   \n",
       "3                    0                           0                      1   \n",
       "4                    0                           0                      0   \n",
       "\n",
       "   emp_length_int:3_to_5  emp_length_int:6_to_9  emp_length_int:greater_than_9  \n",
       "0                      0                      0                              0  \n",
       "1                      0                      0                              0  \n",
       "2                      0                      0                              0  \n",
       "3                      0                      0                              0  \n",
       "4                      1                      0                              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displying the first 5 data instances\n",
    "\n",
    "sm_train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7cL2CBIQ6jP"
   },
   "source": [
    "### **Source Model (SM) Train Output Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_767pvvnQ6jQ",
    "outputId": "453f45db-fe3a-4391-8ed7-dedebdcf83f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFimZeGgQ6jR",
    "outputId": "a7ae0220-b868-4568-a68d-cbb008484ff5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'score_status'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "sm_train_y.columns[[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZwf9mAnQ6jR",
    "outputId": "52dde9b9-a58e-4e5a-83c6-5e000a0c19ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Removing the first index column from the dataset\n",
    "\n",
    "sm_train_y.drop(sm_train_y.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdcMxMCcQ6jS",
    "outputId": "583561c1-e9cd-49bb-e774-81595fd4b1f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565726, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-checking the size of the dataset\n",
    "\n",
    "sm_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "CqfvHIkGQ6jS",
    "outputId": "dc659ea0-de12-4258-895b-01cc91496bbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score_status\n",
       "0             1\n",
       "1             1\n",
       "2             0\n",
       "3             0\n",
       "4             0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displying the first 5 data instances\n",
    "\n",
    "sm_train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1yaeWfiQ7Jt"
   },
   "source": [
    "### **Source Model (SM) Validation Input Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1N2AUU20Q7Ju",
    "outputId": "e86b867e-09c4-4935-f371-3973c07353c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfRiS1pkQ7Ju",
    "outputId": "d99b1c78-3af3-4051-a55f-27ca5400e574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'pub_rec:0', 'pub_record:non_zero'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "sm_validation_X.columns[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_45m8AeQ7Ju",
    "outputId": "046b7018-6ed0-4f94-f862-9ef2071ef992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Removing the first index column from the dataset\n",
    "\n",
    "sm_validation_X.drop(sm_validation_X.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKH0UyyFQ7Jv",
    "outputId": "b87daa8c-d9e0-40c5-b9fb-b52e9fe2fe69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83885, 74)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-checking the size of the dataset\n",
    "\n",
    "sm_validation_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubTaeSM1Sz8i",
    "outputId": "9f45de2c-7273-4ee1-f6a8-adbd737d6909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_rec:0 ..... int64\n",
      "pub_record:non_zero ..... int64\n",
      "delinq_2yrs:0 ..... int64\n",
      "delinq_2yrs:1 ..... int64\n",
      "delinq_2yrs:greater_than_1 ..... int64\n",
      "num_tl_120dpd_2m:0 ..... int64\n",
      "num_tl_120dpd_2m:non_zero ..... int64\n",
      "pub_rec_bankruptcies:0 ..... int64\n",
      "pub_rec_bankruptcies:non_zero ..... int64\n",
      "num_tl_90g_dpd_24m:0 ..... int64\n",
      "num_tl_90g_dpd_24m:non_zero ..... int64\n",
      "num_accts_ever_120_pd:0 ..... int64\n",
      "num_accts_ever_120_pd:_non_zero ..... int64\n",
      "acc_now_delinq:0 ..... int64\n",
      "acc_now_delinq:non_zero ..... int64\n",
      "num_tl_30dpd:0 ..... int64\n",
      "num_tl_30dpd:non_zero ..... int64\n",
      "total_rec_late_fee:0 ..... int64\n",
      "total_rec_late_fee:non_zero ..... int64\n",
      "num_rev_tl_bal_gt_0:0 ..... int64\n",
      "num_rev_tl_bal_gt_0:1_to_5 ..... int64\n",
      "num_rev_tl_bal_gt_0:greater_than_5 ..... int64\n",
      "percent_bc_gt_75:0 ..... int64\n",
      "percent_bc_gt_75:1_to_75 ..... int64\n",
      "percent_bc_gt_75:greater_than_75 ..... int64\n",
      "revol_util:0 ..... int64\n",
      "revol_util:1_to_30 ..... int64\n",
      "revol_util:31_to_60 ..... int64\n",
      "revol_util:greater_than_60 ..... int64\n",
      "il_util:0 ..... int64\n",
      "il_util:1_to_40 ..... int64\n",
      "il_util:greater_than_40 ..... int64\n",
      "max_bal_bc:0 ..... int64\n",
      "max_bal_bc:1_to_5000 ..... int64\n",
      "max_bal_bc:5001_to_10000 ..... int64\n",
      "max_bal_bc:greater_than_10000 ..... int64\n",
      "mo_sin_old_rev_tl_op:less_than_6months ..... int64\n",
      "mo_sin_old_rev_tl_op:7months_to_24months ..... int64\n",
      "mo_sin_old_rev_tl_op:greater_than_24months ..... int64\n",
      "months_since_earliest_cr_line:less_than_78months ..... int64\n",
      "months_since_earliest_cr_line:79months_to_96months ..... int64\n",
      "months_since_earliest_cr_line:greater_than_96months ..... int64\n",
      "open_acc:less_than_5 ..... int64\n",
      "open_acc:6_to_8 ..... int64\n",
      "open_acc:greater_than_8 ..... int64\n",
      "num_sats:0_to_5 ..... int64\n",
      "num_sats:6_to_8 ..... int64\n",
      "num_sats:greater_than_8 ..... int64\n",
      "mort_acc:0 ..... int64\n",
      "mort_acc:1_to_3 ..... int64\n",
      "mort_acc:greater_than_3 ..... int64\n",
      "inq_last_6mths:0 ..... int64\n",
      "inq_last_6mths:1 ..... int64\n",
      "inq_last_6mths:greater_than_1 ..... int64\n",
      "open_il_12m:_0 ..... int64\n",
      "open_il_12m:_1 ..... int64\n",
      "open_il_12m:greater_than_1 ..... int64\n",
      "num_tl_op_past_12m:0 ..... int64\n",
      "num_tl_op_past_12m:1 ..... int64\n",
      "num_tl_op_past_12m:2 ..... int64\n",
      "num_tl_op_past_12m:3 ..... int64\n",
      "num_tl_op_past_12m:greater_than_3 ..... int64\n",
      "annual_inc:0_to_25000 ..... int64\n",
      "annual_inc:25001_to_50000 ..... int64\n",
      "annual_inc:50001_to_75000 ..... int64\n",
      "annual_inc:75001_to_100000 ..... int64\n",
      "annual_inc:greater_than_100001 ..... int64\n",
      "dti:0_to_36 ..... int64\n",
      "dti:greater_than_36 ..... int64\n",
      "emp_length_int:less_than_0 ..... int64\n",
      "emp_length_int:1_to_2 ..... int64\n",
      "emp_length_int:3_to_5 ..... int64\n",
      "emp_length_int:6_to_9 ..... int64\n",
      "emp_length_int:greater_than_9 ..... int64\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of the Input Features in the Source Model (SM) Validation Input Data\n",
    "\n",
    "for feat in sm_validation_X:\n",
    "    print(feat, \".....\", sm_train_X.dtypes[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "e5sFpV_fQ7Jv",
    "outputId": "a7279199-c48e-44f3-d181-5251511fa741"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_rec:0</th>\n",
       "      <th>pub_record:non_zero</th>\n",
       "      <th>delinq_2yrs:0</th>\n",
       "      <th>delinq_2yrs:1</th>\n",
       "      <th>delinq_2yrs:greater_than_1</th>\n",
       "      <th>num_tl_120dpd_2m:0</th>\n",
       "      <th>num_tl_120dpd_2m:non_zero</th>\n",
       "      <th>pub_rec_bankruptcies:0</th>\n",
       "      <th>pub_rec_bankruptcies:non_zero</th>\n",
       "      <th>num_tl_90g_dpd_24m:0</th>\n",
       "      <th>num_tl_90g_dpd_24m:non_zero</th>\n",
       "      <th>num_accts_ever_120_pd:0</th>\n",
       "      <th>num_accts_ever_120_pd:_non_zero</th>\n",
       "      <th>acc_now_delinq:0</th>\n",
       "      <th>acc_now_delinq:non_zero</th>\n",
       "      <th>num_tl_30dpd:0</th>\n",
       "      <th>num_tl_30dpd:non_zero</th>\n",
       "      <th>total_rec_late_fee:0</th>\n",
       "      <th>total_rec_late_fee:non_zero</th>\n",
       "      <th>num_rev_tl_bal_gt_0:0</th>\n",
       "      <th>num_rev_tl_bal_gt_0:1_to_5</th>\n",
       "      <th>num_rev_tl_bal_gt_0:greater_than_5</th>\n",
       "      <th>percent_bc_gt_75:0</th>\n",
       "      <th>percent_bc_gt_75:1_to_75</th>\n",
       "      <th>percent_bc_gt_75:greater_than_75</th>\n",
       "      <th>revol_util:0</th>\n",
       "      <th>revol_util:1_to_30</th>\n",
       "      <th>revol_util:31_to_60</th>\n",
       "      <th>revol_util:greater_than_60</th>\n",
       "      <th>il_util:0</th>\n",
       "      <th>il_util:1_to_40</th>\n",
       "      <th>il_util:greater_than_40</th>\n",
       "      <th>max_bal_bc:0</th>\n",
       "      <th>max_bal_bc:1_to_5000</th>\n",
       "      <th>max_bal_bc:5001_to_10000</th>\n",
       "      <th>max_bal_bc:greater_than_10000</th>\n",
       "      <th>mo_sin_old_rev_tl_op:less_than_6months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:7months_to_24months</th>\n",
       "      <th>mo_sin_old_rev_tl_op:greater_than_24months</th>\n",
       "      <th>months_since_earliest_cr_line:less_than_78months</th>\n",
       "      <th>months_since_earliest_cr_line:79months_to_96months</th>\n",
       "      <th>months_since_earliest_cr_line:greater_than_96months</th>\n",
       "      <th>open_acc:less_than_5</th>\n",
       "      <th>open_acc:6_to_8</th>\n",
       "      <th>open_acc:greater_than_8</th>\n",
       "      <th>num_sats:0_to_5</th>\n",
       "      <th>num_sats:6_to_8</th>\n",
       "      <th>num_sats:greater_than_8</th>\n",
       "      <th>mort_acc:0</th>\n",
       "      <th>mort_acc:1_to_3</th>\n",
       "      <th>mort_acc:greater_than_3</th>\n",
       "      <th>inq_last_6mths:0</th>\n",
       "      <th>inq_last_6mths:1</th>\n",
       "      <th>inq_last_6mths:greater_than_1</th>\n",
       "      <th>open_il_12m:_0</th>\n",
       "      <th>open_il_12m:_1</th>\n",
       "      <th>open_il_12m:greater_than_1</th>\n",
       "      <th>num_tl_op_past_12m:0</th>\n",
       "      <th>num_tl_op_past_12m:1</th>\n",
       "      <th>num_tl_op_past_12m:2</th>\n",
       "      <th>num_tl_op_past_12m:3</th>\n",
       "      <th>num_tl_op_past_12m:greater_than_3</th>\n",
       "      <th>annual_inc:0_to_25000</th>\n",
       "      <th>annual_inc:25001_to_50000</th>\n",
       "      <th>annual_inc:50001_to_75000</th>\n",
       "      <th>annual_inc:75001_to_100000</th>\n",
       "      <th>annual_inc:greater_than_100001</th>\n",
       "      <th>dti:0_to_36</th>\n",
       "      <th>dti:greater_than_36</th>\n",
       "      <th>emp_length_int:less_than_0</th>\n",
       "      <th>emp_length_int:1_to_2</th>\n",
       "      <th>emp_length_int:3_to_5</th>\n",
       "      <th>emp_length_int:6_to_9</th>\n",
       "      <th>emp_length_int:greater_than_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pub_rec:0  pub_record:non_zero  delinq_2yrs:0  delinq_2yrs:1  \\\n",
       "0          1                    0              1              0   \n",
       "1          1                    0              1              0   \n",
       "2          1                    0              1              0   \n",
       "3          0                    1              1              0   \n",
       "4          1                    0              1              0   \n",
       "\n",
       "   delinq_2yrs:greater_than_1  num_tl_120dpd_2m:0  num_tl_120dpd_2m:non_zero  \\\n",
       "0                           0                   1                          0   \n",
       "1                           0                   1                          0   \n",
       "2                           0                   1                          0   \n",
       "3                           0                   1                          0   \n",
       "4                           0                   1                          0   \n",
       "\n",
       "   pub_rec_bankruptcies:0  pub_rec_bankruptcies:non_zero  \\\n",
       "0                       1                              0   \n",
       "1                       1                              0   \n",
       "2                       1                              0   \n",
       "3                       1                              0   \n",
       "4                       1                              0   \n",
       "\n",
       "   num_tl_90g_dpd_24m:0  num_tl_90g_dpd_24m:non_zero  num_accts_ever_120_pd:0  \\\n",
       "0                     1                            0                        1   \n",
       "1                     1                            0                        0   \n",
       "2                     1                            0                        1   \n",
       "3                     1                            0                        1   \n",
       "4                     1                            0                        0   \n",
       "\n",
       "   num_accts_ever_120_pd:_non_zero  acc_now_delinq:0  acc_now_delinq:non_zero  \\\n",
       "0                                0                 1                        0   \n",
       "1                                1                 1                        0   \n",
       "2                                0                 1                        0   \n",
       "3                                0                 1                        0   \n",
       "4                                1                 1                        0   \n",
       "\n",
       "   num_tl_30dpd:0  num_tl_30dpd:non_zero  total_rec_late_fee:0  \\\n",
       "0               1                      0                     1   \n",
       "1               1                      0                     1   \n",
       "2               1                      0                     1   \n",
       "3               1                      0                     1   \n",
       "4               1                      0                     1   \n",
       "\n",
       "   total_rec_late_fee:non_zero  num_rev_tl_bal_gt_0:0  \\\n",
       "0                            0                      0   \n",
       "1                            0                      0   \n",
       "2                            0                      0   \n",
       "3                            0                      0   \n",
       "4                            0                      0   \n",
       "\n",
       "   num_rev_tl_bal_gt_0:1_to_5  num_rev_tl_bal_gt_0:greater_than_5  \\\n",
       "0                           1                                   0   \n",
       "1                           0                                   1   \n",
       "2                           0                                   1   \n",
       "3                           0                                   1   \n",
       "4                           0                                   1   \n",
       "\n",
       "   percent_bc_gt_75:0  percent_bc_gt_75:1_to_75  \\\n",
       "0                   1                         0   \n",
       "1                   1                         0   \n",
       "2                   0                         0   \n",
       "3                   1                         0   \n",
       "4                   1                         0   \n",
       "\n",
       "   percent_bc_gt_75:greater_than_75  revol_util:0  revol_util:1_to_30  \\\n",
       "0                                 0             0                   0   \n",
       "1                                 0             0                   1   \n",
       "2                                 1             0                   0   \n",
       "3                                 0             0                   1   \n",
       "4                                 0             0                   0   \n",
       "\n",
       "   revol_util:31_to_60  revol_util:greater_than_60  il_util:0  \\\n",
       "0                    1                           0          0   \n",
       "1                    0                           0          0   \n",
       "2                    0                           1          1   \n",
       "3                    0                           0          0   \n",
       "4                    1                           0          0   \n",
       "\n",
       "   il_util:1_to_40  il_util:greater_than_40  max_bal_bc:0  \\\n",
       "0                0                        1             0   \n",
       "1                0                        1             0   \n",
       "2                0                        0             1   \n",
       "3                0                        1             0   \n",
       "4                0                        1             0   \n",
       "\n",
       "   max_bal_bc:1_to_5000  max_bal_bc:5001_to_10000  \\\n",
       "0                     1                         0   \n",
       "1                     1                         0   \n",
       "2                     0                         0   \n",
       "3                     0                         1   \n",
       "4                     0                         1   \n",
       "\n",
       "   max_bal_bc:greater_than_10000  mo_sin_old_rev_tl_op:less_than_6months  \\\n",
       "0                              0                                       0   \n",
       "1                              0                                       0   \n",
       "2                              0                                       0   \n",
       "3                              0                                       0   \n",
       "4                              0                                       0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:7months_to_24months  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   mo_sin_old_rev_tl_op:greater_than_24months  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "   months_since_earliest_cr_line:less_than_78months  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   months_since_earliest_cr_line:79months_to_96months  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   months_since_earliest_cr_line:greater_than_96months  open_acc:less_than_5  \\\n",
       "0                                                  1                       0   \n",
       "1                                                  1                       0   \n",
       "2                                                  1                       0   \n",
       "3                                                  1                       0   \n",
       "4                                                  1                       0   \n",
       "\n",
       "   open_acc:6_to_8  open_acc:greater_than_8  num_sats:0_to_5  num_sats:6_to_8  \\\n",
       "0                1                        0                0                1   \n",
       "1                0                        1                0                0   \n",
       "2                0                        1                0                0   \n",
       "3                0                        1                0                0   \n",
       "4                0                        1                0                0   \n",
       "\n",
       "   num_sats:greater_than_8  mort_acc:0  mort_acc:1_to_3  \\\n",
       "0                        0           0                1   \n",
       "1                        1           1                0   \n",
       "2                        1           1                0   \n",
       "3                        1           0                1   \n",
       "4                        1           1                0   \n",
       "\n",
       "   mort_acc:greater_than_3  inq_last_6mths:0  inq_last_6mths:1  \\\n",
       "0                        0                 0                 1   \n",
       "1                        0                 0                 1   \n",
       "2                        0                 1                 0   \n",
       "3                        0                 0                 1   \n",
       "4                        0                 0                 1   \n",
       "\n",
       "   inq_last_6mths:greater_than_1  open_il_12m:_0  open_il_12m:_1  \\\n",
       "0                              0               0               0   \n",
       "1                              0               0               1   \n",
       "2                              0               1               0   \n",
       "3                              0               0               0   \n",
       "4                              0               0               0   \n",
       "\n",
       "   open_il_12m:greater_than_1  num_tl_op_past_12m:0  num_tl_op_past_12m:1  \\\n",
       "0                           1                     0                     0   \n",
       "1                           0                     0                     0   \n",
       "2                           0                     0                     0   \n",
       "3                           1                     0                     0   \n",
       "4                           1                     0                     0   \n",
       "\n",
       "   num_tl_op_past_12m:2  num_tl_op_past_12m:3  \\\n",
       "0                     0                     1   \n",
       "1                     0                     0   \n",
       "2                     0                     1   \n",
       "3                     0                     0   \n",
       "4                     0                     0   \n",
       "\n",
       "   num_tl_op_past_12m:greater_than_3  annual_inc:0_to_25000  \\\n",
       "0                                  0                      0   \n",
       "1                                  1                      0   \n",
       "2                                  0                      0   \n",
       "3                                  1                      0   \n",
       "4                                  1                      0   \n",
       "\n",
       "   annual_inc:25001_to_50000  annual_inc:50001_to_75000  \\\n",
       "0                          1                          0   \n",
       "1                          0                          1   \n",
       "2                          0                          1   \n",
       "3                          0                          0   \n",
       "4                          0                          1   \n",
       "\n",
       "   annual_inc:75001_to_100000  annual_inc:greater_than_100001  dti:0_to_36  \\\n",
       "0                           0                               0            1   \n",
       "1                           0                               0            1   \n",
       "2                           0                               0            1   \n",
       "3                           0                               1            1   \n",
       "4                           0                               0            1   \n",
       "\n",
       "   dti:greater_than_36  emp_length_int:less_than_0  emp_length_int:1_to_2  \\\n",
       "0                    0                           0                      0   \n",
       "1                    0                           1                      0   \n",
       "2                    0                           0                      0   \n",
       "3                    0                           0                      1   \n",
       "4                    0                           0                      0   \n",
       "\n",
       "   emp_length_int:3_to_5  emp_length_int:6_to_9  emp_length_int:greater_than_9  \n",
       "0                      1                      0                              0  \n",
       "1                      0                      0                              0  \n",
       "2                      0                      0                              1  \n",
       "3                      0                      0                              0  \n",
       "4                      0                      0                              1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displying the first 5 data instances\n",
    "\n",
    "sm_validation_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt8KS0-RQy42"
   },
   "source": [
    "### **Source Model (SM) Validation Output Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1cNLC2hQy43",
    "outputId": "616488f4-c7f6-4b62-eeee-b89e228a3071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Sets the pandas dataframe options to display all columns/ rows.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBOoi-P-Qy43",
    "outputId": "906a8c76-a2d1-4aa3-b0ea-e00e0f458166"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'score_status'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 3 column names of the dataset\n",
    "\n",
    "sm_validation_y.columns[[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHuExD77Qy44",
    "outputId": "9f6844ed-6e75-49c8-90b5-6732dfcc2a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Removing the first index column from the dataset\n",
    "\n",
    "sm_validation_y.drop(sm_validation_y.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wE9j3HG6Qy44",
    "outputId": "97b8f318-cee0-463c-8349-5084ed2f61a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83885, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-checking the size of the dataset\n",
    "\n",
    "sm_validation_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "aSQSFEHhQy44",
    "outputId": "2e381ca9-d6d6-426a-94de-8875aa0b41b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score_status\n",
       "0             1\n",
       "1             1\n",
       "2             0\n",
       "3             1\n",
       "4             1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displying the first 5 data instances\n",
    "\n",
    "sm_validation_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ATESNKFTPnQ"
   },
   "source": [
    "# **4. Deep Learning : Neural Networks - Source Model (SM) Definition and Creation - \"adam\" Optimiser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3fIHEZrpPv3"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# Defining the Model\n",
    "\n",
    "sm_model_adam = tf.keras.Sequential([\n",
    "    keras.layers.Dense(74, input_shape=(74,), activation='relu'),\n",
    "    keras.layers.Dense(70, activation='relu'),\n",
    "    keras.layers.Dense(66, activation='relu'),\n",
    "    keras.layers.Dense(60, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the Model\n",
    "\n",
    "#optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "optim = tf.keras.optimizers.Adam()\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = 'accuracy'\n",
    "\n",
    "sm_model_adam.compile(\n",
    "    optimizer=optim,\n",
    "    loss=loss,\n",
    "    metrics=[metrics])\n",
    "\n",
    "print(\"Model Created.....\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k57egxn08cqN",
    "outputId": "0cf43373-f0e4-4157-9831-e136fe65690c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed.....\n"
     ]
    }
   ],
   "source": [
    "# Function to Create a New Deep Learning Model\n",
    "\n",
    "def create_model(lr):\n",
    "\n",
    "    # Defining the Model\n",
    "\n",
    "    sm_model_adam = tf.keras.Sequential([\n",
    "      keras.layers.Dense(74, input_shape=(74,), activation='relu'),\n",
    "      keras.layers.Dense(70, activation='relu'),\n",
    "      keras.layers.Dense(66, activation='relu'),\n",
    "      keras.layers.Dense(60, activation='relu'),\n",
    "      keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compiling the Model\n",
    "\n",
    "    #optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    loss = 'binary_crossentropy'\n",
    "    metrics = 'accuracy'\n",
    "\n",
    "    sm_model_adam.compile(\n",
    "    optimizer=optim,\n",
    "    loss=loss,\n",
    "    metrics=[metrics])\n",
    "\n",
    "    print(\"Model Created.....\")\n",
    "\n",
    "    return sm_model_adam\n",
    "\n",
    "print(\"Execution Completed.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3sY3R-V9A1B",
    "outputId": "4dd20e39-11e0-4e8f-c656-6cd7372127ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created.....\n",
      "Execution Completed.....\n"
     ]
    }
   ],
   "source": [
    "# Executing the Created Model\n",
    "lr = 0.001\n",
    "\n",
    "sm_model_adam = create_model(lr)\n",
    "\n",
    "print(\"Execution Completed.....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLWrgITGrdpp"
   },
   "source": [
    "# **5. Deep Learning : Neural Networks - Source Model (SM) Training - \"adam\" Optimiser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFdJxic78CB4",
    "outputId": "ae2d6062-98aa-46ad-905a-7c07bfaf915e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5596 - accuracy: 0.6999 - val_loss: 0.7154 - val_accuracy: 0.6226\n",
      "Epoch 7502/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7191 - val_accuracy: 0.6203\n",
      "Epoch 7503/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7094 - val_accuracy: 0.6266\n",
      "Epoch 7504/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5599 - accuracy: 0.6997 - val_loss: 0.7222 - val_accuracy: 0.6159\n",
      "Epoch 7505/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7109 - val_accuracy: 0.6287\n",
      "Epoch 7506/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5602 - accuracy: 0.6992 - val_loss: 0.7204 - val_accuracy: 0.6173\n",
      "Epoch 7507/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7102 - val_accuracy: 0.6260\n",
      "Epoch 7508/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7187 - val_accuracy: 0.6210\n",
      "Epoch 7509/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7165 - val_accuracy: 0.6217\n",
      "Epoch 7510/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7137 - val_accuracy: 0.6233\n",
      "Epoch 7511/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7179 - val_accuracy: 0.6203\n",
      "Epoch 7512/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7131 - val_accuracy: 0.6251\n",
      "Epoch 7513/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7196 - val_accuracy: 0.6186\n",
      "Epoch 7514/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5595 - accuracy: 0.6994 - val_loss: 0.7104 - val_accuracy: 0.6258\n",
      "Epoch 7515/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7210 - val_accuracy: 0.6185\n",
      "Epoch 7516/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7103 - val_accuracy: 0.6263\n",
      "Epoch 7517/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7204 - val_accuracy: 0.6177\n",
      "Epoch 7518/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7116 - val_accuracy: 0.6260\n",
      "Epoch 7519/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7207 - val_accuracy: 0.6188\n",
      "Epoch 7520/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7111 - val_accuracy: 0.6266\n",
      "Epoch 7521/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7175 - val_accuracy: 0.6203\n",
      "Epoch 7522/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7156 - val_accuracy: 0.6225\n",
      "Epoch 7523/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7149 - val_accuracy: 0.6222\n",
      "Epoch 7524/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7185 - val_accuracy: 0.6204\n",
      "Epoch 7525/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7120 - val_accuracy: 0.6256\n",
      "Epoch 7526/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7226 - val_accuracy: 0.6162\n",
      "Epoch 7527/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7082 - val_accuracy: 0.6293\n",
      "Epoch 7528/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7237 - val_accuracy: 0.6162\n",
      "Epoch 7529/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7086 - val_accuracy: 0.6277\n",
      "Epoch 7530/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7222 - val_accuracy: 0.6161\n",
      "Epoch 7531/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7111 - val_accuracy: 0.6274\n",
      "Epoch 7532/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7206 - val_accuracy: 0.6184\n",
      "Epoch 7533/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7131 - val_accuracy: 0.6239\n",
      "Epoch 7534/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7162 - val_accuracy: 0.6227\n",
      "Epoch 7535/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7187 - val_accuracy: 0.6214\n",
      "Epoch 7536/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7103 - val_accuracy: 0.6254\n",
      "Epoch 7537/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7223 - val_accuracy: 0.6167\n",
      "Epoch 7538/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7105 - val_accuracy: 0.6285\n",
      "Epoch 7539/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7238 - val_accuracy: 0.6147\n",
      "Epoch 7540/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7074 - val_accuracy: 0.6288\n",
      "Epoch 7541/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7237 - val_accuracy: 0.6159\n",
      "Epoch 7542/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7111 - val_accuracy: 0.6270\n",
      "Epoch 7543/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7196 - val_accuracy: 0.6193\n",
      "Epoch 7544/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7137 - val_accuracy: 0.6244\n",
      "Epoch 7545/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7153 - val_accuracy: 0.6219\n",
      "Epoch 7546/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7172 - val_accuracy: 0.6204\n",
      "Epoch 7547/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7128 - val_accuracy: 0.6252\n",
      "Epoch 7548/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7206 - val_accuracy: 0.6189\n",
      "Epoch 7549/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7106 - val_accuracy: 0.6266\n",
      "Epoch 7550/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5599 - accuracy: 0.6997 - val_loss: 0.7218 - val_accuracy: 0.6163\n",
      "Epoch 7551/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7102 - val_accuracy: 0.6272\n",
      "Epoch 7552/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7193 - val_accuracy: 0.6187\n",
      "Epoch 7553/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7146 - val_accuracy: 0.6237\n",
      "Epoch 7554/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7151 - val_accuracy: 0.6232\n",
      "Epoch 7555/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7195 - val_accuracy: 0.6189\n",
      "Epoch 7556/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7085 - val_accuracy: 0.6287\n",
      "Epoch 7557/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7264 - val_accuracy: 0.6138\n",
      "Epoch 7558/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5598 - accuracy: 0.6992 - val_loss: 0.7070 - val_accuracy: 0.6295\n",
      "Epoch 7559/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7240 - val_accuracy: 0.6145\n",
      "Epoch 7560/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5603 - accuracy: 0.6988 - val_loss: 0.7076 - val_accuracy: 0.6297\n",
      "Epoch 7561/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7225 - val_accuracy: 0.6170\n",
      "Epoch 7562/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5597 - accuracy: 0.6992 - val_loss: 0.7116 - val_accuracy: 0.6234\n",
      "Epoch 7563/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7158 - val_accuracy: 0.6224\n",
      "Epoch 7564/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7183 - val_accuracy: 0.6208\n",
      "Epoch 7565/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7111 - val_accuracy: 0.6241\n",
      "Epoch 7566/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5597 - accuracy: 0.6999 - val_loss: 0.7205 - val_accuracy: 0.6179\n",
      "Epoch 7567/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7100 - val_accuracy: 0.6286\n",
      "Epoch 7568/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7239 - val_accuracy: 0.6157\n",
      "Epoch 7569/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7110 - val_accuracy: 0.6263\n",
      "Epoch 7570/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5597 - accuracy: 0.6998 - val_loss: 0.7195 - val_accuracy: 0.6193\n",
      "Epoch 7571/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7114 - val_accuracy: 0.6256\n",
      "Epoch 7572/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7198 - val_accuracy: 0.6197\n",
      "Epoch 7573/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7168 - val_accuracy: 0.6223\n",
      "Epoch 7574/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7135 - val_accuracy: 0.6238\n",
      "Epoch 7575/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7183 - val_accuracy: 0.6209\n",
      "Epoch 7576/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7139 - val_accuracy: 0.6251\n",
      "Epoch 7577/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7196 - val_accuracy: 0.6173\n",
      "Epoch 7578/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7110 - val_accuracy: 0.6262\n",
      "Epoch 7579/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5593 - accuracy: 0.7001 - val_loss: 0.7218 - val_accuracy: 0.6199\n",
      "Epoch 7580/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7099 - val_accuracy: 0.6248\n",
      "Epoch 7581/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5598 - accuracy: 0.6998 - val_loss: 0.7217 - val_accuracy: 0.6155\n",
      "Epoch 7582/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7106 - val_accuracy: 0.6303\n",
      "Epoch 7583/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7220 - val_accuracy: 0.6166\n",
      "Epoch 7584/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7113 - val_accuracy: 0.6251\n",
      "Epoch 7585/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5595 - accuracy: 0.7001 - val_loss: 0.7204 - val_accuracy: 0.6201\n",
      "Epoch 7586/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7136 - val_accuracy: 0.6241\n",
      "Epoch 7587/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7165 - val_accuracy: 0.6214\n",
      "Epoch 7588/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7177 - val_accuracy: 0.6219\n",
      "Epoch 7589/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7162 - val_accuracy: 0.6229\n",
      "Epoch 7590/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7166 - val_accuracy: 0.6216\n",
      "Epoch 7591/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7140 - val_accuracy: 0.6238\n",
      "Epoch 7592/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7199 - val_accuracy: 0.6200\n",
      "Epoch 7593/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7119 - val_accuracy: 0.6255\n",
      "Epoch 7594/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7215 - val_accuracy: 0.6186\n",
      "Epoch 7595/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7116 - val_accuracy: 0.6268\n",
      "Epoch 7596/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7210 - val_accuracy: 0.6174\n",
      "Epoch 7597/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7098 - val_accuracy: 0.6275\n",
      "Epoch 7598/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7240 - val_accuracy: 0.6165\n",
      "Epoch 7599/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7073 - val_accuracy: 0.6283\n",
      "Epoch 7600/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7262 - val_accuracy: 0.6132\n",
      "Epoch 7601/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7071 - val_accuracy: 0.6318\n",
      "Epoch 7602/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7272 - val_accuracy: 0.6120\n",
      "Epoch 7603/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7066 - val_accuracy: 0.6306\n",
      "Epoch 7604/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7252 - val_accuracy: 0.6152\n",
      "Epoch 7605/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7070 - val_accuracy: 0.6281\n",
      "Epoch 7606/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6998 - val_loss: 0.7236 - val_accuracy: 0.6152\n",
      "Epoch 7607/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7131 - val_accuracy: 0.6274\n",
      "Epoch 7608/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7165 - val_accuracy: 0.6199\n",
      "Epoch 7609/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7167 - val_accuracy: 0.6210\n",
      "Epoch 7610/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7141 - val_accuracy: 0.6267\n",
      "Epoch 7611/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7195 - val_accuracy: 0.6167\n",
      "Epoch 7612/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7099 - val_accuracy: 0.6257\n",
      "Epoch 7613/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7221 - val_accuracy: 0.6201\n",
      "Epoch 7614/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7120 - val_accuracy: 0.6237\n",
      "Epoch 7615/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7183 - val_accuracy: 0.6187\n",
      "Epoch 7616/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7141 - val_accuracy: 0.6258\n",
      "Epoch 7617/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7174 - val_accuracy: 0.6204\n",
      "Epoch 7618/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7156 - val_accuracy: 0.6217\n",
      "Epoch 7619/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7162 - val_accuracy: 0.6238\n",
      "Epoch 7620/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7179 - val_accuracy: 0.6213\n",
      "Epoch 7621/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7132 - val_accuracy: 0.6227\n",
      "Epoch 7622/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7174 - val_accuracy: 0.6218\n",
      "Epoch 7623/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7157 - val_accuracy: 0.6230\n",
      "Epoch 7624/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7168 - val_accuracy: 0.6205\n",
      "Epoch 7625/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7143 - val_accuracy: 0.6235\n",
      "Epoch 7626/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7176 - val_accuracy: 0.6216\n",
      "Epoch 7627/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7165 - val_accuracy: 0.6218\n",
      "Epoch 7628/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7156 - val_accuracy: 0.6225\n",
      "Epoch 7629/10000\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7177 - val_accuracy: 0.6217\n",
      "Epoch 7630/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7154 - val_accuracy: 0.6231\n",
      "Epoch 7631/10000\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7170 - val_accuracy: 0.6211\n",
      "Epoch 7632/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7143 - val_accuracy: 0.6245\n",
      "Epoch 7633/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7207 - val_accuracy: 0.6198\n",
      "Epoch 7634/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7120 - val_accuracy: 0.6252\n",
      "Epoch 7635/10000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7216 - val_accuracy: 0.6177\n",
      "Epoch 7636/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7107 - val_accuracy: 0.6283\n",
      "Epoch 7637/10000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7238 - val_accuracy: 0.6149\n",
      "Epoch 7638/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7071 - val_accuracy: 0.6296\n",
      "Epoch 7639/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7276 - val_accuracy: 0.6136\n",
      "Epoch 7640/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7045 - val_accuracy: 0.6318\n",
      "Epoch 7641/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5603 - accuracy: 0.6993 - val_loss: 0.7300 - val_accuracy: 0.6093\n",
      "Epoch 7642/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5602 - accuracy: 0.6989 - val_loss: 0.7052 - val_accuracy: 0.6335\n",
      "Epoch 7643/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5606 - accuracy: 0.6989 - val_loss: 0.7255 - val_accuracy: 0.6126\n",
      "Epoch 7644/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5603 - accuracy: 0.6989 - val_loss: 0.7072 - val_accuracy: 0.6279\n",
      "Epoch 7645/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5598 - accuracy: 0.6999 - val_loss: 0.7210 - val_accuracy: 0.6204\n",
      "Epoch 7646/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7151 - val_accuracy: 0.6225\n",
      "Epoch 7647/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7141 - val_accuracy: 0.6227\n",
      "Epoch 7648/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7209 - val_accuracy: 0.6198\n",
      "Epoch 7649/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7103 - val_accuracy: 0.6271\n",
      "Epoch 7650/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7232 - val_accuracy: 0.6154\n",
      "Epoch 7651/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7090 - val_accuracy: 0.6298\n",
      "Epoch 7652/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7239 - val_accuracy: 0.6156\n",
      "Epoch 7653/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7106 - val_accuracy: 0.6262\n",
      "Epoch 7654/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7184 - val_accuracy: 0.6209\n",
      "Epoch 7655/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7166 - val_accuracy: 0.6223\n",
      "Epoch 7656/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7165 - val_accuracy: 0.6214\n",
      "Epoch 7657/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7166 - val_accuracy: 0.6222\n",
      "Epoch 7658/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7139 - val_accuracy: 0.6243\n",
      "Epoch 7659/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7188 - val_accuracy: 0.6200\n",
      "Epoch 7660/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7156 - val_accuracy: 0.6231\n",
      "Epoch 7661/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7181 - val_accuracy: 0.6213\n",
      "Epoch 7662/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7130 - val_accuracy: 0.6247\n",
      "Epoch 7663/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7213 - val_accuracy: 0.6185\n",
      "Epoch 7664/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7137 - val_accuracy: 0.6260\n",
      "Epoch 7665/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7196 - val_accuracy: 0.6191\n",
      "Epoch 7666/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7113 - val_accuracy: 0.6257\n",
      "Epoch 7667/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7236 - val_accuracy: 0.6176\n",
      "Epoch 7668/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7100 - val_accuracy: 0.6263\n",
      "Epoch 7669/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7234 - val_accuracy: 0.6155\n",
      "Epoch 7670/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7090 - val_accuracy: 0.6300\n",
      "Epoch 7671/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7249 - val_accuracy: 0.6144\n",
      "Epoch 7672/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7095 - val_accuracy: 0.6281\n",
      "Epoch 7673/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7218 - val_accuracy: 0.6177\n",
      "Epoch 7674/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7129 - val_accuracy: 0.6255\n",
      "Epoch 7675/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7194 - val_accuracy: 0.6199\n",
      "Epoch 7676/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7156 - val_accuracy: 0.6233\n",
      "Epoch 7677/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7151 - val_accuracy: 0.6230\n",
      "Epoch 7678/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7186 - val_accuracy: 0.6200\n",
      "Epoch 7679/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7139 - val_accuracy: 0.6249\n",
      "Epoch 7680/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7175 - val_accuracy: 0.6211\n",
      "Epoch 7681/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5599 - accuracy: 0.6991 - val_loss: 0.7140 - val_accuracy: 0.6227\n",
      "Epoch 7682/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7205 - val_accuracy: 0.6203\n",
      "Epoch 7683/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7122 - val_accuracy: 0.6263\n",
      "Epoch 7684/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7193 - val_accuracy: 0.6189\n",
      "Epoch 7685/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5596 - accuracy: 0.6993 - val_loss: 0.7148 - val_accuracy: 0.6234\n",
      "Epoch 7686/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7180 - val_accuracy: 0.6215\n",
      "Epoch 7687/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7148 - val_accuracy: 0.6229\n",
      "Epoch 7688/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5598 - accuracy: 0.6997 - val_loss: 0.7154 - val_accuracy: 0.6217\n",
      "Epoch 7689/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7181 - val_accuracy: 0.6224\n",
      "Epoch 7690/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7165 - val_accuracy: 0.6212\n",
      "Epoch 7691/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7148 - val_accuracy: 0.6223\n",
      "Epoch 7692/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7140 - val_accuracy: 0.6246\n",
      "Epoch 7693/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7221 - val_accuracy: 0.6184\n",
      "Epoch 7694/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7091 - val_accuracy: 0.6254\n",
      "Epoch 7695/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5605 - accuracy: 0.6991 - val_loss: 0.7207 - val_accuracy: 0.6169\n",
      "Epoch 7696/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5598 - accuracy: 0.6991 - val_loss: 0.7129 - val_accuracy: 0.6275\n",
      "Epoch 7697/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5603 - accuracy: 0.6992 - val_loss: 0.7191 - val_accuracy: 0.6189\n",
      "Epoch 7698/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5606 - accuracy: 0.6989 - val_loss: 0.7125 - val_accuracy: 0.6226\n",
      "Epoch 7699/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5597 - accuracy: 0.6998 - val_loss: 0.7159 - val_accuracy: 0.6239\n",
      "Epoch 7700/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7204 - val_accuracy: 0.6205\n",
      "Epoch 7701/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7098 - val_accuracy: 0.6248\n",
      "Epoch 7702/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7222 - val_accuracy: 0.6157\n",
      "Epoch 7703/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5606 - accuracy: 0.6987 - val_loss: 0.7096 - val_accuracy: 0.6292\n",
      "Epoch 7704/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7229 - val_accuracy: 0.6172\n",
      "Epoch 7705/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5604 - accuracy: 0.6991 - val_loss: 0.7084 - val_accuracy: 0.6263\n",
      "Epoch 7706/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5607 - accuracy: 0.6989 - val_loss: 0.7207 - val_accuracy: 0.6173\n",
      "Epoch 7707/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5605 - accuracy: 0.6987 - val_loss: 0.7113 - val_accuracy: 0.6263\n",
      "Epoch 7708/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5600 - accuracy: 0.6995 - val_loss: 0.7201 - val_accuracy: 0.6186\n",
      "Epoch 7709/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5608 - accuracy: 0.6990 - val_loss: 0.7088 - val_accuracy: 0.6265\n",
      "Epoch 7710/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5610 - accuracy: 0.6988 - val_loss: 0.7199 - val_accuracy: 0.6173\n",
      "Epoch 7711/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5610 - accuracy: 0.6984 - val_loss: 0.7131 - val_accuracy: 0.6241\n",
      "Epoch 7712/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5603 - accuracy: 0.6994 - val_loss: 0.7168 - val_accuracy: 0.6208\n",
      "Epoch 7713/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5606 - accuracy: 0.6991 - val_loss: 0.7123 - val_accuracy: 0.6243\n",
      "Epoch 7714/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5602 - accuracy: 0.6992 - val_loss: 0.7163 - val_accuracy: 0.6219\n",
      "Epoch 7715/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5604 - accuracy: 0.6988 - val_loss: 0.7175 - val_accuracy: 0.6210\n",
      "Epoch 7716/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7156 - val_accuracy: 0.6214\n",
      "Epoch 7717/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7117 - val_accuracy: 0.6250\n",
      "Epoch 7718/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5601 - accuracy: 0.6994 - val_loss: 0.7188 - val_accuracy: 0.6206\n",
      "Epoch 7719/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7147 - val_accuracy: 0.6238\n",
      "Epoch 7720/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7209 - val_accuracy: 0.6176\n",
      "Epoch 7721/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7073 - val_accuracy: 0.6283\n",
      "Epoch 7722/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7218 - val_accuracy: 0.6182\n",
      "Epoch 7723/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7122 - val_accuracy: 0.6256\n",
      "Epoch 7724/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7227 - val_accuracy: 0.6153\n",
      "Epoch 7725/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5600 - accuracy: 0.6991 - val_loss: 0.7091 - val_accuracy: 0.6278\n",
      "Epoch 7726/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5596 - accuracy: 0.6999 - val_loss: 0.7187 - val_accuracy: 0.6206\n",
      "Epoch 7727/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7152 - val_accuracy: 0.6226\n",
      "Epoch 7728/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7166 - val_accuracy: 0.6207\n",
      "Epoch 7729/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7170 - val_accuracy: 0.6210\n",
      "Epoch 7730/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7138 - val_accuracy: 0.6257\n",
      "Epoch 7731/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7201 - val_accuracy: 0.6198\n",
      "Epoch 7732/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7110 - val_accuracy: 0.6242\n",
      "Epoch 7733/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7207 - val_accuracy: 0.6177\n",
      "Epoch 7734/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7138 - val_accuracy: 0.6260\n",
      "Epoch 7735/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7191 - val_accuracy: 0.6201\n",
      "Epoch 7736/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7100 - val_accuracy: 0.6248\n",
      "Epoch 7737/10000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7200 - val_accuracy: 0.6181\n",
      "Epoch 7738/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5601 - accuracy: 0.6991 - val_loss: 0.7130 - val_accuracy: 0.6254\n",
      "Epoch 7739/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7204 - val_accuracy: 0.6189\n",
      "Epoch 7740/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5604 - accuracy: 0.6992 - val_loss: 0.7082 - val_accuracy: 0.6268\n",
      "Epoch 7741/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5607 - accuracy: 0.6990 - val_loss: 0.7212 - val_accuracy: 0.6165\n",
      "Epoch 7742/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5609 - accuracy: 0.6986 - val_loss: 0.7105 - val_accuracy: 0.6263\n",
      "Epoch 7743/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5601 - accuracy: 0.6996 - val_loss: 0.7190 - val_accuracy: 0.6193\n",
      "Epoch 7744/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5605 - accuracy: 0.6989 - val_loss: 0.7109 - val_accuracy: 0.6254\n",
      "Epoch 7745/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7193 - val_accuracy: 0.6192\n",
      "Epoch 7746/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5600 - accuracy: 0.6991 - val_loss: 0.7159 - val_accuracy: 0.6225\n",
      "Epoch 7747/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7144 - val_accuracy: 0.6223\n",
      "Epoch 7748/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7145 - val_accuracy: 0.6233\n",
      "Epoch 7749/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7158 - val_accuracy: 0.6234\n",
      "Epoch 7750/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7200 - val_accuracy: 0.6192\n",
      "Epoch 7751/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5600 - accuracy: 0.6990 - val_loss: 0.7133 - val_accuracy: 0.6225\n",
      "Epoch 7752/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7136 - val_accuracy: 0.6239\n",
      "Epoch 7753/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7173 - val_accuracy: 0.6224\n",
      "Epoch 7754/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7174 - val_accuracy: 0.6214\n",
      "Epoch 7755/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7182 - val_accuracy: 0.6202\n",
      "Epoch 7756/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7122 - val_accuracy: 0.6262\n",
      "Epoch 7757/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7189 - val_accuracy: 0.6211\n",
      "Epoch 7758/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7157 - val_accuracy: 0.6233\n",
      "Epoch 7759/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7190 - val_accuracy: 0.6198\n",
      "Epoch 7760/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7135 - val_accuracy: 0.6243\n",
      "Epoch 7761/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7182 - val_accuracy: 0.6216\n",
      "Epoch 7762/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7147 - val_accuracy: 0.6233\n",
      "Epoch 7763/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7196 - val_accuracy: 0.6193\n",
      "Epoch 7764/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7139 - val_accuracy: 0.6247\n",
      "Epoch 7765/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7189 - val_accuracy: 0.6210\n",
      "Epoch 7766/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7131 - val_accuracy: 0.6246\n",
      "Epoch 7767/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7188 - val_accuracy: 0.6205\n",
      "Epoch 7768/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7157 - val_accuracy: 0.6230\n",
      "Epoch 7769/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7176 - val_accuracy: 0.6215\n",
      "Epoch 7770/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7153 - val_accuracy: 0.6225\n",
      "Epoch 7771/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7172 - val_accuracy: 0.6221\n",
      "Epoch 7772/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7161 - val_accuracy: 0.6229\n",
      "Epoch 7773/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7183 - val_accuracy: 0.6210\n",
      "Epoch 7774/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7149 - val_accuracy: 0.6240\n",
      "Epoch 7775/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7185 - val_accuracy: 0.6209\n",
      "Epoch 7776/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7144 - val_accuracy: 0.6242\n",
      "Epoch 7777/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7222 - val_accuracy: 0.6190\n",
      "Epoch 7778/10000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7100 - val_accuracy: 0.6273\n",
      "Epoch 7779/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7252 - val_accuracy: 0.6150\n",
      "Epoch 7780/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7066 - val_accuracy: 0.6318\n",
      "Epoch 7781/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7315 - val_accuracy: 0.6090\n",
      "Epoch 7782/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5605 - accuracy: 0.6987 - val_loss: 0.7008 - val_accuracy: 0.6354\n",
      "Epoch 7783/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5610 - accuracy: 0.6985 - val_loss: 0.7340 - val_accuracy: 0.6070\n",
      "Epoch 7784/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5611 - accuracy: 0.6980 - val_loss: 0.7011 - val_accuracy: 0.6355\n",
      "Epoch 7785/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5610 - accuracy: 0.6984 - val_loss: 0.7299 - val_accuracy: 0.6100\n",
      "Epoch 7786/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5601 - accuracy: 0.6989 - val_loss: 0.7113 - val_accuracy: 0.6277\n",
      "Epoch 7787/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7163 - val_accuracy: 0.6214\n",
      "Epoch 7788/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7195 - val_accuracy: 0.6193\n",
      "Epoch 7789/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7099 - val_accuracy: 0.6299\n",
      "Epoch 7790/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7289 - val_accuracy: 0.6110\n",
      "Epoch 7791/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5601 - accuracy: 0.6990 - val_loss: 0.7044 - val_accuracy: 0.6322\n",
      "Epoch 7792/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7296 - val_accuracy: 0.6122\n",
      "Epoch 7793/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7069 - val_accuracy: 0.6304\n",
      "Epoch 7794/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7238 - val_accuracy: 0.6147\n",
      "Epoch 7795/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7139 - val_accuracy: 0.6258\n",
      "Epoch 7796/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7147 - val_accuracy: 0.6240\n",
      "Epoch 7797/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7234 - val_accuracy: 0.6152\n",
      "Epoch 7798/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7080 - val_accuracy: 0.6308\n",
      "Epoch 7799/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7277 - val_accuracy: 0.6131\n",
      "Epoch 7800/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7057 - val_accuracy: 0.6302\n",
      "Epoch 7801/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5602 - accuracy: 0.6994 - val_loss: 0.7266 - val_accuracy: 0.6129\n",
      "Epoch 7802/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7115 - val_accuracy: 0.6285\n",
      "Epoch 7803/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7180 - val_accuracy: 0.6203\n",
      "Epoch 7804/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7196 - val_accuracy: 0.6195\n",
      "Epoch 7805/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7112 - val_accuracy: 0.6282\n",
      "Epoch 7806/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7256 - val_accuracy: 0.6140\n",
      "Epoch 7807/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7074 - val_accuracy: 0.6298\n",
      "Epoch 7808/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7277 - val_accuracy: 0.6139\n",
      "Epoch 7809/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5597 - accuracy: 0.6991 - val_loss: 0.7074 - val_accuracy: 0.6290\n",
      "Epoch 7810/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7229 - val_accuracy: 0.6162\n",
      "Epoch 7811/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7154 - val_accuracy: 0.6255\n",
      "Epoch 7812/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7140 - val_accuracy: 0.6229\n",
      "Epoch 7813/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7222 - val_accuracy: 0.6163\n",
      "Epoch 7814/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7099 - val_accuracy: 0.6313\n",
      "Epoch 7815/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5605 - accuracy: 0.6988 - val_loss: 0.7249 - val_accuracy: 0.6137\n",
      "Epoch 7816/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7094 - val_accuracy: 0.6268\n",
      "Epoch 7817/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7206 - val_accuracy: 0.6206\n",
      "Epoch 7818/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7155 - val_accuracy: 0.6223\n",
      "Epoch 7819/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7124 - val_accuracy: 0.6238\n",
      "Epoch 7820/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7234 - val_accuracy: 0.6181\n",
      "Epoch 7821/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7104 - val_accuracy: 0.6282\n",
      "Epoch 7822/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7230 - val_accuracy: 0.6157\n",
      "Epoch 7823/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5599 - accuracy: 0.6990 - val_loss: 0.7089 - val_accuracy: 0.6286\n",
      "Epoch 7824/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7240 - val_accuracy: 0.6173\n",
      "Epoch 7825/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7137 - val_accuracy: 0.6244\n",
      "Epoch 7826/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7143 - val_accuracy: 0.6225\n",
      "Epoch 7827/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7200 - val_accuracy: 0.6199\n",
      "Epoch 7828/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7129 - val_accuracy: 0.6264\n",
      "Epoch 7829/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7229 - val_accuracy: 0.6174\n",
      "Epoch 7830/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7110 - val_accuracy: 0.6268\n",
      "Epoch 7831/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7218 - val_accuracy: 0.6181\n",
      "Epoch 7832/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7113 - val_accuracy: 0.6261\n",
      "Epoch 7833/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7203 - val_accuracy: 0.6191\n",
      "Epoch 7834/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7165 - val_accuracy: 0.6233\n",
      "Epoch 7835/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7161 - val_accuracy: 0.6221\n",
      "Epoch 7836/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7173 - val_accuracy: 0.6218\n",
      "Epoch 7837/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7157 - val_accuracy: 0.6241\n",
      "Epoch 7838/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7197 - val_accuracy: 0.6194\n",
      "Epoch 7839/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7132 - val_accuracy: 0.6253\n",
      "Epoch 7840/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7211 - val_accuracy: 0.6196\n",
      "Epoch 7841/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7139 - val_accuracy: 0.6244\n",
      "Epoch 7842/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7186 - val_accuracy: 0.6202\n",
      "Epoch 7843/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7162 - val_accuracy: 0.6236\n",
      "Epoch 7844/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7186 - val_accuracy: 0.6213\n",
      "Epoch 7845/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7154 - val_accuracy: 0.6227\n",
      "Epoch 7846/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7170 - val_accuracy: 0.6222\n",
      "Epoch 7847/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7173 - val_accuracy: 0.6222\n",
      "Epoch 7848/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7177 - val_accuracy: 0.6210\n",
      "Epoch 7849/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7146 - val_accuracy: 0.6243\n",
      "Epoch 7850/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7208 - val_accuracy: 0.6197\n",
      "Epoch 7851/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7135 - val_accuracy: 0.6244\n",
      "Epoch 7852/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7212 - val_accuracy: 0.6191\n",
      "Epoch 7853/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7114 - val_accuracy: 0.6278\n",
      "Epoch 7854/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7249 - val_accuracy: 0.6155\n",
      "Epoch 7855/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7088 - val_accuracy: 0.6282\n",
      "Epoch 7856/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7259 - val_accuracy: 0.6146\n",
      "Epoch 7857/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7080 - val_accuracy: 0.6305\n",
      "Epoch 7858/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5596 - accuracy: 0.6999 - val_loss: 0.7274 - val_accuracy: 0.6135\n",
      "Epoch 7859/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7083 - val_accuracy: 0.6293\n",
      "Epoch 7860/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7240 - val_accuracy: 0.6156\n",
      "Epoch 7861/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7131 - val_accuracy: 0.6269\n",
      "Epoch 7862/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7187 - val_accuracy: 0.6206\n",
      "Epoch 7863/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7166 - val_accuracy: 0.6219\n",
      "Epoch 7864/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7152 - val_accuracy: 0.6242\n",
      "Epoch 7865/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7217 - val_accuracy: 0.6181\n",
      "Epoch 7866/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7125 - val_accuracy: 0.6261\n",
      "Epoch 7867/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7197 - val_accuracy: 0.6196\n",
      "Epoch 7868/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7156 - val_accuracy: 0.6237\n",
      "Epoch 7869/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.7001 - val_loss: 0.7192 - val_accuracy: 0.6208\n",
      "Epoch 7870/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7138 - val_accuracy: 0.6245\n",
      "Epoch 7871/10000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7178 - val_accuracy: 0.6213\n",
      "Epoch 7872/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7184 - val_accuracy: 0.6219\n",
      "Epoch 7873/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7173 - val_accuracy: 0.6216\n",
      "Epoch 7874/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7147 - val_accuracy: 0.6235\n",
      "Epoch 7875/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7184 - val_accuracy: 0.6216\n",
      "Epoch 7876/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7171 - val_accuracy: 0.6219\n",
      "Epoch 7877/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7162 - val_accuracy: 0.6222\n",
      "Epoch 7878/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7172 - val_accuracy: 0.6225\n",
      "Epoch 7879/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7169 - val_accuracy: 0.6218\n",
      "Epoch 7880/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7175 - val_accuracy: 0.6205\n",
      "Epoch 7881/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7145 - val_accuracy: 0.6245\n",
      "Epoch 7882/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7196 - val_accuracy: 0.6207\n",
      "Epoch 7883/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7163 - val_accuracy: 0.6227\n",
      "Epoch 7884/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7169 - val_accuracy: 0.6220\n",
      "Epoch 7885/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7159 - val_accuracy: 0.6228\n",
      "Epoch 7886/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7177 - val_accuracy: 0.6213\n",
      "Epoch 7887/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7180 - val_accuracy: 0.6222\n",
      "Epoch 7888/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7169 - val_accuracy: 0.6225\n",
      "Epoch 7889/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7169 - val_accuracy: 0.6224\n",
      "Epoch 7890/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7162 - val_accuracy: 0.6230\n",
      "Epoch 7891/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7199 - val_accuracy: 0.6201\n",
      "Epoch 7892/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7135 - val_accuracy: 0.6249\n",
      "Epoch 7893/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7220 - val_accuracy: 0.6193\n",
      "Epoch 7894/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7105 - val_accuracy: 0.6273\n",
      "Epoch 7895/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7274 - val_accuracy: 0.6127\n",
      "Epoch 7896/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7065 - val_accuracy: 0.6327\n",
      "Epoch 7897/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7301 - val_accuracy: 0.6111\n",
      "Epoch 7898/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5600 - accuracy: 0.6991 - val_loss: 0.7040 - val_accuracy: 0.6322\n",
      "Epoch 7899/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5604 - accuracy: 0.6990 - val_loss: 0.7301 - val_accuracy: 0.6098\n",
      "Epoch 7900/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5602 - accuracy: 0.6990 - val_loss: 0.7060 - val_accuracy: 0.6323\n",
      "Epoch 7901/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7259 - val_accuracy: 0.6139\n",
      "Epoch 7902/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7141 - val_accuracy: 0.6252\n",
      "Epoch 7903/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7164 - val_accuracy: 0.6224\n",
      "Epoch 7904/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7192 - val_accuracy: 0.6200\n",
      "Epoch 7905/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7131 - val_accuracy: 0.6272\n",
      "Epoch 7906/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7221 - val_accuracy: 0.6166\n",
      "Epoch 7907/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7098 - val_accuracy: 0.6278\n",
      "Epoch 7908/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5594 - accuracy: 0.7002 - val_loss: 0.7268 - val_accuracy: 0.6158\n",
      "Epoch 7909/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7080 - val_accuracy: 0.6280\n",
      "Epoch 7910/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5602 - accuracy: 0.6994 - val_loss: 0.7239 - val_accuracy: 0.6146\n",
      "Epoch 7911/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7107 - val_accuracy: 0.6299\n",
      "Epoch 7912/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7216 - val_accuracy: 0.6183\n",
      "Epoch 7913/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7123 - val_accuracy: 0.6234\n",
      "Epoch 7914/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5607 - accuracy: 0.6989 - val_loss: 0.7176 - val_accuracy: 0.6208\n",
      "Epoch 7915/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7184 - val_accuracy: 0.6214\n",
      "Epoch 7916/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7134 - val_accuracy: 0.6248\n",
      "Epoch 7917/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5601 - accuracy: 0.6995 - val_loss: 0.7171 - val_accuracy: 0.6203\n",
      "Epoch 7918/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5607 - accuracy: 0.6987 - val_loss: 0.7148 - val_accuracy: 0.6224\n",
      "Epoch 7919/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5606 - accuracy: 0.6991 - val_loss: 0.7176 - val_accuracy: 0.6213\n",
      "Epoch 7920/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7153 - val_accuracy: 0.6230\n",
      "Epoch 7921/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5605 - accuracy: 0.6991 - val_loss: 0.7116 - val_accuracy: 0.6248\n",
      "Epoch 7922/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5608 - accuracy: 0.6987 - val_loss: 0.7201 - val_accuracy: 0.6172\n",
      "Epoch 7923/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5608 - accuracy: 0.6986 - val_loss: 0.7138 - val_accuracy: 0.6251\n",
      "Epoch 7924/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5607 - accuracy: 0.6992 - val_loss: 0.7198 - val_accuracy: 0.6192\n",
      "Epoch 7925/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5602 - accuracy: 0.6992 - val_loss: 0.7108 - val_accuracy: 0.6264\n",
      "Epoch 7926/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5604 - accuracy: 0.6992 - val_loss: 0.7171 - val_accuracy: 0.6217\n",
      "Epoch 7927/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7192 - val_accuracy: 0.6209\n",
      "Epoch 7928/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5598 - accuracy: 0.6992 - val_loss: 0.7164 - val_accuracy: 0.6227\n",
      "Epoch 7929/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7144 - val_accuracy: 0.6223\n",
      "Epoch 7930/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7150 - val_accuracy: 0.6231\n",
      "Epoch 7931/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7189 - val_accuracy: 0.6221\n",
      "Epoch 7932/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7191 - val_accuracy: 0.6210\n",
      "Epoch 7933/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7129 - val_accuracy: 0.6247\n",
      "Epoch 7934/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7159 - val_accuracy: 0.6223\n",
      "Epoch 7935/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7186 - val_accuracy: 0.6226\n",
      "Epoch 7936/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7167 - val_accuracy: 0.6214\n",
      "Epoch 7937/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7181 - val_accuracy: 0.6198\n",
      "Epoch 7938/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7129 - val_accuracy: 0.6263\n",
      "Epoch 7939/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7222 - val_accuracy: 0.6192\n",
      "Epoch 7940/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7102 - val_accuracy: 0.6261\n",
      "Epoch 7941/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5599 - accuracy: 0.6997 - val_loss: 0.7216 - val_accuracy: 0.6164\n",
      "Epoch 7942/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7121 - val_accuracy: 0.6266\n",
      "Epoch 7943/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7217 - val_accuracy: 0.6191\n",
      "Epoch 7944/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7085 - val_accuracy: 0.6262\n",
      "Epoch 7945/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5605 - accuracy: 0.6991 - val_loss: 0.7221 - val_accuracy: 0.6155\n",
      "Epoch 7946/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5606 - accuracy: 0.6987 - val_loss: 0.7132 - val_accuracy: 0.6256\n",
      "Epoch 7947/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5598 - accuracy: 0.6997 - val_loss: 0.7198 - val_accuracy: 0.6200\n",
      "Epoch 7948/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5604 - accuracy: 0.6992 - val_loss: 0.7098 - val_accuracy: 0.6257\n",
      "Epoch 7949/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7174 - val_accuracy: 0.6197\n",
      "Epoch 7950/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5603 - accuracy: 0.6990 - val_loss: 0.7169 - val_accuracy: 0.6225\n",
      "Epoch 7951/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7153 - val_accuracy: 0.6226\n",
      "Epoch 7952/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7150 - val_accuracy: 0.6221\n",
      "Epoch 7953/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7167 - val_accuracy: 0.6222\n",
      "Epoch 7954/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7180 - val_accuracy: 0.6217\n",
      "Epoch 7955/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7168 - val_accuracy: 0.6211\n",
      "Epoch 7956/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7135 - val_accuracy: 0.6254\n",
      "Epoch 7957/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7192 - val_accuracy: 0.6211\n",
      "Epoch 7958/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7156 - val_accuracy: 0.6229\n",
      "Epoch 7959/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7181 - val_accuracy: 0.6198\n",
      "Epoch 7960/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7132 - val_accuracy: 0.6253\n",
      "Epoch 7961/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7211 - val_accuracy: 0.6211\n",
      "Epoch 7962/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7151 - val_accuracy: 0.6232\n",
      "Epoch 7963/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7184 - val_accuracy: 0.6199\n",
      "Epoch 7964/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7146 - val_accuracy: 0.6252\n",
      "Epoch 7965/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7176 - val_accuracy: 0.6221\n",
      "Epoch 7966/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7193 - val_accuracy: 0.6205\n",
      "Epoch 7967/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7147 - val_accuracy: 0.6241\n",
      "Epoch 7968/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7198 - val_accuracy: 0.6194\n",
      "Epoch 7969/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7140 - val_accuracy: 0.6255\n",
      "Epoch 7970/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7215 - val_accuracy: 0.6201\n",
      "Epoch 7971/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7130 - val_accuracy: 0.6251\n",
      "Epoch 7972/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7226 - val_accuracy: 0.6174\n",
      "Epoch 7973/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7114 - val_accuracy: 0.6279\n",
      "Epoch 7974/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7240 - val_accuracy: 0.6165\n",
      "Epoch 7975/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7103 - val_accuracy: 0.6275\n",
      "Epoch 7976/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7241 - val_accuracy: 0.6167\n",
      "Epoch 7977/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7120 - val_accuracy: 0.6268\n",
      "Epoch 7978/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7219 - val_accuracy: 0.6183\n",
      "Epoch 7979/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7121 - val_accuracy: 0.6264\n",
      "Epoch 7980/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5591 - accuracy: 0.7003 - val_loss: 0.7214 - val_accuracy: 0.6194\n",
      "Epoch 7981/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7136 - val_accuracy: 0.6252\n",
      "Epoch 7982/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7230 - val_accuracy: 0.6178\n",
      "Epoch 7983/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7119 - val_accuracy: 0.6275\n",
      "Epoch 7984/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7230 - val_accuracy: 0.6172\n",
      "Epoch 7985/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7128 - val_accuracy: 0.6267\n",
      "Epoch 7986/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7236 - val_accuracy: 0.6178\n",
      "Epoch 7987/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7089 - val_accuracy: 0.6274\n",
      "Epoch 7988/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5595 - accuracy: 0.7000 - val_loss: 0.7255 - val_accuracy: 0.6149\n",
      "Epoch 7989/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7112 - val_accuracy: 0.6295\n",
      "Epoch 7990/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7263 - val_accuracy: 0.6140\n",
      "Epoch 7991/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7089 - val_accuracy: 0.6290\n",
      "Epoch 7992/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7251 - val_accuracy: 0.6162\n",
      "Epoch 7993/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7098 - val_accuracy: 0.6283\n",
      "Epoch 7994/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7255 - val_accuracy: 0.6156\n",
      "Epoch 7995/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7109 - val_accuracy: 0.6278\n",
      "Epoch 7996/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7219 - val_accuracy: 0.6167\n",
      "Epoch 7997/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7112 - val_accuracy: 0.6261\n",
      "Epoch 7998/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5595 - accuracy: 0.7000 - val_loss: 0.7221 - val_accuracy: 0.6194\n",
      "Epoch 7999/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7147 - val_accuracy: 0.6247\n",
      "Epoch 8000/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7174 - val_accuracy: 0.6212\n",
      "Epoch 8001/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5593 - accuracy: 0.7001 - val_loss: 0.7193 - val_accuracy: 0.6213\n",
      "Epoch 8002/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7146 - val_accuracy: 0.6249\n",
      "Epoch 8003/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7212 - val_accuracy: 0.6185\n",
      "Epoch 8004/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7122 - val_accuracy: 0.6265\n",
      "Epoch 8005/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7238 - val_accuracy: 0.6181\n",
      "Epoch 8006/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7110 - val_accuracy: 0.6257\n",
      "Epoch 8007/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.7001 - val_loss: 0.7214 - val_accuracy: 0.6176\n",
      "Epoch 8008/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7143 - val_accuracy: 0.6269\n",
      "Epoch 8009/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7210 - val_accuracy: 0.6183\n",
      "Epoch 8010/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7144 - val_accuracy: 0.6238\n",
      "Epoch 8011/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7180 - val_accuracy: 0.6230\n",
      "Epoch 8012/10000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7176 - val_accuracy: 0.6207\n",
      "Epoch 8013/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7171 - val_accuracy: 0.6219\n",
      "Epoch 8014/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7182 - val_accuracy: 0.6229\n",
      "Epoch 8015/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7142 - val_accuracy: 0.6233\n",
      "Epoch 8016/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7220 - val_accuracy: 0.6189\n",
      "Epoch 8017/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7149 - val_accuracy: 0.6259\n",
      "Epoch 8018/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7194 - val_accuracy: 0.6182\n",
      "Epoch 8019/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7125 - val_accuracy: 0.6255\n",
      "Epoch 8020/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7246 - val_accuracy: 0.6190\n",
      "Epoch 8021/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7104 - val_accuracy: 0.6257\n",
      "Epoch 8022/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7221 - val_accuracy: 0.6164\n",
      "Epoch 8023/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7148 - val_accuracy: 0.6275\n",
      "Epoch 8024/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7200 - val_accuracy: 0.6182\n",
      "Epoch 8025/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7129 - val_accuracy: 0.6242\n",
      "Epoch 8026/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7215 - val_accuracy: 0.6212\n",
      "Epoch 8027/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7126 - val_accuracy: 0.6239\n",
      "Epoch 8028/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7213 - val_accuracy: 0.6172\n",
      "Epoch 8029/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7139 - val_accuracy: 0.6280\n",
      "Epoch 8030/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7217 - val_accuracy: 0.6181\n",
      "Epoch 8031/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7124 - val_accuracy: 0.6250\n",
      "Epoch 8032/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7221 - val_accuracy: 0.6202\n",
      "Epoch 8033/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7141 - val_accuracy: 0.6249\n",
      "Epoch 8034/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7186 - val_accuracy: 0.6193\n",
      "Epoch 8035/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7143 - val_accuracy: 0.6249\n",
      "Epoch 8036/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7209 - val_accuracy: 0.6206\n",
      "Epoch 8037/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7151 - val_accuracy: 0.6226\n",
      "Epoch 8038/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7164 - val_accuracy: 0.6219\n",
      "Epoch 8039/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7201 - val_accuracy: 0.6216\n",
      "Epoch 8040/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7147 - val_accuracy: 0.6235\n",
      "Epoch 8041/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7200 - val_accuracy: 0.6187\n",
      "Epoch 8042/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7132 - val_accuracy: 0.6260\n",
      "Epoch 8043/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7236 - val_accuracy: 0.6183\n",
      "Epoch 8044/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7113 - val_accuracy: 0.6265\n",
      "Epoch 8045/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5596 - accuracy: 0.6999 - val_loss: 0.7225 - val_accuracy: 0.6177\n",
      "Epoch 8046/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7121 - val_accuracy: 0.6279\n",
      "Epoch 8047/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7259 - val_accuracy: 0.6143\n",
      "Epoch 8048/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5595 - accuracy: 0.6994 - val_loss: 0.7079 - val_accuracy: 0.6299\n",
      "Epoch 8049/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7264 - val_accuracy: 0.6146\n",
      "Epoch 8050/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7112 - val_accuracy: 0.6281\n",
      "Epoch 8051/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7234 - val_accuracy: 0.6156\n",
      "Epoch 8052/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7101 - val_accuracy: 0.6277\n",
      "Epoch 8053/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7240 - val_accuracy: 0.6177\n",
      "Epoch 8054/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7115 - val_accuracy: 0.6267\n",
      "Epoch 8055/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7222 - val_accuracy: 0.6178\n",
      "Epoch 8056/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7157 - val_accuracy: 0.6247\n",
      "Epoch 8057/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7174 - val_accuracy: 0.6221\n",
      "Epoch 8058/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7195 - val_accuracy: 0.6201\n",
      "Epoch 8059/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7135 - val_accuracy: 0.6263\n",
      "Epoch 8060/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7229 - val_accuracy: 0.6173\n",
      "Epoch 8061/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7116 - val_accuracy: 0.6262\n",
      "Epoch 8062/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7239 - val_accuracy: 0.6177\n",
      "Epoch 8063/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7097 - val_accuracy: 0.6287\n",
      "Epoch 8064/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7275 - val_accuracy: 0.6131\n",
      "Epoch 8065/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7070 - val_accuracy: 0.6319\n",
      "Epoch 8066/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7304 - val_accuracy: 0.6110\n",
      "Epoch 8067/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5598 - accuracy: 0.6992 - val_loss: 0.7045 - val_accuracy: 0.6324\n",
      "Epoch 8068/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5604 - accuracy: 0.6992 - val_loss: 0.7317 - val_accuracy: 0.6096\n",
      "Epoch 8069/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5600 - accuracy: 0.6990 - val_loss: 0.7065 - val_accuracy: 0.6330\n",
      "Epoch 8070/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7260 - val_accuracy: 0.6131\n",
      "Epoch 8071/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7120 - val_accuracy: 0.6270\n",
      "Epoch 8072/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7203 - val_accuracy: 0.6214\n",
      "Epoch 8073/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7182 - val_accuracy: 0.6203\n",
      "Epoch 8074/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7136 - val_accuracy: 0.6252\n",
      "Epoch 8075/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7246 - val_accuracy: 0.6181\n",
      "Epoch 8076/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7087 - val_accuracy: 0.6284\n",
      "Epoch 8077/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7278 - val_accuracy: 0.6123\n",
      "Epoch 8078/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5599 - accuracy: 0.6991 - val_loss: 0.7088 - val_accuracy: 0.6310\n",
      "Epoch 8079/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7260 - val_accuracy: 0.6142\n",
      "Epoch 8080/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5598 - accuracy: 0.6992 - val_loss: 0.7099 - val_accuracy: 0.6278\n",
      "Epoch 8081/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7217 - val_accuracy: 0.6198\n",
      "Epoch 8082/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7173 - val_accuracy: 0.6218\n",
      "Epoch 8083/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7160 - val_accuracy: 0.6227\n",
      "Epoch 8084/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7206 - val_accuracy: 0.6212\n",
      "Epoch 8085/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7129 - val_accuracy: 0.6257\n",
      "Epoch 8086/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7240 - val_accuracy: 0.6159\n",
      "Epoch 8087/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7115 - val_accuracy: 0.6286\n",
      "Epoch 8088/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7244 - val_accuracy: 0.6164\n",
      "Epoch 8089/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7114 - val_accuracy: 0.6265\n",
      "Epoch 8090/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7232 - val_accuracy: 0.6178\n",
      "Epoch 8091/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7143 - val_accuracy: 0.6257\n",
      "Epoch 8092/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7194 - val_accuracy: 0.6204\n",
      "Epoch 8093/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.6227\n",
      "Epoch 8094/10000\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7136 - val_accuracy: 0.6240\n",
      "Epoch 8095/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7231 - val_accuracy: 0.6170\n",
      "Epoch 8096/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7134 - val_accuracy: 0.6273\n",
      "Epoch 8097/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7204 - val_accuracy: 0.6183\n",
      "Epoch 8098/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7133 - val_accuracy: 0.6258\n",
      "Epoch 8099/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7229 - val_accuracy: 0.6201\n",
      "Epoch 8100/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7141 - val_accuracy: 0.6237\n",
      "Epoch 8101/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7174 - val_accuracy: 0.6207\n",
      "Epoch 8102/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7186 - val_accuracy: 0.6230\n",
      "Epoch 8103/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7169 - val_accuracy: 0.6224\n",
      "Epoch 8104/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7185 - val_accuracy: 0.6204\n",
      "Epoch 8105/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7152 - val_accuracy: 0.6254\n",
      "Epoch 8106/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7233 - val_accuracy: 0.6183\n",
      "Epoch 8107/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7128 - val_accuracy: 0.6253\n",
      "Epoch 8108/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7213 - val_accuracy: 0.6194\n",
      "Epoch 8109/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7137 - val_accuracy: 0.6256\n",
      "Epoch 8110/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7231 - val_accuracy: 0.6172\n",
      "Epoch 8111/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7119 - val_accuracy: 0.6271\n",
      "Epoch 8112/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7239 - val_accuracy: 0.6171\n",
      "Epoch 8113/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7125 - val_accuracy: 0.6266\n",
      "Epoch 8114/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7249 - val_accuracy: 0.6161\n",
      "Epoch 8115/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7091 - val_accuracy: 0.6292\n",
      "Epoch 8116/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7278 - val_accuracy: 0.6141\n",
      "Epoch 8117/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7088 - val_accuracy: 0.6300\n",
      "Epoch 8118/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7281 - val_accuracy: 0.6124\n",
      "Epoch 8119/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7077 - val_accuracy: 0.6314\n",
      "Epoch 8120/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7272 - val_accuracy: 0.6140\n",
      "Epoch 8121/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7102 - val_accuracy: 0.6276\n",
      "Epoch 8122/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5593 - accuracy: 0.7001 - val_loss: 0.7229 - val_accuracy: 0.6180\n",
      "Epoch 8123/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7145 - val_accuracy: 0.6260\n",
      "Epoch 8124/10000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7190 - val_accuracy: 0.6211\n",
      "Epoch 8125/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7194 - val_accuracy: 0.6207\n",
      "Epoch 8126/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7150 - val_accuracy: 0.6248\n",
      "Epoch 8127/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7228 - val_accuracy: 0.6186\n",
      "Epoch 8128/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7110 - val_accuracy: 0.6275\n",
      "Epoch 8129/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7273 - val_accuracy: 0.6140\n",
      "Epoch 8130/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7072 - val_accuracy: 0.6313\n",
      "Epoch 8131/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7297 - val_accuracy: 0.6120\n",
      "Epoch 8132/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7079 - val_accuracy: 0.6309\n",
      "Epoch 8133/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7273 - val_accuracy: 0.6128\n",
      "Epoch 8134/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7101 - val_accuracy: 0.6288\n",
      "Epoch 8135/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7228 - val_accuracy: 0.6185\n",
      "Epoch 8136/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7138 - val_accuracy: 0.6239\n",
      "Epoch 8137/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7206 - val_accuracy: 0.6205\n",
      "Epoch 8138/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7193 - val_accuracy: 0.6216\n",
      "Epoch 8139/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7122 - val_accuracy: 0.6251\n",
      "Epoch 8140/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7237 - val_accuracy: 0.6172\n",
      "Epoch 8141/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7119 - val_accuracy: 0.6290\n",
      "Epoch 8142/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7260 - val_accuracy: 0.6132\n",
      "Epoch 8143/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7087 - val_accuracy: 0.6296\n",
      "Epoch 8144/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7260 - val_accuracy: 0.6171\n",
      "Epoch 8145/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7132 - val_accuracy: 0.6246\n",
      "Epoch 8146/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7191 - val_accuracy: 0.6198\n",
      "Epoch 8147/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7182 - val_accuracy: 0.6238\n",
      "Epoch 8148/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7160 - val_accuracy: 0.6223\n",
      "Epoch 8149/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7204 - val_accuracy: 0.6180\n",
      "Epoch 8150/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7133 - val_accuracy: 0.6278\n",
      "Epoch 8151/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7252 - val_accuracy: 0.6162\n",
      "Epoch 8152/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7114 - val_accuracy: 0.6274\n",
      "Epoch 8153/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7241 - val_accuracy: 0.6173\n",
      "Epoch 8154/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7124 - val_accuracy: 0.6272\n",
      "Epoch 8155/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7237 - val_accuracy: 0.6170\n",
      "Epoch 8156/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7135 - val_accuracy: 0.6260\n",
      "Epoch 8157/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5591 - accuracy: 0.7003 - val_loss: 0.7214 - val_accuracy: 0.6201\n",
      "Epoch 8158/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7160 - val_accuracy: 0.6233\n",
      "Epoch 8159/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7195 - val_accuracy: 0.6214\n",
      "Epoch 8160/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7171 - val_accuracy: 0.6226\n",
      "Epoch 8161/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7178 - val_accuracy: 0.6218\n",
      "Epoch 8162/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7186 - val_accuracy: 0.6227\n",
      "Epoch 8163/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7153 - val_accuracy: 0.6234\n",
      "Epoch 8164/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7216 - val_accuracy: 0.6186\n",
      "Epoch 8165/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7146 - val_accuracy: 0.6255\n",
      "Epoch 8166/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7221 - val_accuracy: 0.6189\n",
      "Epoch 8167/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7132 - val_accuracy: 0.6260\n",
      "Epoch 8168/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7240 - val_accuracy: 0.6177\n",
      "Epoch 8169/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7112 - val_accuracy: 0.6272\n",
      "Epoch 8170/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7247 - val_accuracy: 0.6167\n",
      "Epoch 8171/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7113 - val_accuracy: 0.6278\n",
      "Epoch 8172/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7268 - val_accuracy: 0.6143\n",
      "Epoch 8173/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7081 - val_accuracy: 0.6310\n",
      "Epoch 8174/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7282 - val_accuracy: 0.6131\n",
      "Epoch 8175/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7109 - val_accuracy: 0.6287\n",
      "Epoch 8176/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7255 - val_accuracy: 0.6156\n",
      "Epoch 8177/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7100 - val_accuracy: 0.6284\n",
      "Epoch 8178/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7231 - val_accuracy: 0.6178\n",
      "Epoch 8179/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7166 - val_accuracy: 0.6231\n",
      "Epoch 8180/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7189 - val_accuracy: 0.6212\n",
      "Epoch 8181/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7158 - val_accuracy: 0.6244\n",
      "Epoch 8182/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7197 - val_accuracy: 0.6215\n",
      "Epoch 8183/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7194 - val_accuracy: 0.6213\n",
      "Epoch 8184/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7157 - val_accuracy: 0.6240\n",
      "Epoch 8185/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7203 - val_accuracy: 0.6202\n",
      "Epoch 8186/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7162 - val_accuracy: 0.6239\n",
      "Epoch 8187/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7215 - val_accuracy: 0.6189\n",
      "Epoch 8188/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7121 - val_accuracy: 0.6261\n",
      "Epoch 8189/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7256 - val_accuracy: 0.6173\n",
      "Epoch 8190/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7115 - val_accuracy: 0.6278\n",
      "Epoch 8191/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7235 - val_accuracy: 0.6171\n",
      "Epoch 8192/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7116 - val_accuracy: 0.6273\n",
      "Epoch 8193/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7263 - val_accuracy: 0.6156\n",
      "Epoch 8194/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7106 - val_accuracy: 0.6283\n",
      "Epoch 8195/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7206 - val_accuracy: 0.6178\n",
      "Epoch 8196/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5606 - accuracy: 0.6988 - val_loss: 0.7155 - val_accuracy: 0.6224\n",
      "Epoch 8197/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5598 - accuracy: 0.6997 - val_loss: 0.7164 - val_accuracy: 0.6236\n",
      "Epoch 8198/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5601 - accuracy: 0.6995 - val_loss: 0.7214 - val_accuracy: 0.6184\n",
      "Epoch 8199/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7104 - val_accuracy: 0.6281\n",
      "Epoch 8200/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5605 - accuracy: 0.6991 - val_loss: 0.7266 - val_accuracy: 0.6141\n",
      "Epoch 8201/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5603 - accuracy: 0.6991 - val_loss: 0.7110 - val_accuracy: 0.6278\n",
      "Epoch 8202/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5602 - accuracy: 0.6995 - val_loss: 0.7211 - val_accuracy: 0.6191\n",
      "Epoch 8203/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7144 - val_accuracy: 0.6239\n",
      "Epoch 8204/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7169 - val_accuracy: 0.6221\n",
      "Epoch 8205/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7229 - val_accuracy: 0.6186\n",
      "Epoch 8206/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5601 - accuracy: 0.6990 - val_loss: 0.7116 - val_accuracy: 0.6281\n",
      "Epoch 8207/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7220 - val_accuracy: 0.6180\n",
      "Epoch 8208/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5604 - accuracy: 0.6989 - val_loss: 0.7114 - val_accuracy: 0.6263\n",
      "Epoch 8209/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7227 - val_accuracy: 0.6191\n",
      "Epoch 8210/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7182 - val_accuracy: 0.6230\n",
      "Epoch 8211/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7100 - val_accuracy: 0.6254\n",
      "Epoch 8212/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5612 - accuracy: 0.6985 - val_loss: 0.7229 - val_accuracy: 0.6142\n",
      "Epoch 8213/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5616 - accuracy: 0.6982 - val_loss: 0.7088 - val_accuracy: 0.6302\n",
      "Epoch 8214/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5602 - accuracy: 0.6992 - val_loss: 0.7272 - val_accuracy: 0.6155\n",
      "Epoch 8215/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5615 - accuracy: 0.6984 - val_loss: 0.7070 - val_accuracy: 0.6285\n",
      "Epoch 8216/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5608 - accuracy: 0.6990 - val_loss: 0.7214 - val_accuracy: 0.6165\n",
      "Epoch 8217/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5615 - accuracy: 0.6981 - val_loss: 0.7133 - val_accuracy: 0.6244\n",
      "Epoch 8218/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5599 - accuracy: 0.6997 - val_loss: 0.7189 - val_accuracy: 0.6219\n",
      "Epoch 8219/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5606 - accuracy: 0.6990 - val_loss: 0.7167 - val_accuracy: 0.6211\n",
      "Epoch 8220/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7130 - val_accuracy: 0.6253\n",
      "Epoch 8221/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5603 - accuracy: 0.6991 - val_loss: 0.7227 - val_accuracy: 0.6191\n",
      "Epoch 8222/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7158 - val_accuracy: 0.6242\n",
      "Epoch 8223/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7167 - val_accuracy: 0.6207\n",
      "Epoch 8224/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7146 - val_accuracy: 0.6244\n",
      "Epoch 8225/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7189 - val_accuracy: 0.6220\n",
      "Epoch 8226/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7222 - val_accuracy: 0.6196\n",
      "Epoch 8227/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7136 - val_accuracy: 0.6242\n",
      "Epoch 8228/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7183 - val_accuracy: 0.6212\n",
      "Epoch 8229/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7137 - val_accuracy: 0.6258\n",
      "Epoch 8230/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7237 - val_accuracy: 0.6184\n",
      "Epoch 8231/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6994 - val_loss: 0.7147 - val_accuracy: 0.6239\n",
      "Epoch 8232/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7165 - val_accuracy: 0.6214\n",
      "Epoch 8233/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7160 - val_accuracy: 0.6234\n",
      "Epoch 8234/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7202 - val_accuracy: 0.6222\n",
      "Epoch 8235/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7179 - val_accuracy: 0.6216\n",
      "Epoch 8236/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7174 - val_accuracy: 0.6219\n",
      "Epoch 8237/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7184 - val_accuracy: 0.6227\n",
      "Epoch 8238/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7170 - val_accuracy: 0.6226\n",
      "Epoch 8239/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7178 - val_accuracy: 0.6221\n",
      "Epoch 8240/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7196 - val_accuracy: 0.6217\n",
      "Epoch 8241/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7164 - val_accuracy: 0.6227\n",
      "Epoch 8242/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7194 - val_accuracy: 0.6213\n",
      "Epoch 8243/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7172 - val_accuracy: 0.6241\n",
      "Epoch 8244/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7180 - val_accuracy: 0.6217\n",
      "Epoch 8245/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7196 - val_accuracy: 0.6205\n",
      "Epoch 8246/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7150 - val_accuracy: 0.6251\n",
      "Epoch 8247/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7199 - val_accuracy: 0.6197\n",
      "Epoch 8248/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7166 - val_accuracy: 0.6231\n",
      "Epoch 8249/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7195 - val_accuracy: 0.6213\n",
      "Epoch 8250/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7176 - val_accuracy: 0.6226\n",
      "Epoch 8251/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7182 - val_accuracy: 0.6216\n",
      "Epoch 8252/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7169 - val_accuracy: 0.6232\n",
      "Epoch 8253/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7192 - val_accuracy: 0.6211\n",
      "Epoch 8254/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7190 - val_accuracy: 0.6219\n",
      "Epoch 8255/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7169 - val_accuracy: 0.6235\n",
      "Epoch 8256/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7197 - val_accuracy: 0.6198\n",
      "Epoch 8257/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7158 - val_accuracy: 0.6248\n",
      "Epoch 8258/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7210 - val_accuracy: 0.6212\n",
      "Epoch 8259/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7158 - val_accuracy: 0.6231\n",
      "Epoch 8260/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7173 - val_accuracy: 0.6206\n",
      "Epoch 8261/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7182 - val_accuracy: 0.6236\n",
      "Epoch 8262/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7162 - val_accuracy: 0.6229\n",
      "Epoch 8263/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7209 - val_accuracy: 0.6184\n",
      "Epoch 8264/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7138 - val_accuracy: 0.6272\n",
      "Epoch 8265/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7246 - val_accuracy: 0.6167\n",
      "Epoch 8266/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7112 - val_accuracy: 0.6269\n",
      "Epoch 8267/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7219 - val_accuracy: 0.6183\n",
      "Epoch 8268/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7164 - val_accuracy: 0.6253\n",
      "Epoch 8269/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7187 - val_accuracy: 0.6207\n",
      "Epoch 8270/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7185 - val_accuracy: 0.6204\n",
      "Epoch 8271/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7130 - val_accuracy: 0.6266\n",
      "Epoch 8272/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7266 - val_accuracy: 0.6167\n",
      "Epoch 8273/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5601 - accuracy: 0.6988 - val_loss: 0.7087 - val_accuracy: 0.6287\n",
      "Epoch 8274/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7287 - val_accuracy: 0.6105\n",
      "Epoch 8275/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5607 - accuracy: 0.6985 - val_loss: 0.7052 - val_accuracy: 0.6335\n",
      "Epoch 8276/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7291 - val_accuracy: 0.6143\n",
      "Epoch 8277/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5602 - accuracy: 0.6988 - val_loss: 0.7090 - val_accuracy: 0.6287\n",
      "Epoch 8278/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5603 - accuracy: 0.6993 - val_loss: 0.7243 - val_accuracy: 0.6139\n",
      "Epoch 8279/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7143 - val_accuracy: 0.6261\n",
      "Epoch 8280/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7197 - val_accuracy: 0.6222\n",
      "Epoch 8281/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7173 - val_accuracy: 0.6205\n",
      "Epoch 8282/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7145 - val_accuracy: 0.6234\n",
      "Epoch 8283/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7237 - val_accuracy: 0.6194\n",
      "Epoch 8284/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5596 - accuracy: 0.6993 - val_loss: 0.7144 - val_accuracy: 0.6261\n",
      "Epoch 8285/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7215 - val_accuracy: 0.6177\n",
      "Epoch 8286/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7124 - val_accuracy: 0.6265\n",
      "Epoch 8287/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7223 - val_accuracy: 0.6201\n",
      "Epoch 8288/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7156 - val_accuracy: 0.6242\n",
      "Epoch 8289/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7223 - val_accuracy: 0.6190\n",
      "Epoch 8290/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7133 - val_accuracy: 0.6259\n",
      "Epoch 8291/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7229 - val_accuracy: 0.6186\n",
      "Epoch 8292/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5595 - accuracy: 0.6994 - val_loss: 0.7131 - val_accuracy: 0.6261\n",
      "Epoch 8293/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7238 - val_accuracy: 0.6171\n",
      "Epoch 8294/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7122 - val_accuracy: 0.6268\n",
      "Epoch 8295/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7239 - val_accuracy: 0.6174\n",
      "Epoch 8296/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7114 - val_accuracy: 0.6271\n",
      "Epoch 8297/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7232 - val_accuracy: 0.6162\n",
      "Epoch 8298/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7155 - val_accuracy: 0.6259\n",
      "Epoch 8299/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7204 - val_accuracy: 0.6211\n",
      "Epoch 8300/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7150 - val_accuracy: 0.6224\n",
      "Epoch 8301/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7177 - val_accuracy: 0.6218\n",
      "Epoch 8302/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7222 - val_accuracy: 0.6216\n",
      "Epoch 8303/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7129 - val_accuracy: 0.6248\n",
      "Epoch 8304/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7221 - val_accuracy: 0.6175\n",
      "Epoch 8305/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7149 - val_accuracy: 0.6281\n",
      "Epoch 8306/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7234 - val_accuracy: 0.6166\n",
      "Epoch 8307/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7119 - val_accuracy: 0.6260\n",
      "Epoch 8308/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7231 - val_accuracy: 0.6198\n",
      "Epoch 8309/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7128 - val_accuracy: 0.6262\n",
      "Epoch 8310/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7240 - val_accuracy: 0.6154\n",
      "Epoch 8311/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7137 - val_accuracy: 0.6276\n",
      "Epoch 8312/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7222 - val_accuracy: 0.6189\n",
      "Epoch 8313/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7142 - val_accuracy: 0.6243\n",
      "Epoch 8314/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5595 - accuracy: 0.6999 - val_loss: 0.7218 - val_accuracy: 0.6199\n",
      "Epoch 8315/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7162 - val_accuracy: 0.6236\n",
      "Epoch 8316/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7174 - val_accuracy: 0.6217\n",
      "Epoch 8317/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7214 - val_accuracy: 0.6199\n",
      "Epoch 8318/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7151 - val_accuracy: 0.6258\n",
      "Epoch 8319/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7223 - val_accuracy: 0.6178\n",
      "Epoch 8320/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7113 - val_accuracy: 0.6271\n",
      "Epoch 8321/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7254 - val_accuracy: 0.6170\n",
      "Epoch 8322/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7113 - val_accuracy: 0.6269\n",
      "Epoch 8323/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5600 - accuracy: 0.6996 - val_loss: 0.7238 - val_accuracy: 0.6160\n",
      "Epoch 8324/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7129 - val_accuracy: 0.6284\n",
      "Epoch 8325/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7231 - val_accuracy: 0.6185\n",
      "Epoch 8326/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7159 - val_accuracy: 0.6227\n",
      "Epoch 8327/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7173 - val_accuracy: 0.6231\n",
      "Epoch 8328/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7222 - val_accuracy: 0.6198\n",
      "Epoch 8329/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7132 - val_accuracy: 0.6251\n",
      "Epoch 8330/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7228 - val_accuracy: 0.6183\n",
      "Epoch 8331/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7135 - val_accuracy: 0.6274\n",
      "Epoch 8332/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7238 - val_accuracy: 0.6163\n",
      "Epoch 8333/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7136 - val_accuracy: 0.6263\n",
      "Epoch 8334/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7244 - val_accuracy: 0.6183\n",
      "Epoch 8335/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7092 - val_accuracy: 0.6275\n",
      "Epoch 8336/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5598 - accuracy: 0.6997 - val_loss: 0.7236 - val_accuracy: 0.6159\n",
      "Epoch 8337/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7163 - val_accuracy: 0.6258\n",
      "Epoch 8338/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7211 - val_accuracy: 0.6193\n",
      "Epoch 8339/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7136 - val_accuracy: 0.6244\n",
      "Epoch 8340/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7214 - val_accuracy: 0.6210\n",
      "Epoch 8341/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7199 - val_accuracy: 0.6216\n",
      "Epoch 8342/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7136 - val_accuracy: 0.6237\n",
      "Epoch 8343/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.7003 - val_loss: 0.7220 - val_accuracy: 0.6196\n",
      "Epoch 8344/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7153 - val_accuracy: 0.6268\n",
      "Epoch 8345/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7253 - val_accuracy: 0.6153\n",
      "Epoch 8346/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7104 - val_accuracy: 0.6293\n",
      "Epoch 8347/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7259 - val_accuracy: 0.6173\n",
      "Epoch 8348/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7117 - val_accuracy: 0.6265\n",
      "Epoch 8349/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7251 - val_accuracy: 0.6146\n",
      "Epoch 8350/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7126 - val_accuracy: 0.6299\n",
      "Epoch 8351/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7235 - val_accuracy: 0.6175\n",
      "Epoch 8352/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7142 - val_accuracy: 0.6229\n",
      "Epoch 8353/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7184 - val_accuracy: 0.6228\n",
      "Epoch 8354/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7231 - val_accuracy: 0.6200\n",
      "Epoch 8355/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7098 - val_accuracy: 0.6265\n",
      "Epoch 8356/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5601 - accuracy: 0.6995 - val_loss: 0.7239 - val_accuracy: 0.6154\n",
      "Epoch 8357/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5602 - accuracy: 0.6989 - val_loss: 0.7109 - val_accuracy: 0.6298\n",
      "Epoch 8358/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5603 - accuracy: 0.6994 - val_loss: 0.7291 - val_accuracy: 0.6138\n",
      "Epoch 8359/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5605 - accuracy: 0.6989 - val_loss: 0.7046 - val_accuracy: 0.6317\n",
      "Epoch 8360/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5622 - accuracy: 0.6981 - val_loss: 0.7272 - val_accuracy: 0.6105\n",
      "Epoch 8361/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5617 - accuracy: 0.6981 - val_loss: 0.7092 - val_accuracy: 0.6294\n",
      "Epoch 8362/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5608 - accuracy: 0.6988 - val_loss: 0.7234 - val_accuracy: 0.6188\n",
      "Epoch 8363/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5609 - accuracy: 0.6989 - val_loss: 0.7141 - val_accuracy: 0.6235\n",
      "Epoch 8364/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5605 - accuracy: 0.6989 - val_loss: 0.7143 - val_accuracy: 0.6219\n",
      "Epoch 8365/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5608 - accuracy: 0.6988 - val_loss: 0.7202 - val_accuracy: 0.6197\n",
      "Epoch 8366/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7152 - val_accuracy: 0.6260\n",
      "Epoch 8367/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5605 - accuracy: 0.6991 - val_loss: 0.7205 - val_accuracy: 0.6190\n",
      "Epoch 8368/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7147 - val_accuracy: 0.6242\n",
      "Epoch 8369/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5600 - accuracy: 0.6995 - val_loss: 0.7205 - val_accuracy: 0.6210\n",
      "Epoch 8370/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5594 - accuracy: 0.6994 - val_loss: 0.7191 - val_accuracy: 0.6221\n",
      "Epoch 8371/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7131 - val_accuracy: 0.6245\n",
      "Epoch 8372/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7203 - val_accuracy: 0.6204\n",
      "Epoch 8373/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7160 - val_accuracy: 0.6255\n",
      "Epoch 8374/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7245 - val_accuracy: 0.6173\n",
      "Epoch 8375/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7109 - val_accuracy: 0.6263\n",
      "Epoch 8376/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7196 - val_accuracy: 0.6205\n",
      "Epoch 8377/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7178 - val_accuracy: 0.6240\n",
      "Epoch 8378/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7219 - val_accuracy: 0.6195\n",
      "Epoch 8379/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7162 - val_accuracy: 0.6219\n",
      "Epoch 8380/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7162 - val_accuracy: 0.6236\n",
      "Epoch 8381/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7198 - val_accuracy: 0.6220\n",
      "Epoch 8382/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7186 - val_accuracy: 0.6217\n",
      "Epoch 8383/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7190 - val_accuracy: 0.6211\n",
      "Epoch 8384/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7166 - val_accuracy: 0.6236\n",
      "Epoch 8385/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7200 - val_accuracy: 0.6212\n",
      "Epoch 8386/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7168 - val_accuracy: 0.6233\n",
      "Epoch 8387/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7192 - val_accuracy: 0.6215\n",
      "Epoch 8388/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7189 - val_accuracy: 0.6217\n",
      "Epoch 8389/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7196 - val_accuracy: 0.6212\n",
      "Epoch 8390/10000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7163 - val_accuracy: 0.6238\n",
      "Epoch 8391/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7183 - val_accuracy: 0.6216\n",
      "Epoch 8392/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7200 - val_accuracy: 0.6210\n",
      "Epoch 8393/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7181 - val_accuracy: 0.6226\n",
      "Epoch 8394/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7184 - val_accuracy: 0.6221\n",
      "Epoch 8395/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7173 - val_accuracy: 0.6233\n",
      "Epoch 8396/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7219 - val_accuracy: 0.6201\n",
      "Epoch 8397/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7151 - val_accuracy: 0.6249\n",
      "Epoch 8398/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7233 - val_accuracy: 0.6185\n",
      "Epoch 8399/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7120 - val_accuracy: 0.6280\n",
      "Epoch 8400/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7288 - val_accuracy: 0.6136\n",
      "Epoch 8401/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5595 - accuracy: 0.6994 - val_loss: 0.7071 - val_accuracy: 0.6318\n",
      "Epoch 8402/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7335 - val_accuracy: 0.6088\n",
      "Epoch 8403/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5603 - accuracy: 0.6987 - val_loss: 0.7026 - val_accuracy: 0.6356\n",
      "Epoch 8404/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5607 - accuracy: 0.6987 - val_loss: 0.7362 - val_accuracy: 0.6068\n",
      "Epoch 8405/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5607 - accuracy: 0.6982 - val_loss: 0.7053 - val_accuracy: 0.6338\n",
      "Epoch 8406/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5605 - accuracy: 0.6989 - val_loss: 0.7293 - val_accuracy: 0.6121\n",
      "Epoch 8407/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7106 - val_accuracy: 0.6284\n",
      "Epoch 8408/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7213 - val_accuracy: 0.6200\n",
      "Epoch 8409/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7207 - val_accuracy: 0.6209\n",
      "Epoch 8410/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7133 - val_accuracy: 0.6271\n",
      "Epoch 8411/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7273 - val_accuracy: 0.6139\n",
      "Epoch 8412/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7091 - val_accuracy: 0.6305\n",
      "Epoch 8413/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7282 - val_accuracy: 0.6140\n",
      "Epoch 8414/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7099 - val_accuracy: 0.6285\n",
      "Epoch 8415/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7268 - val_accuracy: 0.6146\n",
      "Epoch 8416/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7119 - val_accuracy: 0.6275\n",
      "Epoch 8417/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7199 - val_accuracy: 0.6198\n",
      "Epoch 8418/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7202 - val_accuracy: 0.6224\n",
      "Epoch 8419/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7131 - val_accuracy: 0.6252\n",
      "Epoch 8420/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7245 - val_accuracy: 0.6142\n",
      "Epoch 8421/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7098 - val_accuracy: 0.6306\n",
      "Epoch 8422/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7286 - val_accuracy: 0.6142\n",
      "Epoch 8423/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5603 - accuracy: 0.6990 - val_loss: 0.7077 - val_accuracy: 0.6290\n",
      "Epoch 8424/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5608 - accuracy: 0.6990 - val_loss: 0.7240 - val_accuracy: 0.6154\n",
      "Epoch 8425/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5605 - accuracy: 0.6989 - val_loss: 0.7146 - val_accuracy: 0.6261\n",
      "Epoch 8426/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5597 - accuracy: 0.6998 - val_loss: 0.7188 - val_accuracy: 0.6218\n",
      "Epoch 8427/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5608 - accuracy: 0.6992 - val_loss: 0.7157 - val_accuracy: 0.6209\n",
      "Epoch 8428/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5608 - accuracy: 0.6989 - val_loss: 0.7151 - val_accuracy: 0.6220\n",
      "Epoch 8429/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5614 - accuracy: 0.6987 - val_loss: 0.7159 - val_accuracy: 0.6224\n",
      "Epoch 8430/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5603 - accuracy: 0.6993 - val_loss: 0.7189 - val_accuracy: 0.6211\n",
      "Epoch 8431/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7164 - val_accuracy: 0.6244\n",
      "Epoch 8432/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5603 - accuracy: 0.6991 - val_loss: 0.7188 - val_accuracy: 0.6213\n",
      "Epoch 8433/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5601 - accuracy: 0.6991 - val_loss: 0.7172 - val_accuracy: 0.6218\n",
      "Epoch 8434/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5604 - accuracy: 0.6989 - val_loss: 0.7171 - val_accuracy: 0.6212\n",
      "Epoch 8435/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5600 - accuracy: 0.6996 - val_loss: 0.7154 - val_accuracy: 0.6229\n",
      "Epoch 8436/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7177 - val_accuracy: 0.6232\n",
      "Epoch 8437/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7174 - val_accuracy: 0.6216\n",
      "Epoch 8438/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7212 - val_accuracy: 0.6196\n",
      "Epoch 8439/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5602 - accuracy: 0.6990 - val_loss: 0.7135 - val_accuracy: 0.6250\n",
      "Epoch 8440/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7177 - val_accuracy: 0.6223\n",
      "Epoch 8441/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7176 - val_accuracy: 0.6233\n",
      "Epoch 8442/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7205 - val_accuracy: 0.6206\n",
      "Epoch 8443/10000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7201 - val_accuracy: 0.6202\n",
      "Epoch 8444/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7116 - val_accuracy: 0.6260\n",
      "Epoch 8445/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7231 - val_accuracy: 0.6190\n",
      "Epoch 8446/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7117 - val_accuracy: 0.6276\n",
      "Epoch 8447/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7268 - val_accuracy: 0.6139\n",
      "Epoch 8448/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5601 - accuracy: 0.6989 - val_loss: 0.7119 - val_accuracy: 0.6273\n",
      "Epoch 8449/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7217 - val_accuracy: 0.6199\n",
      "Epoch 8450/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7150 - val_accuracy: 0.6247\n",
      "Epoch 8451/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7194 - val_accuracy: 0.6214\n",
      "Epoch 8452/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7212 - val_accuracy: 0.6200\n",
      "Epoch 8453/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7153 - val_accuracy: 0.6238\n",
      "Epoch 8454/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7211 - val_accuracy: 0.6204\n",
      "Epoch 8455/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7137 - val_accuracy: 0.6269\n",
      "Epoch 8456/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7245 - val_accuracy: 0.6165\n",
      "Epoch 8457/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7136 - val_accuracy: 0.6255\n",
      "Epoch 8458/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7213 - val_accuracy: 0.6205\n",
      "Epoch 8459/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7159 - val_accuracy: 0.6243\n",
      "Epoch 8460/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7204 - val_accuracy: 0.6206\n",
      "Epoch 8461/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7182 - val_accuracy: 0.6220\n",
      "Epoch 8462/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.6226\n",
      "Epoch 8463/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7197 - val_accuracy: 0.6217\n",
      "Epoch 8464/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7177 - val_accuracy: 0.6229\n",
      "Epoch 8465/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7194 - val_accuracy: 0.6212\n",
      "Epoch 8466/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.6234\n",
      "Epoch 8467/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7193 - val_accuracy: 0.6224\n",
      "Epoch 8468/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7175 - val_accuracy: 0.6225\n",
      "Epoch 8469/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7204 - val_accuracy: 0.6212\n",
      "Epoch 8470/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7174 - val_accuracy: 0.6241\n",
      "Epoch 8471/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7206 - val_accuracy: 0.6204\n",
      "Epoch 8472/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7149 - val_accuracy: 0.6251\n",
      "Epoch 8473/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7242 - val_accuracy: 0.6182\n",
      "Epoch 8474/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7128 - val_accuracy: 0.6275\n",
      "Epoch 8475/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7277 - val_accuracy: 0.6150\n",
      "Epoch 8476/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7080 - val_accuracy: 0.6310\n",
      "Epoch 8477/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7322 - val_accuracy: 0.6099\n",
      "Epoch 8478/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5598 - accuracy: 0.6991 - val_loss: 0.7055 - val_accuracy: 0.6342\n",
      "Epoch 8479/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5602 - accuracy: 0.6991 - val_loss: 0.7346 - val_accuracy: 0.6086\n",
      "Epoch 8480/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5602 - accuracy: 0.6988 - val_loss: 0.7054 - val_accuracy: 0.6330\n",
      "Epoch 8481/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7286 - val_accuracy: 0.6131\n",
      "Epoch 8482/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7143 - val_accuracy: 0.6276\n",
      "Epoch 8483/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7207 - val_accuracy: 0.6205\n",
      "Epoch 8484/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7202 - val_accuracy: 0.6206\n",
      "Epoch 8485/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7134 - val_accuracy: 0.6272\n",
      "Epoch 8486/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7284 - val_accuracy: 0.6142\n",
      "Epoch 8487/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7101 - val_accuracy: 0.6296\n",
      "Epoch 8488/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7267 - val_accuracy: 0.6153\n",
      "Epoch 8489/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7130 - val_accuracy: 0.6283\n",
      "Epoch 8490/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5593 - accuracy: 0.7001 - val_loss: 0.7249 - val_accuracy: 0.6173\n",
      "Epoch 8491/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7127 - val_accuracy: 0.6262\n",
      "Epoch 8492/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7215 - val_accuracy: 0.6198\n",
      "Epoch 8493/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7204 - val_accuracy: 0.6222\n",
      "Epoch 8494/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7159 - val_accuracy: 0.6241\n",
      "Epoch 8495/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7215 - val_accuracy: 0.6196\n",
      "Epoch 8496/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7157 - val_accuracy: 0.6263\n",
      "Epoch 8497/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7248 - val_accuracy: 0.6160\n",
      "Epoch 8498/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7109 - val_accuracy: 0.6285\n",
      "Epoch 8499/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7267 - val_accuracy: 0.6160\n",
      "Epoch 8500/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7124 - val_accuracy: 0.6265\n",
      "Epoch 8501/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7252 - val_accuracy: 0.6161\n",
      "Epoch 8502/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7128 - val_accuracy: 0.6280\n",
      "Epoch 8503/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7230 - val_accuracy: 0.6178\n",
      "Epoch 8504/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7152 - val_accuracy: 0.6243\n",
      "Epoch 8505/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7209 - val_accuracy: 0.6212\n",
      "Epoch 8506/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7173 - val_accuracy: 0.6232\n",
      "Epoch 8507/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7188 - val_accuracy: 0.6214\n",
      "Epoch 8508/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7206 - val_accuracy: 0.6213\n",
      "Epoch 8509/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7175 - val_accuracy: 0.6234\n",
      "Epoch 8510/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7202 - val_accuracy: 0.6211\n",
      "Epoch 8511/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7154 - val_accuracy: 0.6257\n",
      "Epoch 8512/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7236 - val_accuracy: 0.6178\n",
      "Epoch 8513/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7134 - val_accuracy: 0.6263\n",
      "Epoch 8514/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7241 - val_accuracy: 0.6189\n",
      "Epoch 8515/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7130 - val_accuracy: 0.6255\n",
      "Epoch 8516/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7262 - val_accuracy: 0.6147\n",
      "Epoch 8517/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7119 - val_accuracy: 0.6302\n",
      "Epoch 8518/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7254 - val_accuracy: 0.6162\n",
      "Epoch 8519/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7130 - val_accuracy: 0.6264\n",
      "Epoch 8520/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7239 - val_accuracy: 0.6181\n",
      "Epoch 8521/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6994 - val_loss: 0.7146 - val_accuracy: 0.6254\n",
      "Epoch 8522/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7198 - val_accuracy: 0.6201\n",
      "Epoch 8523/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7197 - val_accuracy: 0.6213\n",
      "Epoch 8524/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.6240\n",
      "Epoch 8525/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7213 - val_accuracy: 0.6196\n",
      "Epoch 8526/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7151 - val_accuracy: 0.6249\n",
      "Epoch 8527/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7224 - val_accuracy: 0.6198\n",
      "Epoch 8528/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7148 - val_accuracy: 0.6248\n",
      "Epoch 8529/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7217 - val_accuracy: 0.6186\n",
      "Epoch 8530/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7173 - val_accuracy: 0.6237\n",
      "Epoch 8531/10000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7207 - val_accuracy: 0.6214\n",
      "Epoch 8532/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7160 - val_accuracy: 0.6229\n",
      "Epoch 8533/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7192 - val_accuracy: 0.6214\n",
      "Epoch 8534/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7195 - val_accuracy: 0.6226\n",
      "Epoch 8535/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7194 - val_accuracy: 0.6214\n",
      "Epoch 8536/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7176 - val_accuracy: 0.6215\n",
      "Epoch 8537/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7190 - val_accuracy: 0.6224\n",
      "Epoch 8538/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7164 - val_accuracy: 0.6234\n",
      "Epoch 8539/10000\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7215 - val_accuracy: 0.6184\n",
      "Epoch 8540/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7178 - val_accuracy: 0.6243\n",
      "Epoch 8541/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7166 - val_accuracy: 0.6225\n",
      "Epoch 8542/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7166 - val_accuracy: 0.6208\n",
      "Epoch 8543/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7194 - val_accuracy: 0.6232\n",
      "Epoch 8544/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7235 - val_accuracy: 0.6207\n",
      "Epoch 8545/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7084 - val_accuracy: 0.6271\n",
      "Epoch 8546/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5604 - accuracy: 0.6991 - val_loss: 0.7256 - val_accuracy: 0.6129\n",
      "Epoch 8547/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5604 - accuracy: 0.6990 - val_loss: 0.7127 - val_accuracy: 0.6306\n",
      "Epoch 8548/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5602 - accuracy: 0.6991 - val_loss: 0.7271 - val_accuracy: 0.6155\n",
      "Epoch 8549/10000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.5604 - accuracy: 0.6990 - val_loss: 0.7071 - val_accuracy: 0.6267\n",
      "Epoch 8550/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5608 - accuracy: 0.6989 - val_loss: 0.7214 - val_accuracy: 0.6167\n",
      "Epoch 8551/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5603 - accuracy: 0.6991 - val_loss: 0.7183 - val_accuracy: 0.6260\n",
      "Epoch 8552/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7177 - val_accuracy: 0.6224\n",
      "Epoch 8553/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5601 - accuracy: 0.6994 - val_loss: 0.7184 - val_accuracy: 0.6182\n",
      "Epoch 8554/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5603 - accuracy: 0.6991 - val_loss: 0.7133 - val_accuracy: 0.6258\n",
      "Epoch 8555/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7247 - val_accuracy: 0.6198\n",
      "Epoch 8556/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5602 - accuracy: 0.6991 - val_loss: 0.7135 - val_accuracy: 0.6242\n",
      "Epoch 8557/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7176 - val_accuracy: 0.6202\n",
      "Epoch 8558/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7175 - val_accuracy: 0.6235\n",
      "Epoch 8559/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7192 - val_accuracy: 0.6232\n",
      "Epoch 8560/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7203 - val_accuracy: 0.6189\n",
      "Epoch 8561/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7119 - val_accuracy: 0.6263\n",
      "Epoch 8562/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7243 - val_accuracy: 0.6193\n",
      "Epoch 8563/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7153 - val_accuracy: 0.6252\n",
      "Epoch 8564/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7242 - val_accuracy: 0.6162\n",
      "Epoch 8565/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7110 - val_accuracy: 0.6273\n",
      "Epoch 8566/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7214 - val_accuracy: 0.6204\n",
      "Epoch 8567/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7170 - val_accuracy: 0.6235\n",
      "Epoch 8568/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7244 - val_accuracy: 0.6177\n",
      "Epoch 8569/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7146 - val_accuracy: 0.6254\n",
      "Epoch 8570/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7188 - val_accuracy: 0.6221\n",
      "Epoch 8571/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7172 - val_accuracy: 0.6226\n",
      "Epoch 8572/10000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7220 - val_accuracy: 0.6203\n",
      "Epoch 8573/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7186 - val_accuracy: 0.6224\n",
      "Epoch 8574/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7167 - val_accuracy: 0.6229\n",
      "Epoch 8575/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7201 - val_accuracy: 0.6219\n",
      "Epoch 8576/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7179 - val_accuracy: 0.6240\n",
      "Epoch 8577/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7224 - val_accuracy: 0.6185\n",
      "Epoch 8578/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7150 - val_accuracy: 0.6257\n",
      "Epoch 8579/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7231 - val_accuracy: 0.6200\n",
      "Epoch 8580/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7137 - val_accuracy: 0.6253\n",
      "Epoch 8581/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7246 - val_accuracy: 0.6164\n",
      "Epoch 8582/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7139 - val_accuracy: 0.6275\n",
      "Epoch 8583/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7243 - val_accuracy: 0.6186\n",
      "Epoch 8584/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7136 - val_accuracy: 0.6261\n",
      "Epoch 8585/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7242 - val_accuracy: 0.6176\n",
      "Epoch 8586/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7148 - val_accuracy: 0.6258\n",
      "Epoch 8587/10000\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7228 - val_accuracy: 0.6191\n",
      "Epoch 8588/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7167 - val_accuracy: 0.6245\n",
      "Epoch 8589/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7202 - val_accuracy: 0.6207\n",
      "Epoch 8590/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7187 - val_accuracy: 0.6222\n",
      "Epoch 8591/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7209 - val_accuracy: 0.6220\n",
      "Epoch 8592/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7156 - val_accuracy: 0.6245\n",
      "Epoch 8593/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7212 - val_accuracy: 0.6201\n",
      "Epoch 8594/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.6245\n",
      "Epoch 8595/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7218 - val_accuracy: 0.6188\n",
      "Epoch 8596/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7143 - val_accuracy: 0.6257\n",
      "Epoch 8597/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7248 - val_accuracy: 0.6187\n",
      "Epoch 8598/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7130 - val_accuracy: 0.6265\n",
      "Epoch 8599/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7265 - val_accuracy: 0.6163\n",
      "Epoch 8600/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7110 - val_accuracy: 0.6301\n",
      "Epoch 8601/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7297 - val_accuracy: 0.6113\n",
      "Epoch 8602/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7067 - val_accuracy: 0.6327\n",
      "Epoch 8603/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7332 - val_accuracy: 0.6115\n",
      "Epoch 8604/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5598 - accuracy: 0.6991 - val_loss: 0.7057 - val_accuracy: 0.6312\n",
      "Epoch 8605/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5607 - accuracy: 0.6990 - val_loss: 0.7309 - val_accuracy: 0.6095\n",
      "Epoch 8606/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5603 - accuracy: 0.6989 - val_loss: 0.7092 - val_accuracy: 0.6327\n",
      "Epoch 8607/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7280 - val_accuracy: 0.6151\n",
      "Epoch 8608/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7105 - val_accuracy: 0.6258\n",
      "Epoch 8609/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5606 - accuracy: 0.6992 - val_loss: 0.7200 - val_accuracy: 0.6191\n",
      "Epoch 8610/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5604 - accuracy: 0.6992 - val_loss: 0.7176 - val_accuracy: 0.6232\n",
      "Epoch 8611/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7175 - val_accuracy: 0.6235\n",
      "Epoch 8612/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7201 - val_accuracy: 0.6198\n",
      "Epoch 8613/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7171 - val_accuracy: 0.6241\n",
      "Epoch 8614/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7219 - val_accuracy: 0.6203\n",
      "Epoch 8615/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7157 - val_accuracy: 0.6239\n",
      "Epoch 8616/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7173 - val_accuracy: 0.6228\n",
      "Epoch 8617/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7223 - val_accuracy: 0.6206\n",
      "Epoch 8618/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7180 - val_accuracy: 0.6232\n",
      "Epoch 8619/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7186 - val_accuracy: 0.6206\n",
      "Epoch 8620/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7146 - val_accuracy: 0.6256\n",
      "Epoch 8621/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7239 - val_accuracy: 0.6197\n",
      "Epoch 8622/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7187 - val_accuracy: 0.6221\n",
      "Epoch 8623/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7176 - val_accuracy: 0.6223\n",
      "Epoch 8624/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7178 - val_accuracy: 0.6239\n",
      "Epoch 8625/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7186 - val_accuracy: 0.6223\n",
      "Epoch 8626/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7231 - val_accuracy: 0.6184\n",
      "Epoch 8627/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7138 - val_accuracy: 0.6263\n",
      "Epoch 8628/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7250 - val_accuracy: 0.6178\n",
      "Epoch 8629/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7114 - val_accuracy: 0.6280\n",
      "Epoch 8630/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7280 - val_accuracy: 0.6135\n",
      "Epoch 8631/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7117 - val_accuracy: 0.6293\n",
      "Epoch 8632/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7268 - val_accuracy: 0.6155\n",
      "Epoch 8633/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7097 - val_accuracy: 0.6289\n",
      "Epoch 8634/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5597 - accuracy: 0.6998 - val_loss: 0.7271 - val_accuracy: 0.6150\n",
      "Epoch 8635/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7119 - val_accuracy: 0.6281\n",
      "Epoch 8636/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7251 - val_accuracy: 0.6165\n",
      "Epoch 8637/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7110 - val_accuracy: 0.6272\n",
      "Epoch 8638/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5600 - accuracy: 0.6995 - val_loss: 0.7242 - val_accuracy: 0.6168\n",
      "Epoch 8639/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5601 - accuracy: 0.6991 - val_loss: 0.7148 - val_accuracy: 0.6254\n",
      "Epoch 8640/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7206 - val_accuracy: 0.6210\n",
      "Epoch 8641/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.7132 - val_accuracy: 0.6243\n",
      "Epoch 8642/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7220 - val_accuracy: 0.6178\n",
      "Epoch 8643/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5603 - accuracy: 0.6989 - val_loss: 0.7151 - val_accuracy: 0.6247\n",
      "Epoch 8644/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7188 - val_accuracy: 0.6220\n",
      "Epoch 8645/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7186 - val_accuracy: 0.6226\n",
      "Epoch 8646/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7185 - val_accuracy: 0.6230\n",
      "Epoch 8647/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7222 - val_accuracy: 0.6190\n",
      "Epoch 8648/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7118 - val_accuracy: 0.6261\n",
      "Epoch 8649/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7229 - val_accuracy: 0.6192\n",
      "Epoch 8650/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7136 - val_accuracy: 0.6259\n",
      "Epoch 8651/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7267 - val_accuracy: 0.6147\n",
      "Epoch 8652/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7107 - val_accuracy: 0.6280\n",
      "Epoch 8653/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7237 - val_accuracy: 0.6193\n",
      "Epoch 8654/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7164 - val_accuracy: 0.6255\n",
      "Epoch 8655/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7220 - val_accuracy: 0.6188\n",
      "Epoch 8656/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7181 - val_accuracy: 0.6223\n",
      "Epoch 8657/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7166 - val_accuracy: 0.6246\n",
      "Epoch 8658/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7220 - val_accuracy: 0.6209\n",
      "Epoch 8659/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7137 - val_accuracy: 0.6243\n",
      "Epoch 8660/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7248 - val_accuracy: 0.6160\n",
      "Epoch 8661/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7132 - val_accuracy: 0.6273\n",
      "Epoch 8662/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7237 - val_accuracy: 0.6190\n",
      "Epoch 8663/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7136 - val_accuracy: 0.6264\n",
      "Epoch 8664/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7258 - val_accuracy: 0.6169\n",
      "Epoch 8665/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7145 - val_accuracy: 0.6258\n",
      "Epoch 8666/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7213 - val_accuracy: 0.6189\n",
      "Epoch 8667/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7143 - val_accuracy: 0.6265\n",
      "Epoch 8668/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7244 - val_accuracy: 0.6189\n",
      "Epoch 8669/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7168 - val_accuracy: 0.6232\n",
      "Epoch 8670/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7198 - val_accuracy: 0.6211\n",
      "Epoch 8671/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7181 - val_accuracy: 0.6246\n",
      "Epoch 8672/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7197 - val_accuracy: 0.6221\n",
      "Epoch 8673/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7214 - val_accuracy: 0.6197\n",
      "Epoch 8674/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7152 - val_accuracy: 0.6262\n",
      "Epoch 8675/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7253 - val_accuracy: 0.6180\n",
      "Epoch 8676/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7109 - val_accuracy: 0.6277\n",
      "Epoch 8677/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7290 - val_accuracy: 0.6131\n",
      "Epoch 8678/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7120 - val_accuracy: 0.6303\n",
      "Epoch 8679/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7266 - val_accuracy: 0.6154\n",
      "Epoch 8680/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7094 - val_accuracy: 0.6287\n",
      "Epoch 8681/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5592 - accuracy: 0.7002 - val_loss: 0.7278 - val_accuracy: 0.6150\n",
      "Epoch 8682/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7143 - val_accuracy: 0.6266\n",
      "Epoch 8683/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7229 - val_accuracy: 0.6193\n",
      "Epoch 8684/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7140 - val_accuracy: 0.6259\n",
      "Epoch 8685/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5590 - accuracy: 0.7003 - val_loss: 0.7233 - val_accuracy: 0.6194\n",
      "Epoch 8686/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7172 - val_accuracy: 0.6238\n",
      "Epoch 8687/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7213 - val_accuracy: 0.6206\n",
      "Epoch 8688/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7162 - val_accuracy: 0.6240\n",
      "Epoch 8689/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7204 - val_accuracy: 0.6206\n",
      "Epoch 8690/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7173 - val_accuracy: 0.6231\n",
      "Epoch 8691/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7199 - val_accuracy: 0.6221\n",
      "Epoch 8692/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7175 - val_accuracy: 0.6222\n",
      "Epoch 8693/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7197 - val_accuracy: 0.6207\n",
      "Epoch 8694/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7177 - val_accuracy: 0.6230\n",
      "Epoch 8695/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7192 - val_accuracy: 0.6223\n",
      "Epoch 8696/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7181 - val_accuracy: 0.6226\n",
      "Epoch 8697/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7212 - val_accuracy: 0.6201\n",
      "Epoch 8698/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7173 - val_accuracy: 0.6232\n",
      "Epoch 8699/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7189 - val_accuracy: 0.6226\n",
      "Epoch 8700/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7192 - val_accuracy: 0.6230\n",
      "Epoch 8701/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7199 - val_accuracy: 0.6211\n",
      "Epoch 8702/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7204 - val_accuracy: 0.6204\n",
      "Epoch 8703/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7144 - val_accuracy: 0.6264\n",
      "Epoch 8704/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7260 - val_accuracy: 0.6173\n",
      "Epoch 8705/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7135 - val_accuracy: 0.6268\n",
      "Epoch 8706/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7268 - val_accuracy: 0.6146\n",
      "Epoch 8707/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7098 - val_accuracy: 0.6309\n",
      "Epoch 8708/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7295 - val_accuracy: 0.6136\n",
      "Epoch 8709/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7095 - val_accuracy: 0.6298\n",
      "Epoch 8710/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7303 - val_accuracy: 0.6118\n",
      "Epoch 8711/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7097 - val_accuracy: 0.6308\n",
      "Epoch 8712/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7266 - val_accuracy: 0.6152\n",
      "Epoch 8713/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7142 - val_accuracy: 0.6262\n",
      "Epoch 8714/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7243 - val_accuracy: 0.6184\n",
      "Epoch 8715/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7170 - val_accuracy: 0.6234\n",
      "Epoch 8716/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7181 - val_accuracy: 0.6234\n",
      "Epoch 8717/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7219 - val_accuracy: 0.6205\n",
      "Epoch 8718/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7174 - val_accuracy: 0.6240\n",
      "Epoch 8719/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7230 - val_accuracy: 0.6188\n",
      "Epoch 8720/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7151 - val_accuracy: 0.6258\n",
      "Epoch 8721/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7234 - val_accuracy: 0.6190\n",
      "Epoch 8722/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7157 - val_accuracy: 0.6255\n",
      "Epoch 8723/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7252 - val_accuracy: 0.6178\n",
      "Epoch 8724/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7133 - val_accuracy: 0.6271\n",
      "Epoch 8725/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7260 - val_accuracy: 0.6170\n",
      "Epoch 8726/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7123 - val_accuracy: 0.6283\n",
      "Epoch 8727/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7294 - val_accuracy: 0.6132\n",
      "Epoch 8728/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7104 - val_accuracy: 0.6307\n",
      "Epoch 8729/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7304 - val_accuracy: 0.6129\n",
      "Epoch 8730/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5600 - accuracy: 0.6989 - val_loss: 0.7070 - val_accuracy: 0.6306\n",
      "Epoch 8731/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7285 - val_accuracy: 0.6135\n",
      "Epoch 8732/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7141 - val_accuracy: 0.6283\n",
      "Epoch 8733/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7247 - val_accuracy: 0.6169\n",
      "Epoch 8734/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7164 - val_accuracy: 0.6235\n",
      "Epoch 8735/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7174 - val_accuracy: 0.6248\n",
      "Epoch 8736/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7254 - val_accuracy: 0.6170\n",
      "Epoch 8737/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7140 - val_accuracy: 0.6257\n",
      "Epoch 8738/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7246 - val_accuracy: 0.6187\n",
      "Epoch 8739/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7131 - val_accuracy: 0.6266\n",
      "Epoch 8740/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7241 - val_accuracy: 0.6165\n",
      "Epoch 8741/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7175 - val_accuracy: 0.6265\n",
      "Epoch 8742/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7211 - val_accuracy: 0.6199\n",
      "Epoch 8743/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7141 - val_accuracy: 0.6218\n",
      "Epoch 8744/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5601 - accuracy: 0.6996 - val_loss: 0.7189 - val_accuracy: 0.6222\n",
      "Epoch 8745/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5605 - accuracy: 0.6990 - val_loss: 0.7211 - val_accuracy: 0.6217\n",
      "Epoch 8746/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7189 - val_accuracy: 0.6221\n",
      "Epoch 8747/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5605 - accuracy: 0.6990 - val_loss: 0.7127 - val_accuracy: 0.6250\n",
      "Epoch 8748/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5609 - accuracy: 0.6986 - val_loss: 0.7227 - val_accuracy: 0.6170\n",
      "Epoch 8749/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5611 - accuracy: 0.6987 - val_loss: 0.7130 - val_accuracy: 0.6266\n",
      "Epoch 8750/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5610 - accuracy: 0.6990 - val_loss: 0.7240 - val_accuracy: 0.6166\n",
      "Epoch 8751/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5607 - accuracy: 0.6988 - val_loss: 0.7118 - val_accuracy: 0.6281\n",
      "Epoch 8752/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5605 - accuracy: 0.6989 - val_loss: 0.7233 - val_accuracy: 0.6183\n",
      "Epoch 8753/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5605 - accuracy: 0.6991 - val_loss: 0.7191 - val_accuracy: 0.6223\n",
      "Epoch 8754/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7178 - val_accuracy: 0.6228\n",
      "Epoch 8755/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5600 - accuracy: 0.6995 - val_loss: 0.7195 - val_accuracy: 0.6207\n",
      "Epoch 8756/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7146 - val_accuracy: 0.6259\n",
      "Epoch 8757/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5598 - accuracy: 0.6996 - val_loss: 0.7229 - val_accuracy: 0.6186\n",
      "Epoch 8758/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7185 - val_accuracy: 0.6234\n",
      "Epoch 8759/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5598 - accuracy: 0.6992 - val_loss: 0.7189 - val_accuracy: 0.6213\n",
      "Epoch 8760/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7188 - val_accuracy: 0.6229\n",
      "Epoch 8761/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7183 - val_accuracy: 0.6244\n",
      "Epoch 8762/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7237 - val_accuracy: 0.6181\n",
      "Epoch 8763/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7149 - val_accuracy: 0.6242\n",
      "Epoch 8764/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7213 - val_accuracy: 0.6203\n",
      "Epoch 8765/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7169 - val_accuracy: 0.6252\n",
      "Epoch 8766/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7209 - val_accuracy: 0.6202\n",
      "Epoch 8767/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7205 - val_accuracy: 0.6207\n",
      "Epoch 8768/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7178 - val_accuracy: 0.6241\n",
      "Epoch 8769/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7226 - val_accuracy: 0.6207\n",
      "Epoch 8770/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7154 - val_accuracy: 0.6248\n",
      "Epoch 8771/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7228 - val_accuracy: 0.6187\n",
      "Epoch 8772/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7161 - val_accuracy: 0.6256\n",
      "Epoch 8773/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7249 - val_accuracy: 0.6181\n",
      "Epoch 8774/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7137 - val_accuracy: 0.6263\n",
      "Epoch 8775/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7241 - val_accuracy: 0.6182\n",
      "Epoch 8776/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7152 - val_accuracy: 0.6261\n",
      "Epoch 8777/10000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7234 - val_accuracy: 0.6178\n",
      "Epoch 8778/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7160 - val_accuracy: 0.6252\n",
      "Epoch 8779/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7239 - val_accuracy: 0.6194\n",
      "Epoch 8780/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7148 - val_accuracy: 0.6249\n",
      "Epoch 8781/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7226 - val_accuracy: 0.6201\n",
      "Epoch 8782/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.6244\n",
      "Epoch 8783/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7222 - val_accuracy: 0.6192\n",
      "Epoch 8784/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7159 - val_accuracy: 0.6256\n",
      "Epoch 8785/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7241 - val_accuracy: 0.6190\n",
      "Epoch 8786/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7149 - val_accuracy: 0.6254\n",
      "Epoch 8787/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7249 - val_accuracy: 0.6170\n",
      "Epoch 8788/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7134 - val_accuracy: 0.6282\n",
      "Epoch 8789/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7285 - val_accuracy: 0.6143\n",
      "Epoch 8790/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7106 - val_accuracy: 0.6292\n",
      "Epoch 8791/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7307 - val_accuracy: 0.6123\n",
      "Epoch 8792/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5595 - accuracy: 0.6994 - val_loss: 0.7058 - val_accuracy: 0.6333\n",
      "Epoch 8793/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7360 - val_accuracy: 0.6083\n",
      "Epoch 8794/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5601 - accuracy: 0.6988 - val_loss: 0.7061 - val_accuracy: 0.6336\n",
      "Epoch 8795/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5604 - accuracy: 0.6989 - val_loss: 0.7332 - val_accuracy: 0.6087\n",
      "Epoch 8796/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5601 - accuracy: 0.6989 - val_loss: 0.7091 - val_accuracy: 0.6322\n",
      "Epoch 8797/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7265 - val_accuracy: 0.6171\n",
      "Epoch 8798/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7160 - val_accuracy: 0.6224\n",
      "Epoch 8799/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7174 - val_accuracy: 0.6234\n",
      "Epoch 8800/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7280 - val_accuracy: 0.6179\n",
      "Epoch 8801/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7078 - val_accuracy: 0.6297\n",
      "Epoch 8802/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5600 - accuracy: 0.6995 - val_loss: 0.7306 - val_accuracy: 0.6104\n",
      "Epoch 8803/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7117 - val_accuracy: 0.6330\n",
      "Epoch 8804/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5604 - accuracy: 0.6987 - val_loss: 0.7252 - val_accuracy: 0.6147\n",
      "Epoch 8805/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7167 - val_accuracy: 0.6223\n",
      "Epoch 8806/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7180 - val_accuracy: 0.6259\n",
      "Epoch 8807/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7238 - val_accuracy: 0.6175\n",
      "Epoch 8808/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7113 - val_accuracy: 0.6278\n",
      "Epoch 8809/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7285 - val_accuracy: 0.6163\n",
      "Epoch 8810/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7139 - val_accuracy: 0.6274\n",
      "Epoch 8811/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7225 - val_accuracy: 0.6168\n",
      "Epoch 8812/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7161 - val_accuracy: 0.6248\n",
      "Epoch 8813/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7213 - val_accuracy: 0.6226\n",
      "Epoch 8814/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7211 - val_accuracy: 0.6194\n",
      "Epoch 8815/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7134 - val_accuracy: 0.6270\n",
      "Epoch 8816/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7280 - val_accuracy: 0.6170\n",
      "Epoch 8817/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7114 - val_accuracy: 0.6281\n",
      "Epoch 8818/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7272 - val_accuracy: 0.6134\n",
      "Epoch 8819/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5599 - accuracy: 0.6991 - val_loss: 0.7123 - val_accuracy: 0.6289\n",
      "Epoch 8820/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7249 - val_accuracy: 0.6180\n",
      "Epoch 8821/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7158 - val_accuracy: 0.6235\n",
      "Epoch 8822/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7186 - val_accuracy: 0.6229\n",
      "Epoch 8823/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7225 - val_accuracy: 0.6205\n",
      "Epoch 8824/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7146 - val_accuracy: 0.6250\n",
      "Epoch 8825/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7258 - val_accuracy: 0.6160\n",
      "Epoch 8826/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7144 - val_accuracy: 0.6284\n",
      "Epoch 8827/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7221 - val_accuracy: 0.6185\n",
      "Epoch 8828/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7168 - val_accuracy: 0.6235\n",
      "Epoch 8829/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7223 - val_accuracy: 0.6220\n",
      "Epoch 8830/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7208 - val_accuracy: 0.6211\n",
      "Epoch 8831/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7149 - val_accuracy: 0.6239\n",
      "Epoch 8832/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7225 - val_accuracy: 0.6202\n",
      "Epoch 8833/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7181 - val_accuracy: 0.6248\n",
      "Epoch 8834/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7246 - val_accuracy: 0.6180\n",
      "Epoch 8835/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7156 - val_accuracy: 0.6261\n",
      "Epoch 8836/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7238 - val_accuracy: 0.6197\n",
      "Epoch 8837/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7148 - val_accuracy: 0.6251\n",
      "Epoch 8838/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7239 - val_accuracy: 0.6181\n",
      "Epoch 8839/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5587 - accuracy: 0.7000 - val_loss: 0.7179 - val_accuracy: 0.6248\n",
      "Epoch 8840/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7206 - val_accuracy: 0.6212\n",
      "Epoch 8841/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7202 - val_accuracy: 0.6218\n",
      "Epoch 8842/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5586 - accuracy: 0.7005 - val_loss: 0.7187 - val_accuracy: 0.6239\n",
      "Epoch 8843/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7211 - val_accuracy: 0.6198\n",
      "Epoch 8844/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7169 - val_accuracy: 0.6248\n",
      "Epoch 8845/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7240 - val_accuracy: 0.6203\n",
      "Epoch 8846/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5588 - accuracy: 0.6999 - val_loss: 0.7145 - val_accuracy: 0.6251\n",
      "Epoch 8847/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7258 - val_accuracy: 0.6170\n",
      "Epoch 8848/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7143 - val_accuracy: 0.6281\n",
      "Epoch 8849/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7257 - val_accuracy: 0.6146\n",
      "Epoch 8850/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7116 - val_accuracy: 0.6280\n",
      "Epoch 8851/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7281 - val_accuracy: 0.6162\n",
      "Epoch 8852/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7125 - val_accuracy: 0.6273\n",
      "Epoch 8853/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7252 - val_accuracy: 0.6167\n",
      "Epoch 8854/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7162 - val_accuracy: 0.6268\n",
      "Epoch 8855/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7247 - val_accuracy: 0.6175\n",
      "Epoch 8856/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7162 - val_accuracy: 0.6248\n",
      "Epoch 8857/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7220 - val_accuracy: 0.6216\n",
      "Epoch 8858/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7191 - val_accuracy: 0.6219\n",
      "Epoch 8859/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7189 - val_accuracy: 0.6224\n",
      "Epoch 8860/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7217 - val_accuracy: 0.6222\n",
      "Epoch 8861/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7183 - val_accuracy: 0.6235\n",
      "Epoch 8862/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7229 - val_accuracy: 0.6191\n",
      "Epoch 8863/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7153 - val_accuracy: 0.6267\n",
      "Epoch 8864/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7262 - val_accuracy: 0.6167\n",
      "Epoch 8865/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.6999 - val_loss: 0.7130 - val_accuracy: 0.6272\n",
      "Epoch 8866/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7282 - val_accuracy: 0.6149\n",
      "Epoch 8867/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7110 - val_accuracy: 0.6299\n",
      "Epoch 8868/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7307 - val_accuracy: 0.6130\n",
      "Epoch 8869/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7092 - val_accuracy: 0.6311\n",
      "Epoch 8870/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7318 - val_accuracy: 0.6113\n",
      "Epoch 8871/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7099 - val_accuracy: 0.6309\n",
      "Epoch 8872/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7296 - val_accuracy: 0.6140\n",
      "Epoch 8873/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7117 - val_accuracy: 0.6283\n",
      "Epoch 8874/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7263 - val_accuracy: 0.6167\n",
      "Epoch 8875/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7171 - val_accuracy: 0.6258\n",
      "Epoch 8876/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7201 - val_accuracy: 0.6220\n",
      "Epoch 8877/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7211 - val_accuracy: 0.6208\n",
      "Epoch 8878/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7177 - val_accuracy: 0.6250\n",
      "Epoch 8879/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7244 - val_accuracy: 0.6180\n",
      "Epoch 8880/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5587 - accuracy: 0.7000 - val_loss: 0.7149 - val_accuracy: 0.6267\n",
      "Epoch 8881/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7247 - val_accuracy: 0.6187\n",
      "Epoch 8882/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5588 - accuracy: 0.6999 - val_loss: 0.7160 - val_accuracy: 0.6254\n",
      "Epoch 8883/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7240 - val_accuracy: 0.6186\n",
      "Epoch 8884/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7167 - val_accuracy: 0.6250\n",
      "Epoch 8885/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7208 - val_accuracy: 0.6207\n",
      "Epoch 8886/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7188 - val_accuracy: 0.6223\n",
      "Epoch 8887/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7211 - val_accuracy: 0.6217\n",
      "Epoch 8888/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7177 - val_accuracy: 0.6233\n",
      "Epoch 8889/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7215 - val_accuracy: 0.6204\n",
      "Epoch 8890/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7209 - val_accuracy: 0.6224\n",
      "Epoch 8891/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7172 - val_accuracy: 0.6232\n",
      "Epoch 8892/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7211 - val_accuracy: 0.6209\n",
      "Epoch 8893/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7209 - val_accuracy: 0.6234\n",
      "Epoch 8894/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7194 - val_accuracy: 0.6213\n",
      "Epoch 8895/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7181 - val_accuracy: 0.6227\n",
      "Epoch 8896/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7233 - val_accuracy: 0.6218\n",
      "Epoch 8897/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7159 - val_accuracy: 0.6235\n",
      "Epoch 8898/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7234 - val_accuracy: 0.6182\n",
      "Epoch 8899/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7158 - val_accuracy: 0.6283\n",
      "Epoch 8900/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7273 - val_accuracy: 0.6153\n",
      "Epoch 8901/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7084 - val_accuracy: 0.6295\n",
      "Epoch 8902/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5598 - accuracy: 0.6997 - val_loss: 0.7328 - val_accuracy: 0.6110\n",
      "Epoch 8903/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5600 - accuracy: 0.6991 - val_loss: 0.7086 - val_accuracy: 0.6321\n",
      "Epoch 8904/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7320 - val_accuracy: 0.6104\n",
      "Epoch 8905/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5606 - accuracy: 0.6988 - val_loss: 0.7038 - val_accuracy: 0.6326\n",
      "Epoch 8906/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5617 - accuracy: 0.6984 - val_loss: 0.7298 - val_accuracy: 0.6107\n",
      "Epoch 8907/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5620 - accuracy: 0.6980 - val_loss: 0.7114 - val_accuracy: 0.6270\n",
      "Epoch 8908/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5603 - accuracy: 0.6994 - val_loss: 0.7202 - val_accuracy: 0.6208\n",
      "Epoch 8909/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7221 - val_accuracy: 0.6217\n",
      "Epoch 8910/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5607 - accuracy: 0.6992 - val_loss: 0.7120 - val_accuracy: 0.6275\n",
      "Epoch 8911/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5606 - accuracy: 0.6992 - val_loss: 0.7295 - val_accuracy: 0.6113\n",
      "Epoch 8912/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5619 - accuracy: 0.6979 - val_loss: 0.7048 - val_accuracy: 0.6310\n",
      "Epoch 8913/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5609 - accuracy: 0.6988 - val_loss: 0.7245 - val_accuracy: 0.6160\n",
      "Epoch 8914/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5604 - accuracy: 0.6989 - val_loss: 0.7189 - val_accuracy: 0.6230\n",
      "Epoch 8915/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5606 - accuracy: 0.6992 - val_loss: 0.7147 - val_accuracy: 0.6246\n",
      "Epoch 8916/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5603 - accuracy: 0.6990 - val_loss: 0.7274 - val_accuracy: 0.6129\n",
      "Epoch 8917/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5612 - accuracy: 0.6983 - val_loss: 0.7050 - val_accuracy: 0.6325\n",
      "Epoch 8918/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5609 - accuracy: 0.6986 - val_loss: 0.7267 - val_accuracy: 0.6152\n",
      "Epoch 8919/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5607 - accuracy: 0.6989 - val_loss: 0.7148 - val_accuracy: 0.6263\n",
      "Epoch 8920/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7201 - val_accuracy: 0.6218\n",
      "Epoch 8921/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7268 - val_accuracy: 0.6155\n",
      "Epoch 8922/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5600 - accuracy: 0.6990 - val_loss: 0.7077 - val_accuracy: 0.6306\n",
      "Epoch 8923/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7267 - val_accuracy: 0.6147\n",
      "Epoch 8924/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5604 - accuracy: 0.6990 - val_loss: 0.7100 - val_accuracy: 0.6289\n",
      "Epoch 8925/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7260 - val_accuracy: 0.6166\n",
      "Epoch 8926/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7214 - val_accuracy: 0.6209\n",
      "Epoch 8927/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7142 - val_accuracy: 0.6263\n",
      "Epoch 8928/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7208 - val_accuracy: 0.6193\n",
      "Epoch 8929/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7138 - val_accuracy: 0.6264\n",
      "Epoch 8930/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7274 - val_accuracy: 0.6163\n",
      "Epoch 8931/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7166 - val_accuracy: 0.6237\n",
      "Epoch 8932/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7175 - val_accuracy: 0.6225\n",
      "Epoch 8933/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7223 - val_accuracy: 0.6210\n",
      "Epoch 8934/10000\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7159 - val_accuracy: 0.6251\n",
      "Epoch 8935/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7248 - val_accuracy: 0.6161\n",
      "Epoch 8936/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7137 - val_accuracy: 0.6282\n",
      "Epoch 8937/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7256 - val_accuracy: 0.6185\n",
      "Epoch 8938/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7146 - val_accuracy: 0.6246\n",
      "Epoch 8939/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7218 - val_accuracy: 0.6200\n",
      "Epoch 8940/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7202 - val_accuracy: 0.6230\n",
      "Epoch 8941/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7186 - val_accuracy: 0.6225\n",
      "Epoch 8942/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7224 - val_accuracy: 0.6199\n",
      "Epoch 8943/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7163 - val_accuracy: 0.6265\n",
      "Epoch 8944/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7250 - val_accuracy: 0.6175\n",
      "Epoch 8945/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7132 - val_accuracy: 0.6270\n",
      "Epoch 8946/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7265 - val_accuracy: 0.6171\n",
      "Epoch 8947/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7155 - val_accuracy: 0.6260\n",
      "Epoch 8948/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7232 - val_accuracy: 0.6197\n",
      "Epoch 8949/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7175 - val_accuracy: 0.6235\n",
      "Epoch 8950/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7217 - val_accuracy: 0.6208\n",
      "Epoch 8951/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7187 - val_accuracy: 0.6238\n",
      "Epoch 8952/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7207 - val_accuracy: 0.6226\n",
      "Epoch 8953/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7191 - val_accuracy: 0.6219\n",
      "Epoch 8954/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7216 - val_accuracy: 0.6211\n",
      "Epoch 8955/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7179 - val_accuracy: 0.6242\n",
      "Epoch 8956/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7194 - val_accuracy: 0.6218\n",
      "Epoch 8957/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7223 - val_accuracy: 0.6212\n",
      "Epoch 8958/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7201 - val_accuracy: 0.6230\n",
      "Epoch 8959/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7196 - val_accuracy: 0.6209\n",
      "Epoch 8960/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7176 - val_accuracy: 0.6247\n",
      "Epoch 8961/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7224 - val_accuracy: 0.6213\n",
      "Epoch 8962/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7200 - val_accuracy: 0.6211\n",
      "Epoch 8963/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7198 - val_accuracy: 0.6228\n",
      "Epoch 8964/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7214 - val_accuracy: 0.6224\n",
      "Epoch 8965/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7176 - val_accuracy: 0.6222\n",
      "Epoch 8966/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7213 - val_accuracy: 0.6207\n",
      "Epoch 8967/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7195 - val_accuracy: 0.6243\n",
      "Epoch 8968/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7195 - val_accuracy: 0.6219\n",
      "Epoch 8969/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7211 - val_accuracy: 0.6210\n",
      "Epoch 8970/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7205 - val_accuracy: 0.6231\n",
      "Epoch 8971/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7187 - val_accuracy: 0.6220\n",
      "Epoch 8972/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7200 - val_accuracy: 0.6229\n",
      "Epoch 8973/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7219 - val_accuracy: 0.6229\n",
      "Epoch 8974/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7188 - val_accuracy: 0.6207\n",
      "Epoch 8975/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7187 - val_accuracy: 0.6227\n",
      "Epoch 8976/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7227 - val_accuracy: 0.6229\n",
      "Epoch 8977/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7169 - val_accuracy: 0.6221\n",
      "Epoch 8978/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7209 - val_accuracy: 0.6199\n",
      "Epoch 8979/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7203 - val_accuracy: 0.6254\n",
      "Epoch 8980/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7226 - val_accuracy: 0.6192\n",
      "Epoch 8981/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7134 - val_accuracy: 0.6247\n",
      "Epoch 8982/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7247 - val_accuracy: 0.6195\n",
      "Epoch 8983/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7174 - val_accuracy: 0.6246\n",
      "Epoch 8984/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7229 - val_accuracy: 0.6180\n",
      "Epoch 8985/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7151 - val_accuracy: 0.6263\n",
      "Epoch 8986/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7252 - val_accuracy: 0.6188\n",
      "Epoch 8987/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7169 - val_accuracy: 0.6240\n",
      "Epoch 8988/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7207 - val_accuracy: 0.6214\n",
      "Epoch 8989/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7202 - val_accuracy: 0.6226\n",
      "Epoch 8990/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7209 - val_accuracy: 0.6224\n",
      "Epoch 8991/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7191 - val_accuracy: 0.6218\n",
      "Epoch 8992/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7191 - val_accuracy: 0.6228\n",
      "Epoch 8993/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7237 - val_accuracy: 0.6204\n",
      "Epoch 8994/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5587 - accuracy: 0.7005 - val_loss: 0.7182 - val_accuracy: 0.6233\n",
      "Epoch 8995/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7211 - val_accuracy: 0.6207\n",
      "Epoch 8996/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7185 - val_accuracy: 0.6246\n",
      "Epoch 8997/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7235 - val_accuracy: 0.6201\n",
      "Epoch 8998/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7173 - val_accuracy: 0.6240\n",
      "Epoch 8999/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7233 - val_accuracy: 0.6202\n",
      "Epoch 9000/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7179 - val_accuracy: 0.6249\n",
      "Epoch 9001/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7229 - val_accuracy: 0.6201\n",
      "Epoch 9002/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7181 - val_accuracy: 0.6239\n",
      "Epoch 9003/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7243 - val_accuracy: 0.6196\n",
      "Epoch 9004/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7140 - val_accuracy: 0.6270\n",
      "Epoch 9005/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7281 - val_accuracy: 0.6152\n",
      "Epoch 9006/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7115 - val_accuracy: 0.6297\n",
      "Epoch 9007/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7317 - val_accuracy: 0.6109\n",
      "Epoch 9008/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5597 - accuracy: 0.6992 - val_loss: 0.7070 - val_accuracy: 0.6334\n",
      "Epoch 9009/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7365 - val_accuracy: 0.6095\n",
      "Epoch 9010/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5603 - accuracy: 0.6988 - val_loss: 0.7026 - val_accuracy: 0.6345\n",
      "Epoch 9011/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5620 - accuracy: 0.6982 - val_loss: 0.7326 - val_accuracy: 0.6070\n",
      "Epoch 9012/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5616 - accuracy: 0.6981 - val_loss: 0.7116 - val_accuracy: 0.6307\n",
      "Epoch 9013/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7248 - val_accuracy: 0.6202\n",
      "Epoch 9014/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7158 - val_accuracy: 0.6217\n",
      "Epoch 9015/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5601 - accuracy: 0.6994 - val_loss: 0.7152 - val_accuracy: 0.6235\n",
      "Epoch 9016/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5604 - accuracy: 0.6991 - val_loss: 0.7251 - val_accuracy: 0.6187\n",
      "Epoch 9017/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7141 - val_accuracy: 0.6269\n",
      "Epoch 9018/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7222 - val_accuracy: 0.6184\n",
      "Epoch 9019/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7183 - val_accuracy: 0.6233\n",
      "Epoch 9020/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7214 - val_accuracy: 0.6221\n",
      "Epoch 9021/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7225 - val_accuracy: 0.6190\n",
      "Epoch 9022/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7096 - val_accuracy: 0.6301\n",
      "Epoch 9023/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7302 - val_accuracy: 0.6140\n",
      "Epoch 9024/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5599 - accuracy: 0.6991 - val_loss: 0.7135 - val_accuracy: 0.6279\n",
      "Epoch 9025/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7245 - val_accuracy: 0.6150\n",
      "Epoch 9026/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7121 - val_accuracy: 0.6270\n",
      "Epoch 9027/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7235 - val_accuracy: 0.6218\n",
      "Epoch 9028/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7215 - val_accuracy: 0.6205\n",
      "Epoch 9029/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7183 - val_accuracy: 0.6211\n",
      "Epoch 9030/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7194 - val_accuracy: 0.6223\n",
      "Epoch 9031/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7192 - val_accuracy: 0.6250\n",
      "Epoch 9032/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7178 - val_accuracy: 0.6220\n",
      "Epoch 9033/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7231 - val_accuracy: 0.6181\n",
      "Epoch 9034/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5598 - accuracy: 0.6992 - val_loss: 0.7158 - val_accuracy: 0.6265\n",
      "Epoch 9035/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7244 - val_accuracy: 0.6190\n",
      "Epoch 9036/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7155 - val_accuracy: 0.6250\n",
      "Epoch 9037/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7244 - val_accuracy: 0.6197\n",
      "Epoch 9038/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7177 - val_accuracy: 0.6247\n",
      "Epoch 9039/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7203 - val_accuracy: 0.6197\n",
      "Epoch 9040/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7188 - val_accuracy: 0.6241\n",
      "Epoch 9041/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7215 - val_accuracy: 0.6232\n",
      "Epoch 9042/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7211 - val_accuracy: 0.6200\n",
      "Epoch 9043/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7167 - val_accuracy: 0.6235\n",
      "Epoch 9044/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7235 - val_accuracy: 0.6215\n",
      "Epoch 9045/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7155 - val_accuracy: 0.6252\n",
      "Epoch 9046/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7244 - val_accuracy: 0.6162\n",
      "Epoch 9047/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7154 - val_accuracy: 0.6268\n",
      "Epoch 9048/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7250 - val_accuracy: 0.6192\n",
      "Epoch 9049/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7141 - val_accuracy: 0.6255\n",
      "Epoch 9050/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7253 - val_accuracy: 0.6177\n",
      "Epoch 9051/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7170 - val_accuracy: 0.6260\n",
      "Epoch 9052/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7210 - val_accuracy: 0.6195\n",
      "Epoch 9053/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7194 - val_accuracy: 0.6216\n",
      "Epoch 9054/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7214 - val_accuracy: 0.6232\n",
      "Epoch 9055/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7214 - val_accuracy: 0.6200\n",
      "Epoch 9056/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7151 - val_accuracy: 0.6250\n",
      "Epoch 9057/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7234 - val_accuracy: 0.6215\n",
      "Epoch 9058/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7213 - val_accuracy: 0.6227\n",
      "Epoch 9059/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7201 - val_accuracy: 0.6205\n",
      "Epoch 9060/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7167 - val_accuracy: 0.6238\n",
      "Epoch 9061/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7237 - val_accuracy: 0.6212\n",
      "Epoch 9062/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5587 - accuracy: 0.7000 - val_loss: 0.7184 - val_accuracy: 0.6230\n",
      "Epoch 9063/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7227 - val_accuracy: 0.6196\n",
      "Epoch 9064/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7169 - val_accuracy: 0.6258\n",
      "Epoch 9065/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7224 - val_accuracy: 0.6202\n",
      "Epoch 9066/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7186 - val_accuracy: 0.6230\n",
      "Epoch 9067/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7226 - val_accuracy: 0.6207\n",
      "Epoch 9068/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7191 - val_accuracy: 0.6234\n",
      "Epoch 9069/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7207 - val_accuracy: 0.6219\n",
      "Epoch 9070/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5586 - accuracy: 0.7005 - val_loss: 0.7208 - val_accuracy: 0.6228\n",
      "Epoch 9071/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7212 - val_accuracy: 0.6220\n",
      "Epoch 9072/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7192 - val_accuracy: 0.6224\n",
      "Epoch 9073/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7204 - val_accuracy: 0.6226\n",
      "Epoch 9074/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7223 - val_accuracy: 0.6218\n",
      "Epoch 9075/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7186 - val_accuracy: 0.6234\n",
      "Epoch 9076/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7233 - val_accuracy: 0.6200\n",
      "Epoch 9077/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7160 - val_accuracy: 0.6263\n",
      "Epoch 9078/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7289 - val_accuracy: 0.6147\n",
      "Epoch 9079/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7105 - val_accuracy: 0.6297\n",
      "Epoch 9080/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7328 - val_accuracy: 0.6110\n",
      "Epoch 9081/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5597 - accuracy: 0.6992 - val_loss: 0.7081 - val_accuracy: 0.6334\n",
      "Epoch 9082/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7354 - val_accuracy: 0.6095\n",
      "Epoch 9083/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5599 - accuracy: 0.6990 - val_loss: 0.7054 - val_accuracy: 0.6337\n",
      "Epoch 9084/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5603 - accuracy: 0.6990 - val_loss: 0.7343 - val_accuracy: 0.6092\n",
      "Epoch 9085/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6990 - val_loss: 0.7128 - val_accuracy: 0.6302\n",
      "Epoch 9086/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7245 - val_accuracy: 0.6184\n",
      "Epoch 9087/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7192 - val_accuracy: 0.6223\n",
      "Epoch 9088/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7193 - val_accuracy: 0.6242\n",
      "Epoch 9089/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7247 - val_accuracy: 0.6174\n",
      "Epoch 9090/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7126 - val_accuracy: 0.6284\n",
      "Epoch 9091/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7302 - val_accuracy: 0.6150\n",
      "Epoch 9092/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7096 - val_accuracy: 0.6288\n",
      "Epoch 9093/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5603 - accuracy: 0.6995 - val_loss: 0.7282 - val_accuracy: 0.6134\n",
      "Epoch 9094/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7135 - val_accuracy: 0.6297\n",
      "Epoch 9095/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7275 - val_accuracy: 0.6172\n",
      "Epoch 9096/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5601 - accuracy: 0.6995 - val_loss: 0.7109 - val_accuracy: 0.6261\n",
      "Epoch 9097/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5615 - accuracy: 0.6985 - val_loss: 0.7217 - val_accuracy: 0.6170\n",
      "Epoch 9098/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5616 - accuracy: 0.6984 - val_loss: 0.7140 - val_accuracy: 0.6249\n",
      "Epoch 9099/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5608 - accuracy: 0.6994 - val_loss: 0.7210 - val_accuracy: 0.6202\n",
      "Epoch 9100/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5602 - accuracy: 0.6992 - val_loss: 0.7196 - val_accuracy: 0.6227\n",
      "Epoch 9101/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5606 - accuracy: 0.6991 - val_loss: 0.7174 - val_accuracy: 0.6240\n",
      "Epoch 9102/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7255 - val_accuracy: 0.6174\n",
      "Epoch 9103/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7151 - val_accuracy: 0.6252\n",
      "Epoch 9104/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5598 - accuracy: 0.6998 - val_loss: 0.7204 - val_accuracy: 0.6206\n",
      "Epoch 9105/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7179 - val_accuracy: 0.6244\n",
      "Epoch 9106/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7220 - val_accuracy: 0.6210\n",
      "Epoch 9107/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7250 - val_accuracy: 0.6185\n",
      "Epoch 9108/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7126 - val_accuracy: 0.6274\n",
      "Epoch 9109/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7226 - val_accuracy: 0.6199\n",
      "Epoch 9110/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7172 - val_accuracy: 0.6251\n",
      "Epoch 9111/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7286 - val_accuracy: 0.6160\n",
      "Epoch 9112/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7173 - val_accuracy: 0.6245\n",
      "Epoch 9113/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7180 - val_accuracy: 0.6236\n",
      "Epoch 9114/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7196 - val_accuracy: 0.6224\n",
      "Epoch 9115/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7206 - val_accuracy: 0.6225\n",
      "Epoch 9116/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7239 - val_accuracy: 0.6191\n",
      "Epoch 9117/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7172 - val_accuracy: 0.6244\n",
      "Epoch 9118/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7233 - val_accuracy: 0.6209\n",
      "Epoch 9119/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7173 - val_accuracy: 0.6251\n",
      "Epoch 9120/10000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7239 - val_accuracy: 0.6189\n",
      "Epoch 9121/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7194 - val_accuracy: 0.6241\n",
      "Epoch 9122/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7219 - val_accuracy: 0.6216\n",
      "Epoch 9123/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7197 - val_accuracy: 0.6224\n",
      "Epoch 9124/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7190 - val_accuracy: 0.6235\n",
      "Epoch 9125/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7230 - val_accuracy: 0.6205\n",
      "Epoch 9126/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7178 - val_accuracy: 0.6242\n",
      "Epoch 9127/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7244 - val_accuracy: 0.6188\n",
      "Epoch 9128/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7156 - val_accuracy: 0.6264\n",
      "Epoch 9129/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7262 - val_accuracy: 0.6175\n",
      "Epoch 9130/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5587 - accuracy: 0.7000 - val_loss: 0.7142 - val_accuracy: 0.6271\n",
      "Epoch 9131/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7293 - val_accuracy: 0.6146\n",
      "Epoch 9132/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7107 - val_accuracy: 0.6307\n",
      "Epoch 9133/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7315 - val_accuracy: 0.6126\n",
      "Epoch 9134/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7120 - val_accuracy: 0.6297\n",
      "Epoch 9135/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7292 - val_accuracy: 0.6139\n",
      "Epoch 9136/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7116 - val_accuracy: 0.6295\n",
      "Epoch 9137/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7282 - val_accuracy: 0.6167\n",
      "Epoch 9138/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7172 - val_accuracy: 0.6248\n",
      "Epoch 9139/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7232 - val_accuracy: 0.6198\n",
      "Epoch 9140/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7187 - val_accuracy: 0.6245\n",
      "Epoch 9141/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7214 - val_accuracy: 0.6216\n",
      "Epoch 9142/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5586 - accuracy: 0.7005 - val_loss: 0.7218 - val_accuracy: 0.6218\n",
      "Epoch 9143/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7199 - val_accuracy: 0.6233\n",
      "Epoch 9144/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7215 - val_accuracy: 0.6204\n",
      "Epoch 9145/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7173 - val_accuracy: 0.6245\n",
      "Epoch 9146/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7266 - val_accuracy: 0.6191\n",
      "Epoch 9147/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7121 - val_accuracy: 0.6269\n",
      "Epoch 9148/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7284 - val_accuracy: 0.6142\n",
      "Epoch 9149/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5596 - accuracy: 0.6993 - val_loss: 0.7144 - val_accuracy: 0.6299\n",
      "Epoch 9150/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7301 - val_accuracy: 0.6136\n",
      "Epoch 9151/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7061 - val_accuracy: 0.6311\n",
      "Epoch 9152/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5610 - accuracy: 0.6989 - val_loss: 0.7296 - val_accuracy: 0.6123\n",
      "Epoch 9153/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5608 - accuracy: 0.6986 - val_loss: 0.7138 - val_accuracy: 0.6272\n",
      "Epoch 9154/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5600 - accuracy: 0.6995 - val_loss: 0.7244 - val_accuracy: 0.6183\n",
      "Epoch 9155/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7165 - val_accuracy: 0.6243\n",
      "Epoch 9156/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7207 - val_accuracy: 0.6221\n",
      "Epoch 9157/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7244 - val_accuracy: 0.6183\n",
      "Epoch 9158/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7132 - val_accuracy: 0.6258\n",
      "Epoch 9159/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7232 - val_accuracy: 0.6193\n",
      "Epoch 9160/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7183 - val_accuracy: 0.6241\n",
      "Epoch 9161/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7272 - val_accuracy: 0.6175\n",
      "Epoch 9162/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7142 - val_accuracy: 0.6251\n",
      "Epoch 9163/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7194 - val_accuracy: 0.6224\n",
      "Epoch 9164/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7206 - val_accuracy: 0.6225\n",
      "Epoch 9165/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7257 - val_accuracy: 0.6192\n",
      "Epoch 9166/10000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7185 - val_accuracy: 0.6228\n",
      "Epoch 9167/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7173 - val_accuracy: 0.6246\n",
      "Epoch 9168/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7223 - val_accuracy: 0.6217\n",
      "Epoch 9169/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7218 - val_accuracy: 0.6224\n",
      "Epoch 9170/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7228 - val_accuracy: 0.6193\n",
      "Epoch 9171/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7173 - val_accuracy: 0.6247\n",
      "Epoch 9172/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7226 - val_accuracy: 0.6216\n",
      "Epoch 9173/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7188 - val_accuracy: 0.6232\n",
      "Epoch 9174/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7237 - val_accuracy: 0.6193\n",
      "Epoch 9175/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7186 - val_accuracy: 0.6251\n",
      "Epoch 9176/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7222 - val_accuracy: 0.6209\n",
      "Epoch 9177/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7184 - val_accuracy: 0.6232\n",
      "Epoch 9178/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7224 - val_accuracy: 0.6210\n",
      "Epoch 9179/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7194 - val_accuracy: 0.6235\n",
      "Epoch 9180/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7215 - val_accuracy: 0.6213\n",
      "Epoch 9181/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7213 - val_accuracy: 0.6221\n",
      "Epoch 9182/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7191 - val_accuracy: 0.6230\n",
      "Epoch 9183/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7217 - val_accuracy: 0.6218\n",
      "Epoch 9184/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7194 - val_accuracy: 0.6234\n",
      "Epoch 9185/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7254 - val_accuracy: 0.6185\n",
      "Epoch 9186/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7140 - val_accuracy: 0.6273\n",
      "Epoch 9187/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7277 - val_accuracy: 0.6167\n",
      "Epoch 9188/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7134 - val_accuracy: 0.6280\n",
      "Epoch 9189/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7320 - val_accuracy: 0.6123\n",
      "Epoch 9190/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5592 - accuracy: 0.6995 - val_loss: 0.7099 - val_accuracy: 0.6322\n",
      "Epoch 9191/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7322 - val_accuracy: 0.6124\n",
      "Epoch 9192/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7111 - val_accuracy: 0.6297\n",
      "Epoch 9193/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7306 - val_accuracy: 0.6127\n",
      "Epoch 9194/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5595 - accuracy: 0.6995 - val_loss: 0.7132 - val_accuracy: 0.6291\n",
      "Epoch 9195/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7247 - val_accuracy: 0.6188\n",
      "Epoch 9196/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7201 - val_accuracy: 0.6230\n",
      "Epoch 9197/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7197 - val_accuracy: 0.6233\n",
      "Epoch 9198/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7249 - val_accuracy: 0.6189\n",
      "Epoch 9199/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7152 - val_accuracy: 0.6272\n",
      "Epoch 9200/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7276 - val_accuracy: 0.6157\n",
      "Epoch 9201/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7133 - val_accuracy: 0.6280\n",
      "Epoch 9202/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7292 - val_accuracy: 0.6157\n",
      "Epoch 9203/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7128 - val_accuracy: 0.6285\n",
      "Epoch 9204/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7284 - val_accuracy: 0.6152\n",
      "Epoch 9205/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7167 - val_accuracy: 0.6273\n",
      "Epoch 9206/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7238 - val_accuracy: 0.6192\n",
      "Epoch 9207/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7194 - val_accuracy: 0.6232\n",
      "Epoch 9208/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7221 - val_accuracy: 0.6229\n",
      "Epoch 9209/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7185 - val_accuracy: 0.6217\n",
      "Epoch 9210/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7222 - val_accuracy: 0.6205\n",
      "Epoch 9211/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7226 - val_accuracy: 0.6237\n",
      "Epoch 9212/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7188 - val_accuracy: 0.6221\n",
      "Epoch 9213/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7220 - val_accuracy: 0.6207\n",
      "Epoch 9214/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7214 - val_accuracy: 0.6247\n",
      "Epoch 9215/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7214 - val_accuracy: 0.6199\n",
      "Epoch 9216/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7178 - val_accuracy: 0.6233\n",
      "Epoch 9217/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5585 - accuracy: 0.7006 - val_loss: 0.7240 - val_accuracy: 0.6226\n",
      "Epoch 9218/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7186 - val_accuracy: 0.6220\n",
      "Epoch 9219/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7216 - val_accuracy: 0.6199\n",
      "Epoch 9220/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7207 - val_accuracy: 0.6255\n",
      "Epoch 9221/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7198 - val_accuracy: 0.6201\n",
      "Epoch 9222/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7202 - val_accuracy: 0.6209\n",
      "Epoch 9223/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7208 - val_accuracy: 0.6250\n",
      "Epoch 9224/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7227 - val_accuracy: 0.6202\n",
      "Epoch 9225/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5592 - accuracy: 0.7001 - val_loss: 0.7130 - val_accuracy: 0.6244\n",
      "Epoch 9226/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5607 - accuracy: 0.6989 - val_loss: 0.7249 - val_accuracy: 0.6171\n",
      "Epoch 9227/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5607 - accuracy: 0.6987 - val_loss: 0.7147 - val_accuracy: 0.6265\n",
      "Epoch 9228/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5601 - accuracy: 0.6994 - val_loss: 0.7265 - val_accuracy: 0.6167\n",
      "Epoch 9229/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5603 - accuracy: 0.6990 - val_loss: 0.7119 - val_accuracy: 0.6286\n",
      "Epoch 9230/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5599 - accuracy: 0.6995 - val_loss: 0.7269 - val_accuracy: 0.6177\n",
      "Epoch 9231/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5600 - accuracy: 0.6989 - val_loss: 0.7186 - val_accuracy: 0.6247\n",
      "Epoch 9232/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7199 - val_accuracy: 0.6205\n",
      "Epoch 9233/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7184 - val_accuracy: 0.6230\n",
      "Epoch 9234/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7194 - val_accuracy: 0.6239\n",
      "Epoch 9235/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7280 - val_accuracy: 0.6166\n",
      "Epoch 9236/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7144 - val_accuracy: 0.6260\n",
      "Epoch 9237/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7221 - val_accuracy: 0.6206\n",
      "Epoch 9238/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7169 - val_accuracy: 0.6255\n",
      "Epoch 9239/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7259 - val_accuracy: 0.6183\n",
      "Epoch 9240/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7189 - val_accuracy: 0.6225\n",
      "Epoch 9241/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7194 - val_accuracy: 0.6235\n",
      "Epoch 9242/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7219 - val_accuracy: 0.6211\n",
      "Epoch 9243/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7208 - val_accuracy: 0.6224\n",
      "Epoch 9244/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7213 - val_accuracy: 0.6216\n",
      "Epoch 9245/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7189 - val_accuracy: 0.6233\n",
      "Epoch 9246/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7221 - val_accuracy: 0.6214\n",
      "Epoch 9247/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7218 - val_accuracy: 0.6223\n",
      "Epoch 9248/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7192 - val_accuracy: 0.6230\n",
      "Epoch 9249/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7215 - val_accuracy: 0.6214\n",
      "Epoch 9250/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5586 - accuracy: 0.7005 - val_loss: 0.7224 - val_accuracy: 0.6226\n",
      "Epoch 9251/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7217 - val_accuracy: 0.6221\n",
      "Epoch 9252/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7183 - val_accuracy: 0.6235\n",
      "Epoch 9253/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7244 - val_accuracy: 0.6207\n",
      "Epoch 9254/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7168 - val_accuracy: 0.6251\n",
      "Epoch 9255/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7266 - val_accuracy: 0.6168\n",
      "Epoch 9256/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7147 - val_accuracy: 0.6285\n",
      "Epoch 9257/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7295 - val_accuracy: 0.6147\n",
      "Epoch 9258/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7117 - val_accuracy: 0.6290\n",
      "Epoch 9259/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7323 - val_accuracy: 0.6128\n",
      "Epoch 9260/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7101 - val_accuracy: 0.6314\n",
      "Epoch 9261/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7304 - val_accuracy: 0.6125\n",
      "Epoch 9262/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5598 - accuracy: 0.6991 - val_loss: 0.7123 - val_accuracy: 0.6296\n",
      "Epoch 9263/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7304 - val_accuracy: 0.6152\n",
      "Epoch 9264/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7121 - val_accuracy: 0.6285\n",
      "Epoch 9265/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7249 - val_accuracy: 0.6182\n",
      "Epoch 9266/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7221 - val_accuracy: 0.6236\n",
      "Epoch 9267/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7194 - val_accuracy: 0.6223\n",
      "Epoch 9268/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7220 - val_accuracy: 0.6204\n",
      "Epoch 9269/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7179 - val_accuracy: 0.6262\n",
      "Epoch 9270/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7276 - val_accuracy: 0.6167\n",
      "Epoch 9271/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7151 - val_accuracy: 0.6269\n",
      "Epoch 9272/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7266 - val_accuracy: 0.6171\n",
      "Epoch 9273/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7154 - val_accuracy: 0.6267\n",
      "Epoch 9274/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7280 - val_accuracy: 0.6163\n",
      "Epoch 9275/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7126 - val_accuracy: 0.6282\n",
      "Epoch 9276/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7294 - val_accuracy: 0.6153\n",
      "Epoch 9277/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7149 - val_accuracy: 0.6275\n",
      "Epoch 9278/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7253 - val_accuracy: 0.6171\n",
      "Epoch 9279/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7166 - val_accuracy: 0.6262\n",
      "Epoch 9280/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7249 - val_accuracy: 0.6196\n",
      "Epoch 9281/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7198 - val_accuracy: 0.6225\n",
      "Epoch 9282/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7204 - val_accuracy: 0.6231\n",
      "Epoch 9283/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7225 - val_accuracy: 0.6213\n",
      "Epoch 9284/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7192 - val_accuracy: 0.6224\n",
      "Epoch 9285/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7240 - val_accuracy: 0.6207\n",
      "Epoch 9286/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5586 - accuracy: 0.7001 - val_loss: 0.7179 - val_accuracy: 0.6258\n",
      "Epoch 9287/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7249 - val_accuracy: 0.6175\n",
      "Epoch 9288/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7157 - val_accuracy: 0.6271\n",
      "Epoch 9289/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7285 - val_accuracy: 0.6170\n",
      "Epoch 9290/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7141 - val_accuracy: 0.6262\n",
      "Epoch 9291/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7278 - val_accuracy: 0.6160\n",
      "Epoch 9292/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7166 - val_accuracy: 0.6283\n",
      "Epoch 9293/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7256 - val_accuracy: 0.6168\n",
      "Epoch 9294/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7158 - val_accuracy: 0.6255\n",
      "Epoch 9295/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7269 - val_accuracy: 0.6190\n",
      "Epoch 9296/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7141 - val_accuracy: 0.6263\n",
      "Epoch 9297/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7285 - val_accuracy: 0.6149\n",
      "Epoch 9298/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7158 - val_accuracy: 0.6283\n",
      "Epoch 9299/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7273 - val_accuracy: 0.6151\n",
      "Epoch 9300/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7149 - val_accuracy: 0.6272\n",
      "Epoch 9301/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7275 - val_accuracy: 0.6188\n",
      "Epoch 9302/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7133 - val_accuracy: 0.6256\n",
      "Epoch 9303/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7261 - val_accuracy: 0.6160\n",
      "Epoch 9304/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7200 - val_accuracy: 0.6274\n",
      "Epoch 9305/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7216 - val_accuracy: 0.6201\n",
      "Epoch 9306/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5588 - accuracy: 0.7004 - val_loss: 0.7207 - val_accuracy: 0.6196\n",
      "Epoch 9307/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7193 - val_accuracy: 0.6268\n",
      "Epoch 9308/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7270 - val_accuracy: 0.6173\n",
      "Epoch 9309/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7133 - val_accuracy: 0.6263\n",
      "Epoch 9310/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7269 - val_accuracy: 0.6169\n",
      "Epoch 9311/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.6997 - val_loss: 0.7175 - val_accuracy: 0.6264\n",
      "Epoch 9312/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7245 - val_accuracy: 0.6175\n",
      "Epoch 9313/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7168 - val_accuracy: 0.6251\n",
      "Epoch 9314/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7260 - val_accuracy: 0.6206\n",
      "Epoch 9315/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7152 - val_accuracy: 0.6246\n",
      "Epoch 9316/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5600 - accuracy: 0.6995 - val_loss: 0.7221 - val_accuracy: 0.6180\n",
      "Epoch 9317/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7174 - val_accuracy: 0.6257\n",
      "Epoch 9318/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7251 - val_accuracy: 0.6207\n",
      "Epoch 9319/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7147 - val_accuracy: 0.6235\n",
      "Epoch 9320/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5615 - accuracy: 0.6984 - val_loss: 0.7200 - val_accuracy: 0.6175\n",
      "Epoch 9321/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5617 - accuracy: 0.6982 - val_loss: 0.7123 - val_accuracy: 0.6258\n",
      "Epoch 9322/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5605 - accuracy: 0.6994 - val_loss: 0.7281 - val_accuracy: 0.6183\n",
      "Epoch 9323/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5610 - accuracy: 0.6986 - val_loss: 0.7161 - val_accuracy: 0.6260\n",
      "Epoch 9324/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5603 - accuracy: 0.6992 - val_loss: 0.7205 - val_accuracy: 0.6202\n",
      "Epoch 9325/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5605 - accuracy: 0.6990 - val_loss: 0.7206 - val_accuracy: 0.6217\n",
      "Epoch 9326/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5600 - accuracy: 0.6991 - val_loss: 0.7197 - val_accuracy: 0.6241\n",
      "Epoch 9327/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7220 - val_accuracy: 0.6188\n",
      "Epoch 9328/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7143 - val_accuracy: 0.6260\n",
      "Epoch 9329/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5600 - accuracy: 0.6991 - val_loss: 0.7264 - val_accuracy: 0.6183\n",
      "Epoch 9330/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5595 - accuracy: 0.6993 - val_loss: 0.7208 - val_accuracy: 0.6237\n",
      "Epoch 9331/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7193 - val_accuracy: 0.6208\n",
      "Epoch 9332/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7159 - val_accuracy: 0.6244\n",
      "Epoch 9333/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7214 - val_accuracy: 0.6232\n",
      "Epoch 9334/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7267 - val_accuracy: 0.6197\n",
      "Epoch 9335/10000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7204 - val_accuracy: 0.6222\n",
      "Epoch 9336/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7181 - val_accuracy: 0.6229\n",
      "Epoch 9337/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7196 - val_accuracy: 0.6234\n",
      "Epoch 9338/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7233 - val_accuracy: 0.6216\n",
      "Epoch 9339/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7226 - val_accuracy: 0.6207\n",
      "Epoch 9340/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7187 - val_accuracy: 0.6237\n",
      "Epoch 9341/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7233 - val_accuracy: 0.6211\n",
      "Epoch 9342/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7177 - val_accuracy: 0.6253\n",
      "Epoch 9343/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7252 - val_accuracy: 0.6180\n",
      "Epoch 9344/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7180 - val_accuracy: 0.6253\n",
      "Epoch 9345/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7257 - val_accuracy: 0.6191\n",
      "Epoch 9346/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7168 - val_accuracy: 0.6251\n",
      "Epoch 9347/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7245 - val_accuracy: 0.6191\n",
      "Epoch 9348/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7168 - val_accuracy: 0.6266\n",
      "Epoch 9349/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7262 - val_accuracy: 0.6169\n",
      "Epoch 9350/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7168 - val_accuracy: 0.6263\n",
      "Epoch 9351/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7265 - val_accuracy: 0.6181\n",
      "Epoch 9352/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7156 - val_accuracy: 0.6258\n",
      "Epoch 9353/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7261 - val_accuracy: 0.6189\n",
      "Epoch 9354/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7172 - val_accuracy: 0.6260\n",
      "Epoch 9355/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7264 - val_accuracy: 0.6164\n",
      "Epoch 9356/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7152 - val_accuracy: 0.6278\n",
      "Epoch 9357/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7282 - val_accuracy: 0.6175\n",
      "Epoch 9358/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7156 - val_accuracy: 0.6260\n",
      "Epoch 9359/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7269 - val_accuracy: 0.6165\n",
      "Epoch 9360/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7150 - val_accuracy: 0.6285\n",
      "Epoch 9361/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7282 - val_accuracy: 0.6165\n",
      "Epoch 9362/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7177 - val_accuracy: 0.6250\n",
      "Epoch 9363/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7256 - val_accuracy: 0.6189\n",
      "Epoch 9364/10000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7146 - val_accuracy: 0.6269\n",
      "Epoch 9365/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7287 - val_accuracy: 0.6158\n",
      "Epoch 9366/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7156 - val_accuracy: 0.6272\n",
      "Epoch 9367/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7292 - val_accuracy: 0.6152\n",
      "Epoch 9368/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7124 - val_accuracy: 0.6294\n",
      "Epoch 9369/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7314 - val_accuracy: 0.6135\n",
      "Epoch 9370/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7124 - val_accuracy: 0.6301\n",
      "Epoch 9371/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7319 - val_accuracy: 0.6122\n",
      "Epoch 9372/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7112 - val_accuracy: 0.6306\n",
      "Epoch 9373/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7338 - val_accuracy: 0.6120\n",
      "Epoch 9374/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5594 - accuracy: 0.6993 - val_loss: 0.7101 - val_accuracy: 0.6309\n",
      "Epoch 9375/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7316 - val_accuracy: 0.6121\n",
      "Epoch 9376/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7141 - val_accuracy: 0.6295\n",
      "Epoch 9377/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7271 - val_accuracy: 0.6171\n",
      "Epoch 9378/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7188 - val_accuracy: 0.6238\n",
      "Epoch 9379/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7220 - val_accuracy: 0.6225\n",
      "Epoch 9380/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5583 - accuracy: 0.7004 - val_loss: 0.7236 - val_accuracy: 0.6205\n",
      "Epoch 9381/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5584 - accuracy: 0.7006 - val_loss: 0.7177 - val_accuracy: 0.6256\n",
      "Epoch 9382/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7280 - val_accuracy: 0.6173\n",
      "Epoch 9383/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7144 - val_accuracy: 0.6283\n",
      "Epoch 9384/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7310 - val_accuracy: 0.6140\n",
      "Epoch 9385/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7112 - val_accuracy: 0.6301\n",
      "Epoch 9386/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7338 - val_accuracy: 0.6115\n",
      "Epoch 9387/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5594 - accuracy: 0.6993 - val_loss: 0.7097 - val_accuracy: 0.6323\n",
      "Epoch 9388/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7341 - val_accuracy: 0.6111\n",
      "Epoch 9389/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5595 - accuracy: 0.6993 - val_loss: 0.7111 - val_accuracy: 0.6309\n",
      "Epoch 9390/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7310 - val_accuracy: 0.6134\n",
      "Epoch 9391/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7130 - val_accuracy: 0.6287\n",
      "Epoch 9392/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7287 - val_accuracy: 0.6175\n",
      "Epoch 9393/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7189 - val_accuracy: 0.6245\n",
      "Epoch 9394/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7197 - val_accuracy: 0.6222\n",
      "Epoch 9395/10000\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7251 - val_accuracy: 0.6203\n",
      "Epoch 9396/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7169 - val_accuracy: 0.6272\n",
      "Epoch 9397/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7276 - val_accuracy: 0.6142\n",
      "Epoch 9398/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7134 - val_accuracy: 0.6290\n",
      "Epoch 9399/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7308 - val_accuracy: 0.6164\n",
      "Epoch 9400/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7123 - val_accuracy: 0.6264\n",
      "Epoch 9401/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7264 - val_accuracy: 0.6154\n",
      "Epoch 9402/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7203 - val_accuracy: 0.6272\n",
      "Epoch 9403/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7197 - val_accuracy: 0.6214\n",
      "Epoch 9404/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7225 - val_accuracy: 0.6192\n",
      "Epoch 9405/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7182 - val_accuracy: 0.6271\n",
      "Epoch 9406/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7301 - val_accuracy: 0.6152\n",
      "Epoch 9407/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7109 - val_accuracy: 0.6283\n",
      "Epoch 9408/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7279 - val_accuracy: 0.6159\n",
      "Epoch 9409/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7187 - val_accuracy: 0.6265\n",
      "Epoch 9410/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7236 - val_accuracy: 0.6188\n",
      "Epoch 9411/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7175 - val_accuracy: 0.6233\n",
      "Epoch 9412/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7221 - val_accuracy: 0.6234\n",
      "Epoch 9413/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7253 - val_accuracy: 0.6196\n",
      "Epoch 9414/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7157 - val_accuracy: 0.6254\n",
      "Epoch 9415/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7268 - val_accuracy: 0.6176\n",
      "Epoch 9416/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7161 - val_accuracy: 0.6277\n",
      "Epoch 9417/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7297 - val_accuracy: 0.6144\n",
      "Epoch 9418/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7131 - val_accuracy: 0.6282\n",
      "Epoch 9419/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7283 - val_accuracy: 0.6171\n",
      "Epoch 9420/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7189 - val_accuracy: 0.6246\n",
      "Epoch 9421/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7236 - val_accuracy: 0.6202\n",
      "Epoch 9422/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7195 - val_accuracy: 0.6242\n",
      "Epoch 9423/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7214 - val_accuracy: 0.6220\n",
      "Epoch 9424/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7242 - val_accuracy: 0.6203\n",
      "Epoch 9425/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5585 - accuracy: 0.7002 - val_loss: 0.7190 - val_accuracy: 0.6250\n",
      "Epoch 9426/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7225 - val_accuracy: 0.6204\n",
      "Epoch 9427/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5586 - accuracy: 0.7005 - val_loss: 0.7204 - val_accuracy: 0.6234\n",
      "Epoch 9428/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7250 - val_accuracy: 0.6209\n",
      "Epoch 9429/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7174 - val_accuracy: 0.6239\n",
      "Epoch 9430/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7235 - val_accuracy: 0.6203\n",
      "Epoch 9431/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7220 - val_accuracy: 0.6238\n",
      "Epoch 9432/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7223 - val_accuracy: 0.6208\n",
      "Epoch 9433/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5585 - accuracy: 0.7006 - val_loss: 0.7197 - val_accuracy: 0.6235\n",
      "Epoch 9434/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7235 - val_accuracy: 0.6223\n",
      "Epoch 9435/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7215 - val_accuracy: 0.6220\n",
      "Epoch 9436/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7218 - val_accuracy: 0.6218\n",
      "Epoch 9437/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7206 - val_accuracy: 0.6235\n",
      "Epoch 9438/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7229 - val_accuracy: 0.6205\n",
      "Epoch 9439/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7195 - val_accuracy: 0.6233\n",
      "Epoch 9440/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7254 - val_accuracy: 0.6203\n",
      "Epoch 9441/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7158 - val_accuracy: 0.6262\n",
      "Epoch 9442/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7299 - val_accuracy: 0.6149\n",
      "Epoch 9443/10000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5590 - accuracy: 0.6997 - val_loss: 0.7129 - val_accuracy: 0.6302\n",
      "Epoch 9444/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7321 - val_accuracy: 0.6120\n",
      "Epoch 9445/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5598 - accuracy: 0.6991 - val_loss: 0.7083 - val_accuracy: 0.6321\n",
      "Epoch 9446/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5603 - accuracy: 0.6991 - val_loss: 0.7345 - val_accuracy: 0.6111\n",
      "Epoch 9447/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5598 - accuracy: 0.6990 - val_loss: 0.7129 - val_accuracy: 0.6293\n",
      "Epoch 9448/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7257 - val_accuracy: 0.6168\n",
      "Epoch 9449/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7188 - val_accuracy: 0.6244\n",
      "Epoch 9450/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7239 - val_accuracy: 0.6221\n",
      "Epoch 9451/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7201 - val_accuracy: 0.6208\n",
      "Epoch 9452/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7172 - val_accuracy: 0.6238\n",
      "Epoch 9453/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7278 - val_accuracy: 0.6205\n",
      "Epoch 9454/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7162 - val_accuracy: 0.6248\n",
      "Epoch 9455/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7245 - val_accuracy: 0.6157\n",
      "Epoch 9456/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5595 - accuracy: 0.6994 - val_loss: 0.7162 - val_accuracy: 0.6280\n",
      "Epoch 9457/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7243 - val_accuracy: 0.6213\n",
      "Epoch 9458/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7218 - val_accuracy: 0.6192\n",
      "Epoch 9459/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7181 - val_accuracy: 0.6240\n",
      "Epoch 9460/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7270 - val_accuracy: 0.6194\n",
      "Epoch 9461/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5601 - accuracy: 0.6991 - val_loss: 0.7132 - val_accuracy: 0.6277\n",
      "Epoch 9462/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7289 - val_accuracy: 0.6137\n",
      "Epoch 9463/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7160 - val_accuracy: 0.6279\n",
      "Epoch 9464/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7240 - val_accuracy: 0.6200\n",
      "Epoch 9465/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7211 - val_accuracy: 0.6213\n",
      "Epoch 9466/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5596 - accuracy: 0.6997 - val_loss: 0.7174 - val_accuracy: 0.6235\n",
      "Epoch 9467/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7281 - val_accuracy: 0.6181\n",
      "Epoch 9468/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5596 - accuracy: 0.6993 - val_loss: 0.7127 - val_accuracy: 0.6288\n",
      "Epoch 9469/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7296 - val_accuracy: 0.6116\n",
      "Epoch 9470/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7144 - val_accuracy: 0.6304\n",
      "Epoch 9471/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7297 - val_accuracy: 0.6172\n",
      "Epoch 9472/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7156 - val_accuracy: 0.6236\n",
      "Epoch 9473/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7196 - val_accuracy: 0.6215\n",
      "Epoch 9474/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7262 - val_accuracy: 0.6203\n",
      "Epoch 9475/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7144 - val_accuracy: 0.6277\n",
      "Epoch 9476/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7300 - val_accuracy: 0.6135\n",
      "Epoch 9477/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7138 - val_accuracy: 0.6303\n",
      "Epoch 9478/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7302 - val_accuracy: 0.6144\n",
      "Epoch 9479/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7130 - val_accuracy: 0.6273\n",
      "Epoch 9480/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7262 - val_accuracy: 0.6179\n",
      "Epoch 9481/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7214 - val_accuracy: 0.6234\n",
      "Epoch 9482/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7184 - val_accuracy: 0.6240\n",
      "Epoch 9483/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7264 - val_accuracy: 0.6177\n",
      "Epoch 9484/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5586 - accuracy: 0.7001 - val_loss: 0.7166 - val_accuracy: 0.6281\n",
      "Epoch 9485/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7277 - val_accuracy: 0.6154\n",
      "Epoch 9486/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7147 - val_accuracy: 0.6276\n",
      "Epoch 9487/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7292 - val_accuracy: 0.6170\n",
      "Epoch 9488/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7136 - val_accuracy: 0.6263\n",
      "Epoch 9489/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7268 - val_accuracy: 0.6162\n",
      "Epoch 9490/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7211 - val_accuracy: 0.6249\n",
      "Epoch 9491/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7210 - val_accuracy: 0.6224\n",
      "Epoch 9492/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7201 - val_accuracy: 0.6214\n",
      "Epoch 9493/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5590 - accuracy: 0.7002 - val_loss: 0.7212 - val_accuracy: 0.6234\n",
      "Epoch 9494/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7251 - val_accuracy: 0.6200\n",
      "Epoch 9495/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7164 - val_accuracy: 0.6252\n",
      "Epoch 9496/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5596 - accuracy: 0.6998 - val_loss: 0.7208 - val_accuracy: 0.6198\n",
      "Epoch 9497/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5603 - accuracy: 0.6993 - val_loss: 0.7205 - val_accuracy: 0.6216\n",
      "Epoch 9498/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5604 - accuracy: 0.6994 - val_loss: 0.7178 - val_accuracy: 0.6235\n",
      "Epoch 9499/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5597 - accuracy: 0.6997 - val_loss: 0.7253 - val_accuracy: 0.6194\n",
      "Epoch 9500/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7147 - val_accuracy: 0.6287\n",
      "Epoch 9501/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7283 - val_accuracy: 0.6156\n",
      "Epoch 9502/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7161 - val_accuracy: 0.6260\n",
      "Epoch 9503/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7231 - val_accuracy: 0.6207\n",
      "Epoch 9504/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5593 - accuracy: 0.6996 - val_loss: 0.7208 - val_accuracy: 0.6215\n",
      "Epoch 9505/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7201 - val_accuracy: 0.6228\n",
      "Epoch 9506/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7270 - val_accuracy: 0.6178\n",
      "Epoch 9507/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6994 - val_loss: 0.7137 - val_accuracy: 0.6273\n",
      "Epoch 9508/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7265 - val_accuracy: 0.6174\n",
      "Epoch 9509/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7169 - val_accuracy: 0.6277\n",
      "Epoch 9510/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7282 - val_accuracy: 0.6170\n",
      "Epoch 9511/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7155 - val_accuracy: 0.6254\n",
      "Epoch 9512/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7231 - val_accuracy: 0.6199\n",
      "Epoch 9513/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7212 - val_accuracy: 0.6242\n",
      "Epoch 9514/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7218 - val_accuracy: 0.6219\n",
      "Epoch 9515/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7237 - val_accuracy: 0.6194\n",
      "Epoch 9516/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7174 - val_accuracy: 0.6265\n",
      "Epoch 9517/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7253 - val_accuracy: 0.6188\n",
      "Epoch 9518/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7178 - val_accuracy: 0.6245\n",
      "Epoch 9519/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7255 - val_accuracy: 0.6191\n",
      "Epoch 9520/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7202 - val_accuracy: 0.6242\n",
      "Epoch 9521/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7227 - val_accuracy: 0.6217\n",
      "Epoch 9522/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7218 - val_accuracy: 0.6228\n",
      "Epoch 9523/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7219 - val_accuracy: 0.6225\n",
      "Epoch 9524/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7216 - val_accuracy: 0.6214\n",
      "Epoch 9525/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7208 - val_accuracy: 0.6230\n",
      "Epoch 9526/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7241 - val_accuracy: 0.6213\n",
      "Epoch 9527/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7187 - val_accuracy: 0.6239\n",
      "Epoch 9528/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7254 - val_accuracy: 0.6190\n",
      "Epoch 9529/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7175 - val_accuracy: 0.6262\n",
      "Epoch 9530/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7280 - val_accuracy: 0.6172\n",
      "Epoch 9531/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7147 - val_accuracy: 0.6279\n",
      "Epoch 9532/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7309 - val_accuracy: 0.6141\n",
      "Epoch 9533/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5588 - accuracy: 0.6998 - val_loss: 0.7131 - val_accuracy: 0.6296\n",
      "Epoch 9534/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7324 - val_accuracy: 0.6124\n",
      "Epoch 9535/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5591 - accuracy: 0.6995 - val_loss: 0.7103 - val_accuracy: 0.6317\n",
      "Epoch 9536/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7333 - val_accuracy: 0.6122\n",
      "Epoch 9537/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6994 - val_loss: 0.7134 - val_accuracy: 0.6293\n",
      "Epoch 9538/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7301 - val_accuracy: 0.6144\n",
      "Epoch 9539/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7139 - val_accuracy: 0.6286\n",
      "Epoch 9540/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5590 - accuracy: 0.7001 - val_loss: 0.7284 - val_accuracy: 0.6173\n",
      "Epoch 9541/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7203 - val_accuracy: 0.6241\n",
      "Epoch 9542/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5585 - accuracy: 0.7002 - val_loss: 0.7206 - val_accuracy: 0.6220\n",
      "Epoch 9543/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7240 - val_accuracy: 0.6209\n",
      "Epoch 9544/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7186 - val_accuracy: 0.6258\n",
      "Epoch 9545/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7274 - val_accuracy: 0.6160\n",
      "Epoch 9546/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7151 - val_accuracy: 0.6284\n",
      "Epoch 9547/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7320 - val_accuracy: 0.6157\n",
      "Epoch 9548/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7086 - val_accuracy: 0.6290\n",
      "Epoch 9549/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7321 - val_accuracy: 0.6103\n",
      "Epoch 9550/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5598 - accuracy: 0.6990 - val_loss: 0.7154 - val_accuracy: 0.6322\n",
      "Epoch 9551/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7268 - val_accuracy: 0.6173\n",
      "Epoch 9552/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7195 - val_accuracy: 0.6217\n",
      "Epoch 9553/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7198 - val_accuracy: 0.6255\n",
      "Epoch 9554/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7293 - val_accuracy: 0.6162\n",
      "Epoch 9555/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7093 - val_accuracy: 0.6297\n",
      "Epoch 9556/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7334 - val_accuracy: 0.6112\n",
      "Epoch 9557/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5597 - accuracy: 0.6991 - val_loss: 0.7154 - val_accuracy: 0.6307\n",
      "Epoch 9558/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5597 - accuracy: 0.6992 - val_loss: 0.7272 - val_accuracy: 0.6167\n",
      "Epoch 9559/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7148 - val_accuracy: 0.6250\n",
      "Epoch 9560/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7229 - val_accuracy: 0.6219\n",
      "Epoch 9561/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7272 - val_accuracy: 0.6199\n",
      "Epoch 9562/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7148 - val_accuracy: 0.6270\n",
      "Epoch 9563/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5594 - accuracy: 0.7000 - val_loss: 0.7246 - val_accuracy: 0.6170\n",
      "Epoch 9564/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5603 - accuracy: 0.6988 - val_loss: 0.7165 - val_accuracy: 0.6249\n",
      "Epoch 9565/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7257 - val_accuracy: 0.6199\n",
      "Epoch 9566/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7203 - val_accuracy: 0.6236\n",
      "Epoch 9567/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7151 - val_accuracy: 0.6248\n",
      "Epoch 9568/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5608 - accuracy: 0.6987 - val_loss: 0.7270 - val_accuracy: 0.6156\n",
      "Epoch 9569/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5605 - accuracy: 0.6989 - val_loss: 0.7158 - val_accuracy: 0.6280\n",
      "Epoch 9570/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5603 - accuracy: 0.6993 - val_loss: 0.7274 - val_accuracy: 0.6176\n",
      "Epoch 9571/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5611 - accuracy: 0.6987 - val_loss: 0.7104 - val_accuracy: 0.6277\n",
      "Epoch 9572/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5611 - accuracy: 0.6987 - val_loss: 0.7239 - val_accuracy: 0.6168\n",
      "Epoch 9573/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5620 - accuracy: 0.6978 - val_loss: 0.7191 - val_accuracy: 0.6236\n",
      "Epoch 9574/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5598 - accuracy: 0.6998 - val_loss: 0.7205 - val_accuracy: 0.6242\n",
      "Epoch 9575/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5612 - accuracy: 0.6983 - val_loss: 0.7240 - val_accuracy: 0.6189\n",
      "Epoch 9576/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5602 - accuracy: 0.6992 - val_loss: 0.7126 - val_accuracy: 0.6279\n",
      "Epoch 9577/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5611 - accuracy: 0.6985 - val_loss: 0.7252 - val_accuracy: 0.6165\n",
      "Epoch 9578/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5607 - accuracy: 0.6986 - val_loss: 0.7162 - val_accuracy: 0.6253\n",
      "Epoch 9579/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5604 - accuracy: 0.6990 - val_loss: 0.7212 - val_accuracy: 0.6210\n",
      "Epoch 9580/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.7238 - val_accuracy: 0.6197\n",
      "Epoch 9581/10000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5602 - accuracy: 0.6992 - val_loss: 0.7133 - val_accuracy: 0.6278\n",
      "Epoch 9582/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5606 - accuracy: 0.6987 - val_loss: 0.7295 - val_accuracy: 0.6132\n",
      "Epoch 9583/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5608 - accuracy: 0.6984 - val_loss: 0.7133 - val_accuracy: 0.6289\n",
      "Epoch 9584/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5604 - accuracy: 0.6990 - val_loss: 0.7245 - val_accuracy: 0.6186\n",
      "Epoch 9585/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5598 - accuracy: 0.6993 - val_loss: 0.7190 - val_accuracy: 0.6242\n",
      "Epoch 9586/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7187 - val_accuracy: 0.6254\n",
      "Epoch 9587/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7310 - val_accuracy: 0.6144\n",
      "Epoch 9588/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5597 - accuracy: 0.6991 - val_loss: 0.7138 - val_accuracy: 0.6287\n",
      "Epoch 9589/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7237 - val_accuracy: 0.6186\n",
      "Epoch 9590/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7180 - val_accuracy: 0.6238\n",
      "Epoch 9591/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7227 - val_accuracy: 0.6231\n",
      "Epoch 9592/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7297 - val_accuracy: 0.6166\n",
      "Epoch 9593/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.7139 - val_accuracy: 0.6283\n",
      "Epoch 9594/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7233 - val_accuracy: 0.6194\n",
      "Epoch 9595/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7176 - val_accuracy: 0.6255\n",
      "Epoch 9596/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7265 - val_accuracy: 0.6198\n",
      "Epoch 9597/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7235 - val_accuracy: 0.6203\n",
      "Epoch 9598/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7175 - val_accuracy: 0.6241\n",
      "Epoch 9599/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7240 - val_accuracy: 0.6202\n",
      "Epoch 9600/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7185 - val_accuracy: 0.6257\n",
      "Epoch 9601/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7276 - val_accuracy: 0.6182\n",
      "Epoch 9602/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7182 - val_accuracy: 0.6250\n",
      "Epoch 9603/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7229 - val_accuracy: 0.6208\n",
      "Epoch 9604/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7200 - val_accuracy: 0.6238\n",
      "Epoch 9605/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7233 - val_accuracy: 0.6218\n",
      "Epoch 9606/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7220 - val_accuracy: 0.6223\n",
      "Epoch 9607/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7207 - val_accuracy: 0.6229\n",
      "Epoch 9608/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7236 - val_accuracy: 0.6214\n",
      "Epoch 9609/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7204 - val_accuracy: 0.6238\n",
      "Epoch 9610/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7249 - val_accuracy: 0.6196\n",
      "Epoch 9611/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7181 - val_accuracy: 0.6259\n",
      "Epoch 9612/10000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7267 - val_accuracy: 0.6193\n",
      "Epoch 9613/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7185 - val_accuracy: 0.6247\n",
      "Epoch 9614/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7241 - val_accuracy: 0.6198\n",
      "Epoch 9615/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7205 - val_accuracy: 0.6242\n",
      "Epoch 9616/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7231 - val_accuracy: 0.6219\n",
      "Epoch 9617/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7232 - val_accuracy: 0.6218\n",
      "Epoch 9618/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7197 - val_accuracy: 0.6240\n",
      "Epoch 9619/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7247 - val_accuracy: 0.6212\n",
      "Epoch 9620/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7201 - val_accuracy: 0.6237\n",
      "Epoch 9621/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7250 - val_accuracy: 0.6201\n",
      "Epoch 9622/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7181 - val_accuracy: 0.6251\n",
      "Epoch 9623/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7266 - val_accuracy: 0.6193\n",
      "Epoch 9624/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7183 - val_accuracy: 0.6253\n",
      "Epoch 9625/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7275 - val_accuracy: 0.6176\n",
      "Epoch 9626/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7157 - val_accuracy: 0.6275\n",
      "Epoch 9627/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7293 - val_accuracy: 0.6157\n",
      "Epoch 9628/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7144 - val_accuracy: 0.6284\n",
      "Epoch 9629/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7308 - val_accuracy: 0.6144\n",
      "Epoch 9630/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7142 - val_accuracy: 0.6287\n",
      "Epoch 9631/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7290 - val_accuracy: 0.6167\n",
      "Epoch 9632/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7168 - val_accuracy: 0.6261\n",
      "Epoch 9633/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7271 - val_accuracy: 0.6178\n",
      "Epoch 9634/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7185 - val_accuracy: 0.6260\n",
      "Epoch 9635/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7235 - val_accuracy: 0.6211\n",
      "Epoch 9636/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5583 - accuracy: 0.7006 - val_loss: 0.7223 - val_accuracy: 0.6225\n",
      "Epoch 9637/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5584 - accuracy: 0.7006 - val_loss: 0.7219 - val_accuracy: 0.6233\n",
      "Epoch 9638/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7233 - val_accuracy: 0.6213\n",
      "Epoch 9639/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7187 - val_accuracy: 0.6241\n",
      "Epoch 9640/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7266 - val_accuracy: 0.6193\n",
      "Epoch 9641/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5586 - accuracy: 0.7001 - val_loss: 0.7182 - val_accuracy: 0.6252\n",
      "Epoch 9642/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7258 - val_accuracy: 0.6195\n",
      "Epoch 9643/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7176 - val_accuracy: 0.6264\n",
      "Epoch 9644/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7276 - val_accuracy: 0.6180\n",
      "Epoch 9645/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7165 - val_accuracy: 0.6259\n",
      "Epoch 9646/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7271 - val_accuracy: 0.6181\n",
      "Epoch 9647/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7185 - val_accuracy: 0.6260\n",
      "Epoch 9648/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7278 - val_accuracy: 0.6171\n",
      "Epoch 9649/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7157 - val_accuracy: 0.6272\n",
      "Epoch 9650/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7285 - val_accuracy: 0.6170\n",
      "Epoch 9651/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7160 - val_accuracy: 0.6271\n",
      "Epoch 9652/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7295 - val_accuracy: 0.6153\n",
      "Epoch 9653/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7156 - val_accuracy: 0.6286\n",
      "Epoch 9654/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7278 - val_accuracy: 0.6162\n",
      "Epoch 9655/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7174 - val_accuracy: 0.6259\n",
      "Epoch 9656/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7269 - val_accuracy: 0.6195\n",
      "Epoch 9657/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7175 - val_accuracy: 0.6249\n",
      "Epoch 9658/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7251 - val_accuracy: 0.6193\n",
      "Epoch 9659/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7208 - val_accuracy: 0.6247\n",
      "Epoch 9660/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7223 - val_accuracy: 0.6208\n",
      "Epoch 9661/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5587 - accuracy: 0.7005 - val_loss: 0.7221 - val_accuracy: 0.6223\n",
      "Epoch 9662/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7229 - val_accuracy: 0.6237\n",
      "Epoch 9663/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7199 - val_accuracy: 0.6211\n",
      "Epoch 9664/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7206 - val_accuracy: 0.6217\n",
      "Epoch 9665/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7241 - val_accuracy: 0.6231\n",
      "Epoch 9666/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7227 - val_accuracy: 0.6215\n",
      "Epoch 9667/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7152 - val_accuracy: 0.6246\n",
      "Epoch 9668/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7250 - val_accuracy: 0.6179\n",
      "Epoch 9669/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7173 - val_accuracy: 0.6258\n",
      "Epoch 9670/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7270 - val_accuracy: 0.6166\n",
      "Epoch 9671/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7119 - val_accuracy: 0.6287\n",
      "Epoch 9672/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5604 - accuracy: 0.6991 - val_loss: 0.7291 - val_accuracy: 0.6151\n",
      "Epoch 9673/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5606 - accuracy: 0.6988 - val_loss: 0.7156 - val_accuracy: 0.6261\n",
      "Epoch 9674/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5601 - accuracy: 0.6995 - val_loss: 0.7247 - val_accuracy: 0.6176\n",
      "Epoch 9675/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5599 - accuracy: 0.6992 - val_loss: 0.7173 - val_accuracy: 0.6263\n",
      "Epoch 9676/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7223 - val_accuracy: 0.6230\n",
      "Epoch 9677/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7277 - val_accuracy: 0.6173\n",
      "Epoch 9678/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5597 - accuracy: 0.6992 - val_loss: 0.7169 - val_accuracy: 0.6246\n",
      "Epoch 9679/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7215 - val_accuracy: 0.6212\n",
      "Epoch 9680/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5594 - accuracy: 0.6998 - val_loss: 0.7190 - val_accuracy: 0.6243\n",
      "Epoch 9681/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7250 - val_accuracy: 0.6207\n",
      "Epoch 9682/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7249 - val_accuracy: 0.6196\n",
      "Epoch 9683/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7164 - val_accuracy: 0.6258\n",
      "Epoch 9684/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7241 - val_accuracy: 0.6209\n",
      "Epoch 9685/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7189 - val_accuracy: 0.6251\n",
      "Epoch 9686/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7286 - val_accuracy: 0.6160\n",
      "Epoch 9687/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7165 - val_accuracy: 0.6258\n",
      "Epoch 9688/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7257 - val_accuracy: 0.6202\n",
      "Epoch 9689/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7175 - val_accuracy: 0.6255\n",
      "Epoch 9690/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7268 - val_accuracy: 0.6175\n",
      "Epoch 9691/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7188 - val_accuracy: 0.6252\n",
      "Epoch 9692/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7260 - val_accuracy: 0.6206\n",
      "Epoch 9693/10000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7186 - val_accuracy: 0.6245\n",
      "Epoch 9694/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7240 - val_accuracy: 0.6205\n",
      "Epoch 9695/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7202 - val_accuracy: 0.6240\n",
      "Epoch 9696/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7246 - val_accuracy: 0.6204\n",
      "Epoch 9697/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7209 - val_accuracy: 0.6232\n",
      "Epoch 9698/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7237 - val_accuracy: 0.6212\n",
      "Epoch 9699/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7196 - val_accuracy: 0.6240\n",
      "Epoch 9700/10000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7253 - val_accuracy: 0.6200\n",
      "Epoch 9701/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7185 - val_accuracy: 0.6252\n",
      "Epoch 9702/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7268 - val_accuracy: 0.6181\n",
      "Epoch 9703/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7176 - val_accuracy: 0.6258\n",
      "Epoch 9704/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7268 - val_accuracy: 0.6197\n",
      "Epoch 9705/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7175 - val_accuracy: 0.6249\n",
      "Epoch 9706/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5589 - accuracy: 0.7003 - val_loss: 0.7281 - val_accuracy: 0.6157\n",
      "Epoch 9707/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7143 - val_accuracy: 0.6289\n",
      "Epoch 9708/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7302 - val_accuracy: 0.6159\n",
      "Epoch 9709/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7144 - val_accuracy: 0.6279\n",
      "Epoch 9710/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7321 - val_accuracy: 0.6131\n",
      "Epoch 9711/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5599 - accuracy: 0.6991 - val_loss: 0.7113 - val_accuracy: 0.6304\n",
      "Epoch 9712/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5594 - accuracy: 0.6999 - val_loss: 0.7301 - val_accuracy: 0.6151\n",
      "Epoch 9713/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5598 - accuracy: 0.6995 - val_loss: 0.7130 - val_accuracy: 0.6279\n",
      "Epoch 9714/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7302 - val_accuracy: 0.6132\n",
      "Epoch 9715/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5603 - accuracy: 0.6988 - val_loss: 0.7153 - val_accuracy: 0.6267\n",
      "Epoch 9716/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7252 - val_accuracy: 0.6193\n",
      "Epoch 9717/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7172 - val_accuracy: 0.6254\n",
      "Epoch 9718/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7242 - val_accuracy: 0.6202\n",
      "Epoch 9719/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7240 - val_accuracy: 0.6201\n",
      "Epoch 9720/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7163 - val_accuracy: 0.6247\n",
      "Epoch 9721/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7244 - val_accuracy: 0.6199\n",
      "Epoch 9722/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5598 - accuracy: 0.6994 - val_loss: 0.7161 - val_accuracy: 0.6258\n",
      "Epoch 9723/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7307 - val_accuracy: 0.6145\n",
      "Epoch 9724/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5604 - accuracy: 0.6988 - val_loss: 0.7142 - val_accuracy: 0.6267\n",
      "Epoch 9725/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7237 - val_accuracy: 0.6209\n",
      "Epoch 9726/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7214 - val_accuracy: 0.6237\n",
      "Epoch 9727/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7215 - val_accuracy: 0.6210\n",
      "Epoch 9728/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7233 - val_accuracy: 0.6193\n",
      "Epoch 9729/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5597 - accuracy: 0.6993 - val_loss: 0.7152 - val_accuracy: 0.6264\n",
      "Epoch 9730/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7284 - val_accuracy: 0.6174\n",
      "Epoch 9731/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7176 - val_accuracy: 0.6272\n",
      "Epoch 9732/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5597 - accuracy: 0.6996 - val_loss: 0.7247 - val_accuracy: 0.6179\n",
      "Epoch 9733/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5599 - accuracy: 0.6993 - val_loss: 0.7167 - val_accuracy: 0.6239\n",
      "Epoch 9734/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5601 - accuracy: 0.6995 - val_loss: 0.7195 - val_accuracy: 0.6228\n",
      "Epoch 9735/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7246 - val_accuracy: 0.6208\n",
      "Epoch 9736/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7182 - val_accuracy: 0.6264\n",
      "Epoch 9737/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7290 - val_accuracy: 0.6155\n",
      "Epoch 9738/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7165 - val_accuracy: 0.6263\n",
      "Epoch 9739/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7234 - val_accuracy: 0.6200\n",
      "Epoch 9740/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7174 - val_accuracy: 0.6252\n",
      "Epoch 9741/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7231 - val_accuracy: 0.6214\n",
      "Epoch 9742/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7279 - val_accuracy: 0.6180\n",
      "Epoch 9743/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7174 - val_accuracy: 0.6252\n",
      "Epoch 9744/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7234 - val_accuracy: 0.6204\n",
      "Epoch 9745/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7161 - val_accuracy: 0.6271\n",
      "Epoch 9746/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7307 - val_accuracy: 0.6158\n",
      "Epoch 9747/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7190 - val_accuracy: 0.6250\n",
      "Epoch 9748/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7245 - val_accuracy: 0.6191\n",
      "Epoch 9749/10000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7160 - val_accuracy: 0.6265\n",
      "Epoch 9750/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7260 - val_accuracy: 0.6199\n",
      "Epoch 9751/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7217 - val_accuracy: 0.6234\n",
      "Epoch 9752/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7232 - val_accuracy: 0.6215\n",
      "Epoch 9753/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5584 - accuracy: 0.7006 - val_loss: 0.7216 - val_accuracy: 0.6232\n",
      "Epoch 9754/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7210 - val_accuracy: 0.6230\n",
      "Epoch 9755/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7243 - val_accuracy: 0.6208\n",
      "Epoch 9756/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7208 - val_accuracy: 0.6242\n",
      "Epoch 9757/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7250 - val_accuracy: 0.6200\n",
      "Epoch 9758/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5584 - accuracy: 0.7006 - val_loss: 0.7184 - val_accuracy: 0.6254\n",
      "Epoch 9759/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7279 - val_accuracy: 0.6176\n",
      "Epoch 9760/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5584 - accuracy: 0.7003 - val_loss: 0.7174 - val_accuracy: 0.6265\n",
      "Epoch 9761/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5585 - accuracy: 0.7002 - val_loss: 0.7280 - val_accuracy: 0.6172\n",
      "Epoch 9762/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5585 - accuracy: 0.7002 - val_loss: 0.7157 - val_accuracy: 0.6278\n",
      "Epoch 9763/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7316 - val_accuracy: 0.6144\n",
      "Epoch 9764/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7122 - val_accuracy: 0.6298\n",
      "Epoch 9765/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7347 - val_accuracy: 0.6117\n",
      "Epoch 9766/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5592 - accuracy: 0.6993 - val_loss: 0.7107 - val_accuracy: 0.6323\n",
      "Epoch 9767/10000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7359 - val_accuracy: 0.6097\n",
      "Epoch 9768/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5597 - accuracy: 0.6991 - val_loss: 0.7115 - val_accuracy: 0.6326\n",
      "Epoch 9769/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7319 - val_accuracy: 0.6142\n",
      "Epoch 9770/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7161 - val_accuracy: 0.6262\n",
      "Epoch 9771/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7253 - val_accuracy: 0.6201\n",
      "Epoch 9772/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7219 - val_accuracy: 0.6233\n",
      "Epoch 9773/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7213 - val_accuracy: 0.6230\n",
      "Epoch 9774/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7268 - val_accuracy: 0.6193\n",
      "Epoch 9775/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5585 - accuracy: 0.7002 - val_loss: 0.7186 - val_accuracy: 0.6263\n",
      "Epoch 9776/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7271 - val_accuracy: 0.6179\n",
      "Epoch 9777/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7177 - val_accuracy: 0.6269\n",
      "Epoch 9778/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7294 - val_accuracy: 0.6169\n",
      "Epoch 9779/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7170 - val_accuracy: 0.6264\n",
      "Epoch 9780/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7274 - val_accuracy: 0.6181\n",
      "Epoch 9781/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7176 - val_accuracy: 0.6268\n",
      "Epoch 9782/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7292 - val_accuracy: 0.6152\n",
      "Epoch 9783/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7157 - val_accuracy: 0.6279\n",
      "Epoch 9784/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7307 - val_accuracy: 0.6171\n",
      "Epoch 9785/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7126 - val_accuracy: 0.6287\n",
      "Epoch 9786/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7324 - val_accuracy: 0.6127\n",
      "Epoch 9787/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5593 - accuracy: 0.6995 - val_loss: 0.7161 - val_accuracy: 0.6300\n",
      "Epoch 9788/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7281 - val_accuracy: 0.6163\n",
      "Epoch 9789/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7172 - val_accuracy: 0.6254\n",
      "Epoch 9790/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7260 - val_accuracy: 0.6210\n",
      "Epoch 9791/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7219 - val_accuracy: 0.6224\n",
      "Epoch 9792/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7206 - val_accuracy: 0.6234\n",
      "Epoch 9793/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7264 - val_accuracy: 0.6206\n",
      "Epoch 9794/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5584 - accuracy: 0.7003 - val_loss: 0.7202 - val_accuracy: 0.6249\n",
      "Epoch 9795/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7261 - val_accuracy: 0.6177\n",
      "Epoch 9796/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7171 - val_accuracy: 0.6274\n",
      "Epoch 9797/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7292 - val_accuracy: 0.6176\n",
      "Epoch 9798/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7174 - val_accuracy: 0.6256\n",
      "Epoch 9799/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7270 - val_accuracy: 0.6178\n",
      "Epoch 9800/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7186 - val_accuracy: 0.6271\n",
      "Epoch 9801/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5586 - accuracy: 0.7001 - val_loss: 0.7264 - val_accuracy: 0.6181\n",
      "Epoch 9802/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7208 - val_accuracy: 0.6233\n",
      "Epoch 9803/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7234 - val_accuracy: 0.6224\n",
      "Epoch 9804/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5583 - accuracy: 0.7005 - val_loss: 0.7232 - val_accuracy: 0.6220\n",
      "Epoch 9805/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7216 - val_accuracy: 0.6231\n",
      "Epoch 9806/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7257 - val_accuracy: 0.6201\n",
      "Epoch 9807/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.6252\n",
      "Epoch 9808/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7288 - val_accuracy: 0.6174\n",
      "Epoch 9809/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7172 - val_accuracy: 0.6272\n",
      "Epoch 9810/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7309 - val_accuracy: 0.6144\n",
      "Epoch 9811/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7118 - val_accuracy: 0.6314\n",
      "Epoch 9812/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7362 - val_accuracy: 0.6118\n",
      "Epoch 9813/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5593 - accuracy: 0.6994 - val_loss: 0.7104 - val_accuracy: 0.6311\n",
      "Epoch 9814/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7360 - val_accuracy: 0.6091\n",
      "Epoch 9815/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5599 - accuracy: 0.6991 - val_loss: 0.7110 - val_accuracy: 0.6336\n",
      "Epoch 9816/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5596 - accuracy: 0.6993 - val_loss: 0.7301 - val_accuracy: 0.6143\n",
      "Epoch 9817/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7175 - val_accuracy: 0.6253\n",
      "Epoch 9818/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7256 - val_accuracy: 0.6206\n",
      "Epoch 9819/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7215 - val_accuracy: 0.6216\n",
      "Epoch 9820/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7193 - val_accuracy: 0.6247\n",
      "Epoch 9821/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7286 - val_accuracy: 0.6182\n",
      "Epoch 9822/10000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7172 - val_accuracy: 0.6265\n",
      "Epoch 9823/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7276 - val_accuracy: 0.6174\n",
      "Epoch 9824/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5587 - accuracy: 0.7000 - val_loss: 0.7191 - val_accuracy: 0.6264\n",
      "Epoch 9825/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7256 - val_accuracy: 0.6199\n",
      "Epoch 9826/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7197 - val_accuracy: 0.6236\n",
      "Epoch 9827/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7228 - val_accuracy: 0.6226\n",
      "Epoch 9828/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5584 - accuracy: 0.7002 - val_loss: 0.7272 - val_accuracy: 0.6190\n",
      "Epoch 9829/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7152 - val_accuracy: 0.6270\n",
      "Epoch 9830/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5593 - accuracy: 0.6998 - val_loss: 0.7297 - val_accuracy: 0.6155\n",
      "Epoch 9831/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5592 - accuracy: 0.6994 - val_loss: 0.7168 - val_accuracy: 0.6276\n",
      "Epoch 9832/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7288 - val_accuracy: 0.6162\n",
      "Epoch 9833/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7144 - val_accuracy: 0.6279\n",
      "Epoch 9834/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7302 - val_accuracy: 0.6160\n",
      "Epoch 9835/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5592 - accuracy: 0.6998 - val_loss: 0.7188 - val_accuracy: 0.6258\n",
      "Epoch 9836/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7237 - val_accuracy: 0.6206\n",
      "Epoch 9837/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7218 - val_accuracy: 0.6237\n",
      "Epoch 9838/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7232 - val_accuracy: 0.6232\n",
      "Epoch 9839/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7246 - val_accuracy: 0.6189\n",
      "Epoch 9840/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5585 - accuracy: 0.7005 - val_loss: 0.7182 - val_accuracy: 0.6263\n",
      "Epoch 9841/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7292 - val_accuracy: 0.6184\n",
      "Epoch 9842/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7182 - val_accuracy: 0.6257\n",
      "Epoch 9843/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7273 - val_accuracy: 0.6174\n",
      "Epoch 9844/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7175 - val_accuracy: 0.6279\n",
      "Epoch 9845/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5586 - accuracy: 0.7001 - val_loss: 0.7284 - val_accuracy: 0.6177\n",
      "Epoch 9846/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7178 - val_accuracy: 0.6251\n",
      "Epoch 9847/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7259 - val_accuracy: 0.6190\n",
      "Epoch 9848/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7218 - val_accuracy: 0.6246\n",
      "Epoch 9849/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7226 - val_accuracy: 0.6219\n",
      "Epoch 9850/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7239 - val_accuracy: 0.6211\n",
      "Epoch 9851/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5583 - accuracy: 0.7006 - val_loss: 0.7216 - val_accuracy: 0.6244\n",
      "Epoch 9852/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5584 - accuracy: 0.7003 - val_loss: 0.7267 - val_accuracy: 0.6191\n",
      "Epoch 9853/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7168 - val_accuracy: 0.6263\n",
      "Epoch 9854/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7290 - val_accuracy: 0.6177\n",
      "Epoch 9855/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7173 - val_accuracy: 0.6266\n",
      "Epoch 9856/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7297 - val_accuracy: 0.6166\n",
      "Epoch 9857/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7156 - val_accuracy: 0.6282\n",
      "Epoch 9858/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7324 - val_accuracy: 0.6142\n",
      "Epoch 9859/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7128 - val_accuracy: 0.6303\n",
      "Epoch 9860/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5591 - accuracy: 0.7001 - val_loss: 0.7337 - val_accuracy: 0.6124\n",
      "Epoch 9861/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5592 - accuracy: 0.6995 - val_loss: 0.7133 - val_accuracy: 0.6303\n",
      "Epoch 9862/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7330 - val_accuracy: 0.6129\n",
      "Epoch 9863/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7129 - val_accuracy: 0.6300\n",
      "Epoch 9864/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7324 - val_accuracy: 0.6134\n",
      "Epoch 9865/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5588 - accuracy: 0.6999 - val_loss: 0.7182 - val_accuracy: 0.6272\n",
      "Epoch 9866/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7261 - val_accuracy: 0.6199\n",
      "Epoch 9867/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7193 - val_accuracy: 0.6237\n",
      "Epoch 9868/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7246 - val_accuracy: 0.6215\n",
      "Epoch 9869/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5584 - accuracy: 0.7004 - val_loss: 0.7265 - val_accuracy: 0.6212\n",
      "Epoch 9870/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7156 - val_accuracy: 0.6267\n",
      "Epoch 9871/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7313 - val_accuracy: 0.6145\n",
      "Epoch 9872/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7164 - val_accuracy: 0.6298\n",
      "Epoch 9873/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5590 - accuracy: 0.6998 - val_loss: 0.7318 - val_accuracy: 0.6136\n",
      "Epoch 9874/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7135 - val_accuracy: 0.6288\n",
      "Epoch 9875/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7307 - val_accuracy: 0.6169\n",
      "Epoch 9876/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5585 - accuracy: 0.7002 - val_loss: 0.7196 - val_accuracy: 0.6249\n",
      "Epoch 9877/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7241 - val_accuracy: 0.6207\n",
      "Epoch 9878/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5583 - accuracy: 0.7006 - val_loss: 0.7222 - val_accuracy: 0.6230\n",
      "Epoch 9879/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7207 - val_accuracy: 0.6229\n",
      "Epoch 9880/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5593 - accuracy: 0.7000 - val_loss: 0.7260 - val_accuracy: 0.6183\n",
      "Epoch 9881/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7185 - val_accuracy: 0.6257\n",
      "Epoch 9882/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7283 - val_accuracy: 0.6183\n",
      "Epoch 9883/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5597 - accuracy: 0.6998 - val_loss: 0.7125 - val_accuracy: 0.6287\n",
      "Epoch 9884/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5612 - accuracy: 0.6988 - val_loss: 0.7285 - val_accuracy: 0.6127\n",
      "Epoch 9885/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5616 - accuracy: 0.6983 - val_loss: 0.7123 - val_accuracy: 0.6270\n",
      "Epoch 9886/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5608 - accuracy: 0.6991 - val_loss: 0.7259 - val_accuracy: 0.6180\n",
      "Epoch 9887/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5600 - accuracy: 0.6993 - val_loss: 0.7212 - val_accuracy: 0.6247\n",
      "Epoch 9888/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7213 - val_accuracy: 0.6239\n",
      "Epoch 9889/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.7275 - val_accuracy: 0.6172\n",
      "Epoch 9890/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7141 - val_accuracy: 0.6274\n",
      "Epoch 9891/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7276 - val_accuracy: 0.6179\n",
      "Epoch 9892/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5597 - accuracy: 0.6994 - val_loss: 0.7171 - val_accuracy: 0.6263\n",
      "Epoch 9893/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7284 - val_accuracy: 0.6169\n",
      "Epoch 9894/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5592 - accuracy: 0.6996 - val_loss: 0.7216 - val_accuracy: 0.6233\n",
      "Epoch 9895/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7189 - val_accuracy: 0.6250\n",
      "Epoch 9896/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7245 - val_accuracy: 0.6209\n",
      "Epoch 9897/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7192 - val_accuracy: 0.6251\n",
      "Epoch 9898/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7311 - val_accuracy: 0.6156\n",
      "Epoch 9899/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5590 - accuracy: 0.6996 - val_loss: 0.7170 - val_accuracy: 0.6278\n",
      "Epoch 9900/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7252 - val_accuracy: 0.6198\n",
      "Epoch 9901/10000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7182 - val_accuracy: 0.6247\n",
      "Epoch 9902/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7269 - val_accuracy: 0.6188\n",
      "Epoch 9903/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7218 - val_accuracy: 0.6229\n",
      "Epoch 9904/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7228 - val_accuracy: 0.6223\n",
      "Epoch 9905/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7204 - val_accuracy: 0.6235\n",
      "Epoch 9906/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7259 - val_accuracy: 0.6195\n",
      "Epoch 9907/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7220 - val_accuracy: 0.6237\n",
      "Epoch 9908/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7241 - val_accuracy: 0.6211\n",
      "Epoch 9909/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7187 - val_accuracy: 0.6239\n",
      "Epoch 9910/10000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5591 - accuracy: 0.7002 - val_loss: 0.7258 - val_accuracy: 0.6192\n",
      "Epoch 9911/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5594 - accuracy: 0.6995 - val_loss: 0.7195 - val_accuracy: 0.6246\n",
      "Epoch 9912/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5586 - accuracy: 0.7005 - val_loss: 0.7255 - val_accuracy: 0.6204\n",
      "Epoch 9913/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5593 - accuracy: 0.6999 - val_loss: 0.7175 - val_accuracy: 0.6252\n",
      "Epoch 9914/10000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7281 - val_accuracy: 0.6167\n",
      "Epoch 9915/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7173 - val_accuracy: 0.6260\n",
      "Epoch 9916/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5590 - accuracy: 0.6999 - val_loss: 0.7254 - val_accuracy: 0.6189\n",
      "Epoch 9917/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7179 - val_accuracy: 0.6259\n",
      "Epoch 9918/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5591 - accuracy: 0.6999 - val_loss: 0.7294 - val_accuracy: 0.6176\n",
      "Epoch 9919/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7201 - val_accuracy: 0.6231\n",
      "Epoch 9920/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7201 - val_accuracy: 0.6227\n",
      "Epoch 9921/10000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7254 - val_accuracy: 0.6216\n",
      "Epoch 9922/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5587 - accuracy: 0.7004 - val_loss: 0.7195 - val_accuracy: 0.6250\n",
      "Epoch 9923/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7312 - val_accuracy: 0.6133\n",
      "Epoch 9924/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.7112 - val_accuracy: 0.6327\n",
      "Epoch 9925/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5594 - accuracy: 0.6996 - val_loss: 0.7347 - val_accuracy: 0.6128\n",
      "Epoch 9926/10000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5594 - accuracy: 0.6994 - val_loss: 0.7145 - val_accuracy: 0.6285\n",
      "Epoch 9927/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7325 - val_accuracy: 0.6127\n",
      "Epoch 9928/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5593 - accuracy: 0.6993 - val_loss: 0.7166 - val_accuracy: 0.6282\n",
      "Epoch 9929/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5588 - accuracy: 0.7002 - val_loss: 0.7248 - val_accuracy: 0.6213\n",
      "Epoch 9930/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7222 - val_accuracy: 0.6217\n",
      "Epoch 9931/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7225 - val_accuracy: 0.6229\n",
      "Epoch 9932/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7262 - val_accuracy: 0.6198\n",
      "Epoch 9933/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7170 - val_accuracy: 0.6259\n",
      "Epoch 9934/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7278 - val_accuracy: 0.6180\n",
      "Epoch 9935/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7193 - val_accuracy: 0.6261\n",
      "Epoch 9936/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7284 - val_accuracy: 0.6169\n",
      "Epoch 9937/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7186 - val_accuracy: 0.6263\n",
      "Epoch 9938/10000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7254 - val_accuracy: 0.6206\n",
      "Epoch 9939/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7212 - val_accuracy: 0.6231\n",
      "Epoch 9940/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5587 - accuracy: 0.7003 - val_loss: 0.7247 - val_accuracy: 0.6208\n",
      "Epoch 9941/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5584 - accuracy: 0.7005 - val_loss: 0.7231 - val_accuracy: 0.6230\n",
      "Epoch 9942/10000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7207 - val_accuracy: 0.6232\n",
      "Epoch 9943/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5588 - accuracy: 0.7003 - val_loss: 0.7258 - val_accuracy: 0.6193\n",
      "Epoch 9944/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7182 - val_accuracy: 0.6256\n",
      "Epoch 9945/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7289 - val_accuracy: 0.6182\n",
      "Epoch 9946/10000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.5591 - accuracy: 0.7000 - val_loss: 0.7149 - val_accuracy: 0.6278\n",
      "Epoch 9947/10000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5603 - accuracy: 0.6992 - val_loss: 0.7298 - val_accuracy: 0.6141\n",
      "Epoch 9948/10000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5600 - accuracy: 0.6991 - val_loss: 0.7164 - val_accuracy: 0.6274\n",
      "Epoch 9949/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5595 - accuracy: 0.6996 - val_loss: 0.7276 - val_accuracy: 0.6180\n",
      "Epoch 9950/10000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5604 - accuracy: 0.6991 - val_loss: 0.7166 - val_accuracy: 0.6258\n",
      "Epoch 9951/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5600 - accuracy: 0.6994 - val_loss: 0.7267 - val_accuracy: 0.6186\n",
      "Epoch 9952/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5604 - accuracy: 0.6989 - val_loss: 0.7192 - val_accuracy: 0.6239\n",
      "Epoch 9953/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.7190 - val_accuracy: 0.6218\n",
      "Epoch 9954/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5595 - accuracy: 0.6998 - val_loss: 0.7244 - val_accuracy: 0.6209\n",
      "Epoch 9955/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7195 - val_accuracy: 0.6257\n",
      "Epoch 9956/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5604 - accuracy: 0.6989 - val_loss: 0.7299 - val_accuracy: 0.6141\n",
      "Epoch 9957/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5608 - accuracy: 0.6987 - val_loss: 0.7119 - val_accuracy: 0.6281\n",
      "Epoch 9958/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5601 - accuracy: 0.6993 - val_loss: 0.7246 - val_accuracy: 0.6188\n",
      "Epoch 9959/10000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5600 - accuracy: 0.6992 - val_loss: 0.7216 - val_accuracy: 0.6255\n",
      "Epoch 9960/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5596 - accuracy: 0.6996 - val_loss: 0.7214 - val_accuracy: 0.6230\n",
      "Epoch 9961/10000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7297 - val_accuracy: 0.6144\n",
      "Epoch 9962/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5602 - accuracy: 0.6989 - val_loss: 0.7105 - val_accuracy: 0.6302\n",
      "Epoch 9963/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5597 - accuracy: 0.6995 - val_loss: 0.7316 - val_accuracy: 0.6148\n",
      "Epoch 9964/10000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5601 - accuracy: 0.6990 - val_loss: 0.7158 - val_accuracy: 0.6289\n",
      "Epoch 9965/10000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5596 - accuracy: 0.6995 - val_loss: 0.7283 - val_accuracy: 0.6169\n",
      "Epoch 9966/10000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7237 - val_accuracy: 0.6208\n",
      "Epoch 9967/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.7164 - val_accuracy: 0.6268\n",
      "Epoch 9968/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5589 - accuracy: 0.7002 - val_loss: 0.7294 - val_accuracy: 0.6177\n",
      "Epoch 9969/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5596 - accuracy: 0.6994 - val_loss: 0.7154 - val_accuracy: 0.6286\n",
      "Epoch 9970/10000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5592 - accuracy: 0.6999 - val_loss: 0.7332 - val_accuracy: 0.6129\n",
      "Epoch 9971/10000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5594 - accuracy: 0.6994 - val_loss: 0.7159 - val_accuracy: 0.6274\n",
      "Epoch 9972/10000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.7262 - val_accuracy: 0.6189\n",
      "Epoch 9973/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7218 - val_accuracy: 0.6240\n",
      "Epoch 9974/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5588 - accuracy: 0.7000 - val_loss: 0.7199 - val_accuracy: 0.6254\n",
      "Epoch 9975/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5586 - accuracy: 0.7002 - val_loss: 0.7304 - val_accuracy: 0.6154\n",
      "Epoch 9976/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5591 - accuracy: 0.6998 - val_loss: 0.7150 - val_accuracy: 0.6280\n",
      "Epoch 9977/10000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5590 - accuracy: 0.7000 - val_loss: 0.7302 - val_accuracy: 0.6158\n",
      "Epoch 9978/10000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7168 - val_accuracy: 0.6276\n",
      "Epoch 9979/10000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5592 - accuracy: 0.7000 - val_loss: 0.7268 - val_accuracy: 0.6180\n",
      "Epoch 9980/10000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7214 - val_accuracy: 0.6237\n",
      "Epoch 9981/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5586 - accuracy: 0.7005 - val_loss: 0.7223 - val_accuracy: 0.6239\n",
      "Epoch 9982/10000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.7279 - val_accuracy: 0.6184\n",
      "Epoch 9983/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7147 - val_accuracy: 0.6286\n",
      "Epoch 9984/10000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7319 - val_accuracy: 0.6140\n",
      "Epoch 9985/10000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5592 - accuracy: 0.6995 - val_loss: 0.7161 - val_accuracy: 0.6288\n",
      "Epoch 9986/10000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5589 - accuracy: 0.7001 - val_loss: 0.7307 - val_accuracy: 0.6143\n",
      "Epoch 9987/10000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5589 - accuracy: 0.6999 - val_loss: 0.7155 - val_accuracy: 0.6283\n",
      "Epoch 9988/10000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7281 - val_accuracy: 0.6187\n",
      "Epoch 9989/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5585 - accuracy: 0.7002 - val_loss: 0.7226 - val_accuracy: 0.6218\n",
      "Epoch 9990/10000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5585 - accuracy: 0.7004 - val_loss: 0.7209 - val_accuracy: 0.6234\n",
      "Epoch 9991/10000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7269 - val_accuracy: 0.6202\n",
      "Epoch 9992/10000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5585 - accuracy: 0.7003 - val_loss: 0.7183 - val_accuracy: 0.6259\n",
      "Epoch 9993/10000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5589 - accuracy: 0.7000 - val_loss: 0.7281 - val_accuracy: 0.6158\n",
      "Epoch 9994/10000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7179 - val_accuracy: 0.6277\n",
      "Epoch 9995/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5587 - accuracy: 0.7002 - val_loss: 0.7304 - val_accuracy: 0.6170\n",
      "Epoch 9996/10000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5589 - accuracy: 0.6998 - val_loss: 0.7157 - val_accuracy: 0.6260\n",
      "Epoch 9997/10000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5588 - accuracy: 0.7001 - val_loss: 0.7275 - val_accuracy: 0.6176\n",
      "Epoch 9998/10000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7212 - val_accuracy: 0.6252\n",
      "Epoch 9999/10000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5587 - accuracy: 0.7001 - val_loss: 0.7245 - val_accuracy: 0.6208\n",
      "Epoch 10000/10000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5586 - accuracy: 0.7003 - val_loss: 0.7230 - val_accuracy: 0.6224\n",
      "Model Training Completed.....\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "# Training Configurations\n",
    "\n",
    "input_data_size = sm_train_X.shape[0]\n",
    "\n",
    "epochs = 10000\n",
    "batch_size = input_data_size\n",
    "\n",
    "# Tensorboard Configuration\n",
    "\n",
    "#log_dir = \"/content/drive/MyDrive/Colab Notebooks/logs/sm_adam_4_0.001_relu_sigmoid_batch32/\"\n",
    "\n",
    "tb_callback_sm_adam = tf.keras.callbacks.TensorBoard(log_dir=\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/logs/sm_adam_relu_retrain_1/\", \n",
    "                                                  histogram_freq=1)\n",
    "\n",
    "\n",
    "print(\"Model Training Started.....\")\n",
    "\n",
    "history = sm_model_adam.fit(sm_train_X, sm_train_y,\n",
    "                            validation_data=(sm_validation_X, sm_validation_y),\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size, \n",
    "                            callbacks=[tb_callback_sm_adam])\n",
    "\n",
    "print(\"Model Training Completed.....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IvWkYf285_y"
   },
   "source": [
    "# **6. Source Model - Validation Predictions - Classification - \"score_status\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xr0drYIy85_z",
    "outputId": "6deddd0c-08b2-4e91-b438-bc4955b76ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Target \"Credit Default\" on the Validation Data\n",
    "\n",
    "sm_y_pred = sm_model_adam.predict(sm_validation_X, batch_size=1)\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvHj0wlL85_z",
    "outputId": "dcf0bd93-41af-4114-f147-87a0c9ea0c0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Output Actuals on the Source Model Validation Data:  83885\n",
      "Total Output Predictions on the Source Model Validation Data:  83885\n"
     ]
    }
   ],
   "source": [
    "# Verifying the Count of Prediction Outcomes on the Validation Data\n",
    "\n",
    "print(\"Total Output Actuals on the Source Model Validation Data: \", sm_validation_y.shape[0])\n",
    "print(\"Total Output Predictions on the Source Model Validation Data: \", len(sm_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOGPBHcJ85_0",
    "outputId": "4402f8fd-63e9-4c15-9d0c-d1d7d65f77c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Model Validation Actuals\n",
      "   score_status\n",
      "0             1\n",
      "1             1\n",
      "2             0\n",
      "3             1\n",
      "4             1\n",
      "5             0\n",
      "6             0\n",
      "7             1\n",
      "8             1\n",
      "9             0\n",
      "Source Model Validation Predictions\n",
      "[[0.58479035]\n",
      " [0.76699924]\n",
      " [0.33402687]\n",
      " [0.794162  ]\n",
      " [0.64306295]\n",
      " [0.49100298]\n",
      " [0.5014749 ]\n",
      " [0.28952545]\n",
      " [0.36903524]\n",
      " [0.20245379]]\n"
     ]
    }
   ],
   "source": [
    "# Comparing the Actual and Prediction Results for the first 10 Validation Data Instances\n",
    "\n",
    "print(\"Source Model Validation Actuals\")\n",
    "print(sm_validation_y[:10])\n",
    "\n",
    "print(\"Source Model Validation Predictions\")\n",
    "print(sm_y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBHYYdcg88qQ"
   },
   "source": [
    "# **7. Source Model - Visualising the Performance Metrics (Loss)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MbH6qOgB88qS",
    "outputId": "054f07c9-0f08-4a04-9170-94dab4af45d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.558884</td>\n",
       "      <td>0.699834</td>\n",
       "      <td>0.715740</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.558833</td>\n",
       "      <td>0.700130</td>\n",
       "      <td>0.727534</td>\n",
       "      <td>0.617607</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.558591</td>\n",
       "      <td>0.700341</td>\n",
       "      <td>0.721249</td>\n",
       "      <td>0.625225</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.558692</td>\n",
       "      <td>0.700062</td>\n",
       "      <td>0.724541</td>\n",
       "      <td>0.620850</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.558567</td>\n",
       "      <td>0.700293</td>\n",
       "      <td>0.723039</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss  accuracy  val_loss  val_accuracy  epoch\n",
       "9995  0.558884  0.699834  0.715740      0.626012   9995\n",
       "9996  0.558833  0.700130  0.727534      0.617607   9996\n",
       "9997  0.558591  0.700341  0.721249      0.625225   9997\n",
       "9998  0.558692  0.700062  0.724541      0.620850   9998\n",
       "9999  0.558567  0.700293  0.723039      0.622435   9999"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_sm = pd.DataFrame(history.history)\n",
    "hist_sm['epoch'] = history.epoch\n",
    "hist_sm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UykZNjy88qT",
    "outputId": "141be7b1-28f6-43d4-f5b5-20873956d624"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "RsxRSqR888qU",
    "outputId": "2d8c2a1e-c746-41d1-ba75-3c5998ca8bec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sm_plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='Loss')\n",
    "  plt.plot(history.history['val_loss'], label='Validation_Loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Loss]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "sm_plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63-FtZQGZ8R5"
   },
   "source": [
    "# **8. Source Model - Actuals versus Predictions Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "3EyMFVAvaH0y",
    "outputId": "377566af-d8da-4494-dca8-6eab11165b86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score_Status_Probability_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.584790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.766999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.334027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.643063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score_Status_Probability_Prediction\n",
       "0                             0.584790\n",
       "1                             0.766999\n",
       "2                             0.334027\n",
       "3                             0.794162\n",
       "4                             0.643063"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting probability predictions numpy array into a dataframe\n",
    "\n",
    "sm_y_pred_df = pd.DataFrame(sm_y_pred, columns=['Score_Status_Probability_Prediction'])\n",
    "sm_y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "LfUsbRI0fnpN",
    "outputId": "51fd0274-b050-4953-b250-ceb4e5d1fc0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in the New Column 'Score_Status_Probability_Prediction': 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score_Status_Probability_Prediction</th>\n",
       "      <th>Score_Status_Class_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27898</th>\n",
       "      <td>0.303097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>0.008083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57316</th>\n",
       "      <td>0.937550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14116</th>\n",
       "      <td>0.791640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38266</th>\n",
       "      <td>0.857461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307</th>\n",
       "      <td>0.667170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69959</th>\n",
       "      <td>0.874374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.335236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68471</th>\n",
       "      <td>0.923041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>0.244193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score_Status_Probability_Prediction  Score_Status_Class_Prediction\n",
       "27898                             0.303097                              0\n",
       "5350                              0.008083                              0\n",
       "57316                             0.937550                              1\n",
       "14116                             0.791640                              1\n",
       "38266                             0.857461                              1\n",
       "13307                             0.667170                              1\n",
       "69959                             0.874374                              1\n",
       "2192                              0.335236                              0\n",
       "68471                             0.923041                              1\n",
       "13494                             0.244193                              0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_y_pred_df['Score_Status_Class_Prediction'] = np.where( sm_y_pred_df['Score_Status_Probability_Prediction'] > 0.5, 1, 0)\n",
    "\n",
    "print(\"Missing Values in the New Column 'Score_Status_Probability_Prediction':\", sm_y_pred_df['Score_Status_Probability_Prediction'].isna().sum())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Displaying a sample of 10 random actuals and its respective predictions\n",
    "sm_y_pred_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cB8qeJjXiHHP",
    "outputId": "61730cf4-1484-4338-b67a-c533c3183799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83885, 1)\n",
      "(83885, 2)\n",
      "\n",
      "\n",
      "score_status    0\n",
      "dtype: int64\n",
      "Score_Status_Probability_Prediction    0\n",
      "Score_Status_Class_Prediction          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verifying the Size and the Missing Values (if any) Count of the Score Status Actual (Ground-Truth) Dataframe and the Predictions Dataframe\n",
    "\n",
    "print(sm_validation_y.shape)\n",
    "print(sm_y_pred_df.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(sm_validation_y.isna().sum())\n",
    "print(sm_y_pred_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "bdYHSrhZgbDS",
    "outputId": "fb843c21-cd2b-41e8-de25-7db788287a23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score_Status_Class_Actual</th>\n",
       "      <th>Score_Status_Probability_Prediction</th>\n",
       "      <th>Score_Status_Class_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.796518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>1</td>\n",
       "      <td>0.942906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43778</th>\n",
       "      <td>1</td>\n",
       "      <td>0.564429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71207</th>\n",
       "      <td>1</td>\n",
       "      <td>0.488566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24927</th>\n",
       "      <td>1</td>\n",
       "      <td>0.367843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18679</th>\n",
       "      <td>1</td>\n",
       "      <td>0.255964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67692</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49936</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>0.367913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40707</th>\n",
       "      <td>1</td>\n",
       "      <td>0.282098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score_Status_Class_Actual  Score_Status_Probability_Prediction  \\\n",
       "5149                           1                             0.796518   \n",
       "7169                           1                             0.942906   \n",
       "43778                          1                             0.564429   \n",
       "71207                          1                             0.488566   \n",
       "24927                          1                             0.367843   \n",
       "18679                          1                             0.255964   \n",
       "67692                          0                             0.017323   \n",
       "49936                          1                             0.027133   \n",
       "1950                           0                             0.367913   \n",
       "40707                          1                             0.282098   \n",
       "\n",
       "       Score_Status_Class_Prediction  \n",
       "5149                               1  \n",
       "7169                               1  \n",
       "43778                              1  \n",
       "71207                              0  \n",
       "24927                              0  \n",
       "18679                              0  \n",
       "67692                              0  \n",
       "49936                              0  \n",
       "1950                               0  \n",
       "40707                              0  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the Score Status Actual (Ground-Truth) Dataframe and the Predictions Dataframe\n",
    "\n",
    "frames = [sm_validation_y, sm_y_pred_df]\n",
    "\n",
    "sm_results = pd.concat(frames, axis=1)\n",
    "\n",
    "# Renaming the \"score_status\" Column Name\n",
    "sm_results.rename(columns = {'score_status':'Score_Status_Class_Actual'}, inplace = True)\n",
    "\n",
    "# Displaying a sample of 10 random results\n",
    "sm_results.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fU5UP5AecBv"
   },
   "source": [
    "# **9. Exporting a Copy of the Score Status Output Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYVIX4XmecB7",
    "outputId": "d54aa640-2b99-44ad-c336-006f7db61eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Export Completed\n"
     ]
    }
   ],
   "source": [
    "# Exporting a copy of Score Status Actuals and Predictions DataFrame as a csv file\n",
    "\n",
    "sm_results.to_csv(\"/content/drive/MyDrive/QMUL_MSc_Project/credit_risk_scoring_project/output/sm_adam_relu_retrain_1_10000_predictions.csv\")\n",
    "\n",
    "print(\"Data Export Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bV9TddFDZGfU"
   },
   "source": [
    "# **10. Source Model - Metrics Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUk8g7QmZLar",
    "outputId": "c27fdb0a-a711-427f-d5f1-0dded19a2fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.57      0.50     27409\n",
      "           1       0.76      0.65      0.70     56476\n",
      "\n",
      "    accuracy                           0.62     83885\n",
      "   macro avg       0.60      0.61      0.60     83885\n",
      "weighted avg       0.65      0.62      0.63     83885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Source Model - Classificatio Report \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "sm_classification_report = classification_report(sm_results['Score_Status_Class_Actual'], sm_results['Score_Status_Class_Prediction'])\n",
    "\n",
    "print(sm_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "WXsYh7wIZvST",
    "outputId": "3f8bc5d3-37fa-4345-b6c3-77fef0cf27ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(51.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFzCAYAAAB/3gPNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxd87n48c+TQ0gEMTeNIIghUhLzXDeKxFBDVXEvuaYYorS37Q360xpb/VFa96INCaElMbQVSlFc5WoiKQkSVCRI0pgyiiFxcr73j70SO3rOyYljr5Vkfd5e62WfZw37u8grz3m+32evHSklJElSftoUPQBJksrG5CtJUs5MvpIk5czkK0lSzky+kiTlzOQrSVLOVil6AE3Zt/P+fgZKK7yn33256CFIX4j6BdOiVtf+5L1Jrfr7ftX1N6/Z2GpluU2+kqSSaFhY9Ahy57SzJEk5s/KVJBUrNRQ9gtyZfCVJxWow+UqSlKtUwsrXNV9JknJm5StJKpbTzpIk5ayE084mX0lSsUr4OV+TrySpWCWsfG24kiQpZ1a+kqRi2XAlSVK+yvg5X5OvJKlYVr6SJOWshJWvDVeSpJVaRKweEc9ExLiIGB8RF2fxWyJickSMzbaeWTwi4tqImBgRz0fEjlXX6hcRr2Zbv6r4ThHxQnbOtRHR7HcMW/lKkopV+8/5zgd6p5TmRcSqwFMR8WC27wcppbs/c3xfoFu27QbcAOwWEesCPwZ2BhLwt4gYkVKalR1zGjAKeADoAzxIE6x8JUnFSg2t25Z2+Yp52Y+rZltq5pTDgVuz80YCHSOiE3AQ8EhKaWaWcB8B+mT71kopjUwpJeBW4IjmxmTylSQVq6GhdVsLRERdRIwF3qGSQEdluy7PppaviYjVslhnYErV6VOzWHPxqY3Em2TylSSt0CKif0SMqdr6f/aYlNLClFJPYGNg14joAZwPbAPsAqwLDMxrzCZfSVKxWjntnFIalFLauWob1ORbpTQbeBzok1Kank0tzwduBnbNDpsGdKk6beMs1lx840biTTL5SpKKVeNp54jYICI6Zq/bAQcAL2drtWSdyUcAL2anjABOzLqedwfmpJSmAw8BB0bEOhGxDnAg8FC2b25E7J5d60Tg3ubGZLezJKlQKdW827kTMDQi6qgUnXemlO6PiMciYgMggLHAGdnxDwAHAxOBD4GTKuNMMyPiUmB0dtwlKaWZ2euzgFuAdlS6nJvsdAaTrySpaDV+yEZK6XmgVyPx3k0cn4ABTewbAgxpJD4G6NHSMTntLElSzqx8JUnF8tnOkiTlrITPdjb5SpKKVfvHSy53TL6SpGKVsPK14UqSpJxZ+UqSimXDlSRJOSvhtLPJV5JUrBJWvq75SpKUMytfSVKxSlj5mnwlSYXK4YsVljsmX0lSsax8JUnKWQm7nW24kiQpZ1a+kqRiOe0sSVLOSjjtbPKVJBXLyleSpJyVsPK14UqSpJxZ+UqSiuW0syRJOTP5SpKUM9d8JUlSrVn5SpKK5bSzJEk5K+G0s8lXklQsK19JknJWwsrXhitJknJm5StJKpbTzpIk5czkK0lSzlIqegS5M/lKkopVwsrXhitJknJm5StJKlYJK1+TrySpWCX8nK/JV5JUrBJWvq75SpKUMytfSVKx/KiRJEk5K+G0s8lXklQsk68kSTkrYbezDVeSJOXMyleSVKjUYMOVJEn5cs1XkqSclXDN1+QrSSpWCaedbbiSJClnVr6SpGK55itJUs5MvpIk5ayEz3Z2zVeSpJyZfFcCA3/+fe4ddze3PHrT4thJ/3Ei94wZzuCHf83gh3/N7r13Xbxv82035/oR/8XQxwZzy59vpO1qqwLQ++v7cfMjNzL0scGcccFpi48/pv/R3Pr4EG5+5EauGX4lG3XeML+bU2ncOOjn/GPqOMY+9+ji2De+cSjjxj7Ggo+nsNOO2y+OH3fckYwZ/fDibcHHU9hhh+0AuPSSgUx+bTSzZ/59iev//MqLFh8/YfyTvPfOhHxuTEvX0NC6bQUUaTkt9/ftvP/yObDl0A67fYWPPviYC345kH/f/1Sgknw/+uAjhv36riWOratrw01/+jWXnftTXpswibXWWYt5c+bRYe0ODH7oV5za50zmzJzDBb8YyJ/ufphnn3qOXnv2ZMKzLzH/4/kcfuJh9NpjBy4687IibnWF8/S7Lxc9hBXGPnvvxrx5H3Dzzb+kZ6/9Adhmmy1paEjccN0V/OfAS/nbs8//03k9emzDPXcNZutt9wJgt1135I03p/LyhKfouO5Wjb7XgLNOomfPHpzW/3u1u6GVTP2CaVGra3941amt+vu+/fdvqtnYasXKdyUwbtQLzJ09t0XH7vLVnXntpUm8NmESAHNnzaWhoYEvb9KJqZOnMWfmHADGPPk3vnrwPgA89/RY5n88H4AJf3uJDTptUIO7UNk9+dQoZs6avUTs5Zcn8ve/v9bsecd+6wjuvGvE4p9HPfMsb731zlLPGT78D59/sPpipYbWbSugmjVcRcQ2wOFA5yw0DRiRUnqpVu+pJR150hEcdPSBvPz8K1x3ya+YN2ceXTbfmETiqt9eQcf1OvLovY9zxw3Dmfr6NLps0YUvbbwR705/l30O2otV2q76T9c85Li+jHr8mQLuRmrcN48+jKOOPrnFx2+ySWc226wLjz3+vzUclZaJD9n4YkTEQGAYEMAz2RbAHRFxXjPn9Y+IMRExZvoH02oxtNL4w633cdyeJ3Dygf2Z8c5MBvzoDADq6urYfpceXHr2TxhwxLns03dvdty7F/PmzOPq83/JRTdcyH/9/pe8NfVtGhYu+RvlAUd9ja132Io7briziFuS/smuu/Tiw48+Yvz4V1p8zreOOZx7fvdHGlbQtUKtHGo17XwKsEtK6YqU0m+y7Qpg12xfo1JKg1JKO6eUdu60RuemDlMLzHpvFg0NDaSUuP+3f2TbntsA8M709xg36gXmzJrL/I/nM/KxUWzVoxsATz/yV8447GzO+vq3efO1KUyZNHXx9XbaZ0dOPOd4zv/3C/lkwSeF3JP0Wd865nCGD793mc455nOco9pKDQ2t2pYmIlaPiGciYlxEjI+Ii7N414gYFRETI2J4RLTN4qtlP0/M9m9Wda3zs/grEXFQVbxPFpvYXJG5SK2SbwPw5UbinbJ9qrH1Nlx38et9+u7N5FdeB+CZJ0az+TZdWW311aira0PP3bfn9VffAKDjeh0B6LB2B47o93Xuv+MBALpttyXfv+K7nH/ShcyeseSanFSUiODoow9l+J0tT6Rbb70F63Rcm7+OHFPDkWmZNaTWbUs3H+idUtoB6An0iYjdgZ8B16SUtgRm8WlxeAowK4tfkx1HRHQHjgW2A/oA10dEXUTUAdcBfYHuwHHZsU2q1Zrvd4BHI+JVYEoW2wTYEji7Ru9ZWj+67of02mMH1l53be4eM4ybrxpKzz13oFv3LUgJ3pr6FlcNvAaAeXPmMXzQ3Qx64HpSSox87BlGPjoKgHMuGcCW3bcA4JZrbmNqVvmeeWF/2q3Rjot//SMA3pn2DuefdGEBd6qV2W9uu46v7rsH66+/Lq9PGsPFl1zFzFmz+eU1l7HBBusy4t5bGTduPAcf+q8A7LvP7kydOp3Jk99c4jpX/PSHHPutI2nfvh2vTxrDkJtv55JLrwYqlfKdd1n1Lndq3DSVKh/rmZf9uGq2JaA3cHwWHwpcBNxApV/poix+N/DfERFZfFhKaT4wOSImUpnRBZiYUpoEEBHDsmOb/DxbzT5qFBFtskFVN1yNTiktbMn5ftRIKwM/aqSVRS0/avTBZf/Wqr/vO1z429OB/lWhQSmlQdXHZNXp36gUgdcBVwIjs+qWiOgCPJhS6hERLwJ9UkpTs32vAbtRScgjU0q/yeKDgQezt+iTUjo1i58A7JZSarLYrFm3c0qpARhZq+tLklYSrex2zhLtoKUcsxDoGREdgd8D27TqTVvJZztLkoqVY+d5Sml2RDwO7AF0jIhVUkr1wMZUZmjJ/t0FmBoRqwBrAzOq4otUn9NUvFE+ZEOSVKwaN1xFxAZZxUtEtAMOAF4CHgeOzg7rByxqCBiR/Uy2/7Fs3XgEcGzWDd0V6Eblo7SjgW5Z93RbKk1Znz75pRFWvpKkYtX+KVWdgKHZum8b4M6U0v0RMQEYFhGXAc8Bg7PjBwO3ZQ1VM6kkU1JK4yPiTiqNVPXAgEV9TBFxNvAQUAcMSSmNb25AJl9J0kotpfQ80KuR+CQ+7Vaujn8MfLOJa10OXN5I/AHggZaOyeQrSSpWCR8vafKVJBWqJU+pWtmYfCVJxbLylSQpZyVMvn7USJKknFn5SpKKVfuPGi13TL6SpGKVcNrZ5CtJKlQqYfJ1zVeSpJxZ+UqSilXCytfkK0kqlg/ZkCQpZ1a+kiTlrITJ14YrSZJyZuUrSSpU5Xvqy8XkK0kqVgmnnU2+kqRimXwlScqXT7iSJEk1Z+UrSSpWCStfk68kqVjle8CVyVeSVCzXfCVJUs1Z+UqSilXCytfkK0kqlmu+kiTlq4xrviZfSVKxSlj52nAlSVLOrHwlSYVy2lmSpLyVcNrZ5CtJKlQy+UqSlLMSJl8briRJypmVrySpUE47S5KUN5OvJEn5KmPl65qvJEk5s/KVJBWqjJWvyVeSVCiTryRJeUtR9AhyZ/KVJBWqjJWvDVeSJOXMyleSVKjU4LSzJEm5KuO0s8lXklSoZMOVJEn5KmPla8OVJEk5s/KVJBXKhitJknKWUtEjyJ/JV5JUqDJWvq75SpKUMytfSVKhylj5mnwlSYVyzVeSpJxZ+UqSlLMyPuHKhitJknJm5StJKpSPl5QkKWcNKVq1LU1EdImIxyNiQkSMj4hzs/hFETEtIsZm28FV55wfERMj4pWIOKgq3ieLTYyI86riXSNiVBYfHhFtmxuTyVeSVKiUolVbC9QD30spdQd2BwZERPds3zUppZ7Z9gBAtu9YYDugD3B9RNRFRB1wHdAX6A4cV3Wdn2XX2hKYBZzS3IBMvpKkQqWGaNW21OunND2l9Gz2+n3gJaBzM6ccDgxLKc1PKU0GJgK7ZtvElNKklNICYBhweEQE0Bu4Ozt/KHBEc2My+UqSVmgR0T8ixlRt/Zs5djOgFzAqC50dEc9HxJCIWCeLdQamVJ02NYs1FV8PmJ1Sqv9MvEktariKiD2BzaqPTynd2pJzJUlqTmsfspFSGgQMWtpxEdEBuAf4TkppbkTcAFwKpOzfPwdObt1oWmapyTcibgO2AMYCC7NwAky+kqRWy+MhGxGxKpXE+9uU0u8AUkpvV+2/Ebg/+3Ea0KXq9I2zGE3EZwAdI2KVrPqtPr5RLal8dwa6p1TGB4BJkmqtJR3LrZGtyQ4GXkopXV0V75RSmp79eCTwYvZ6BHB7RFwNfBnoBjwDBNAtIrpSSa7HAsenlFJEPA4cTWUduB9wb3NjaknyfRH4EjB9aQdKkrQc2gs4AXghIsZmsQuodCv3pDKb+zpwOkBKaXxE3AlMoNIpPSCltBAgIs4GHgLqgCEppfHZ9QYCwyLiMuA5Ksm+SdFUQRsR92UDWhPoSSXrz1+0P6X09WW582W1b+f9rbS1wnv63ZeLHoL0hahfMK1m5ekLXQ9r1d/3X5l83wr3fMrmKt+rchuFJKm0yrio2WTyTSk9ARARP0spDazeFxE/A56o8dgkSSVQ6zXf5VFLPud7QCOxvl/0QCRJ5ZTDE66WO01WvhFxJnAWsEVEPF+1a03g6VoPTJKklVVza763Aw8CPwXOq4q/n1KaWdNRSZJKwzXfKimlOcCciBj4mV0dIqJDSunNWg7soFW+VMvLS7l49B83Fj0EablXxjXflnzO949UPnIUwOpAV+AVKt/2IElSq6yo67atsdTkm1L6SvXPEbEjlbVgSZJarYyV7zJ/q1H2tUy71WAskiSVQku+WOE/qn5sA+wI/KNmI5IklUoJ+61atOa7ZtXreiprwPfUZjiSpLIp47Rzs8k3IuqANVNK389pPJKkkiljw1WTa77Z9xIupPJtEJIk6QvSXOX7DJX13bERMQK4C/hg0c5FX0YsSVJrNBQ9gAK0ZM13dWAG0JtPP++bAJOvJKnVEuWbdm4u+W6YdTq/yKdJd5EyNqdJkmqgoYQZpbnkWwd0gEZ/JSnhfypJUi00WPkuYXpK6ZLcRiJJUkk0l3zL96uIJCl3rvkuaf/cRiFJKi27nav4nb2SpDyUsfJd5i9WkCRJrdOSz/lKklQzTjtLkpQzk68kSTkr45qvyVeSVKiG8uVeG64kScqbla8kqVA+XlKSpJyV8csCTL6SpELZ7SxJUs4aonzTzjZcSZKUMytfSVKhXPOVJClnrvlKkpQzH7IhSZJqzspXklQoH7IhSVLObLiSJClnZVzzNflKkgpVxm5nG64kScqZla8kqVCu+UqSlDPXfCVJylkZ13xNvpKkQpUx+dpwJUlSzqx8JUmFSq75SpKUrzJOO5t8JUmFKmPydc1XkqScWflKkgrlQzYkScqZD9mQJClnZVzzNflKkgpVxuRrw5UkSTmz8pUkFaqMDVdWvpKkQjVE67aliYguEfF4REyIiPERcW4WXzciHomIV7N/r5PFIyKujYiJEfF8ROxYda1+2fGvRkS/qvhOEfFCds61EdHsyEy+kqRCNbRya4F64Hsppe7A7sCAiOgOnAc8mlLqBjya/QzQF+iWbf2BG6CSrIEfA7sBuwI/XpSws2NOqzqvT3MDMvlKkgqVWrkt9fopTU8pPZu9fh94CegMHA4MzQ4bChyRvT4cuDVVjAQ6RkQn4CDgkZTSzJTSLOARoE+2b62U0siUUgJurbpWo0y+kqTSiIjNgF7AKGCjlNL0bNdbwEbZ687AlKrTpmax5uJTG4k3yeQrSSpUA6lVW0T0j4gxVVv/xt4nIjoA9wDfSSnNrd6XVay59X7Z7SxJKlRrP+ebUhoEDGrumIhYlUri/W1K6XdZ+O2I6JRSmp5NHb+TxacBXapO3ziLTQP2+0z8f7L4xo0c3yQrX0lSoWq95pt1Hg8GXkopXV21awSwqGO5H3BvVfzErOt5d2BONj39EHBgRKyTNVodCDyU7ZsbEbtn73Vi1bUaZeUrSVrZ7QWcALwQEWOz2AXAFcCdEXEK8AZwTLbvAeBgYCLwIXASQEppZkRcCozOjrskpTQze30WcAvQDngw25pk8pUkFarWj5dMKT0FNPW52/0bOT4BA5q41hBgSCPxMUCPlo7J5CtJKpTfaiRJUs4aSviASZOvJKlQ5Uu9djtLkpQ7K19JUqHK+H2+Jl9JUqFc85UkKWflS70mX0lSwco47WzDlSRJObPylSQVyjVfSZJyVr7Ua/KVJBXMNV9JklRzVr6SpEKlEk48m3wlSYUq47SzyVeSVCi7nSVJyln5Uq8NV5Ik5c7KdyVw6JWnsWXvXnwwYy43HngeABtuuwl9f3Iybduvzpyp7/KHc69nwbyPaLNqHQf/5BQ6bb85qaGBhy++jTdHvgTAvw37IR027Ej9x58AcPsJV/DhjLlsf/S+9L7gOOa9NQuAMbc+zNhh/1PIvWrlNX/+AvoN+AELPvmEhfULOeBf9ubsU08gpcS1g4by8ONP0aZNG7515CH82zcP55lnn+ec8y6mc6cvAfC1r+7JmSf/K9PffpcLLr2KGbNmEQRHH96XE445AoCHHnuS6wf/hklvTOGOG39Bj223KvKWlXHaWSukcXc9yZihj3DY1Wcsjh3ys1N59PLbeXPUy+xwzFfZ4/RDeOLnd9PruN4A3HjQebRfby2OHfqfDDnsQkiVP/z3nns901+Y/E/v8dL9I3noR0PzuSGVUtu2qzLk2ito374dn9TXc+KZ32ef3Xdm0htTeOud97jv9kG0adOGGbNmLz5nxx16cP2VFy9xnVXq6vjBt0+j+9Zb8sEHH3LMKeew5y692KLrpmy5+ab84icXcvGV1+Z9e2pGGRuunHZeCUx55mU+mj1vidi6XTvx5qiXAZj05Ats3XdXANbv1pnXn54AwIcz5vLx3A/48vZd8x2w1IiIoH37dgDU19dTX19PRDD893/kzJOOp02byl9X663TsdnrbLD+unTfeksA1lijPZtv2oW3350BwBabbULXTTeu4V3o80it/GdFZPJdSb336lS2OnAnALY9ZDfW6rQuAO9MeIOtDtiRqGvD2l02oFOPrqz55fUWn3foVadz6gM/Ye9zjljietv03YVT//RTjrrhXNbMriV90RYuXMg3+g1g30OPY49derH9dtswZdp0Hnz0CY45+RzO+N6FvDFl2uLjx734Ekf1O4szvnchEye98U/Xmzb9bV569TW2327rPG9Dy6ihlduKKPfkGxEnNbOvf0SMiYgxo+dNzHNYK537fzCInU44gJPvv4zV1mjHwk/qARh75xPMnT6TU+67jAN/dAJTn32VtLDyx/fec6/nxoPO49ZvXkKXXbbhK0ftDcCrf36W/97rO9zU53wmP/kCX6+a3pa+SHV1ddwz9Doe/f1tvDDh77w66XUWfPIJq7Vty51DruUbh/Xhwp9cA0D3rbfgkXuG8ruh13P8Nw7jnPMvWeJaH374Ed/94WUMPOd0OqyxRhG3IzWpiMr34qZ2pJQGpZR2TintvEuHLfMc00pnxmvTueOEKxhy6P9j/Iinmf3GOwCkhQ38+dLfcNPBF3DXaVez+lrtmTn5LQDef7vSULXgg48Zf+/TfLnnFgB8NHseCxdkyXvY43yph9PUqq211uzArjtuz1Mjx/ClDdbna1/dC6g0Vf39tUpPQoc11lg8Tb3vnrtSX1/PrNlzAPikvp7v/PAyDjnwXzhgv72KuQm1mNPOX5CIeL6J7QVgo1q8p5bUfr21Ki8i2OvbR/Dsbx8FYJXV27Jqu9UA6Lp3DxrqG3jv1WlEXRvardMBgDar1LHl/r1495WpAHTY8NM1tq0O2IkZE/+R452oLGbOms3c9yu9Cx/Pn89fRz9H10270HvfPXjm2XEAjH7uBTbt0hmA92bMJGWNgi9MeIWGlOi49lqklPjRT3/B5pt2od+xRxVzM1omZZx2rlW380bAQcCsz8QDeLpG71laR1w7gE332JZ266zJt0f+F3+55m7atl+dnU48AIBX/jSacXc+AcAa66/FcbcOJKXE+2/N4t7v3gDAKm1X5bjbzqPNKnW0qWvD5Kde5Lk7HgNg538/iK0O2JGG+oV8NOcD7vv+r4q5Ua3U3p0xix9edhULGxpIDYmDeu/Dfnvtxo7bb8fAi/8/tw3/A+3brc7F530HgIcff4rhv/8jdavUsXrbtlx58XlEBM+Oe5H7/vQo3bbYjG/0GwDAuaf3Y989d+XPT/wvP73mBmbOnsNZP/gx23TbnEHXXF7kbQtoSCtm9doakWpw0xExGLg5pfRUI/tuTykdv7RrXL7pv5bv/4ZWOv/5t0uLHoL0hVh1/c2jVtc+YdOjWvX3/W1v/K5mY6uVmlS+KaVTmtm31MQrSSqPMlZaPmRDklQon3AlSVLOVtSO5dYw+UqSCrWidiy3hk+4kiQpZ1a+kqRCueYrSVLOXPOVJClnZVzzNflKkgpVi4c9Le9suJIkKWdWvpKkQtlwJUlSzlzzlSQpZ2XsdnbNV5KknFn5SpIK5ZqvJEk5K+NHjUy+kqRC2XAlSVLObLiSJEk1Z+UrSSqUDVeSJOXMhitJknJWxsrXNV9JknJm5StJKlQZu51NvpKkQjW45itJUr7Kl3pNvpKkgtlwJUmSas7KV5JUqDJWviZfSVKhyviQDaedJUmFaiC1aluaiBgSEe9ExItVsYsiYlpEjM22g6v2nR8REyPilYg4qCreJ4tNjIjzquJdI2JUFh8eEW2XNiaTrySpUKmV/7TALUCfRuLXpJR6ZtsDABHRHTgW2C475/qIqIuIOuA6oC/QHTguOxbgZ9m1tgRmAacsbUAmX0nSSi2l9BdgZgsPPxwYllKan1KaDEwEds22iSmlSSmlBcAw4PCICKA3cHd2/lDgiKW9iclXklSolFKrtlY4OyKez6al18linYEpVcdMzWJNxdcDZqeU6j8Tb5bJV5JUqNau+UZE/4gYU7X1b8Hb3gBsAfQEpgM/r+lNfobdzpKkQrW22zmlNAgYtIznvL3odUTcCNyf/TgN6FJ16MZZjCbiM4COEbFKVv1WH98kK19JUulERKeqH48EFnVCjwCOjYjVIqIr0A14BhgNdMs6m9tSacoakSq/OTwOHJ2d3w+4d2nvb+UrSSpUrR+yERF3APsB60fEVODHwH4R0ZPKo6VfB04HSCmNj4g7gQlAPTAgpbQwu87ZwENAHTAkpTQ+e4uBwLCIuAx4Dhi8tDGZfCVJhar1VwqmlI5rJNxkgkwpXQ5c3kj8AeCBRuKTqHRDt5jJV5JUKL9SUJKknNW68l0e2XAlSVLOrHwlSYVy2lmSpJyVcdrZ5CtJKpSVryRJOStj5WvDlSRJObPylSQVymlnSZJyVsZpZ5OvJKlQKTUUPYTcueYrSVLOrHwlSYWq9bcaLY9MvpKkQiUbriRJypeVryRJOStj5WvDlSRJObPylSQVyodsSJKUMx+yIUlSzsq45mvylSQVqozdzjZcSZKUMytfSVKhnHaWJClndjtLkpSzMla+rvlKkpQzK19JUqHK2O1s8pUkFaqM084mX0lSoWy4kiQpZ2V8vKQNV5Ik5czKV5JUKKedJUnKmQ1XkiTlrIxrviZfSVKhylj52nAlSVLOrHwlSYUqY+Vr8pUkFap8qReijL9xqCIi+qeUBhU9Dqm1/LOsFY1rvuXWv+gBSF8Q/yxrhWLylSQpZyZfSZJyZvItN9fItLLwz7JWKDZcSZKUMytfSZJyZvItqYjoExGvRMTEiDiv6PFIn0dEDImIdyLixaLHIi0Lk28JRUQdcB3QF+gOHBcR3YsdlfS53AL0KXoQ0rIy+ZbTrsDElNKklNICYBhweMFjkpZZSukvwMyixyEtK5NvOXUGplT9PDWLSZJyYPKVJClnJt9ymgZ0qfp54ywmScqBybecRgPdIqJrRLQFjgVGFDwmSSoNk28JpZTqgbOBh4CXgDtTSuOLHUkttRYAAAKeSURBVJW07CLiDuCvwNYRMTUiTil6TFJL+IQrSZJyZuUrSVLOTL6SJOXM5CtJUs5MvpIk5czkK0lSzky+EhARCyNibES8GBF3RUT7Vlzrlog4Ont9U3NfWhER+0XEnp/jPV6PiPU/7xglFcvkK1V8lFLqmVLqASwAzqjeGRGrfJ6LppROTSlNaOaQ/YBlTr6SVmwmX+mfPQlsmVWlT0bECGBCRNRFxJURMToino+I0wGi4r+z70f+M7DhogtFxP9ExM7Z6z4R8WxEjIuIRyNiMypJ/rtZ1b1PRGwQEfdk7zE6IvbKzl0vIh6OiPERcRMQ+f4nkfRF+ly/zUsrq6zC7Qv8KQvtCPRIKU2OiP7AnJTSLhGxGvC/EfEw0AvYmsp3I28ETACGfOa6GwA3Avtm11o3pTQzIn4FzEspXZUddztwTUrpqYjYhMpTyLYFfgw8lVK6JCIOAXySk7QCM/lKFe0iYmz2+klgMJXp4GdSSpOz+IHA9ovWc4G1gW7AvsAdKaWFwD8i4rFGrr878JdF10opNfUdtF8DukcsLmzXiogO2XsclZ37x4iY9TnvU9JywOQrVXyUUupZHcgS4AfVIeDbKaWHPnPcwV/gONoAu6eUPm5kLJJWEq75Si33EHBmRKwKEBFbRcQawF+Ab2Vrwp2Af2nk3JHAvhHRNTt33Sz+PrBm1XEPA99e9ENELPqF4C/A8VmsL7DOF3ZXknJn8pVa7iYq67nPRsSLwK+pzB79Hng123crlW/ZWUJK6V2gP/C7iBgHDM923QccuajhCjgH2Dlr6JrAp13XF1NJ3uOpTD+/WaN7lJQDv9VIkqScWflKkpQzk68kSTkz+UqSlDOTryRJOTP5SpKUM5OvJEk5M/lKkpQzk68kSTn7Pw4keWgr6S3tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source Model - Confusion Matrix\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "sm_cm = tf.math.confusion_matrix(labels=sm_results['Score_Status_Class_Actual'], predictions=sm_results['Score_Status_Class_Prediction'])\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "sn.heatmap(sm_cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aMIWnj3ikvS",
    "outputId": "f88f427f-926d-4d25-eb61-86ee19653636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Model ROC AUC:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Source Model - ROC, AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sm_auc = roc_auc_score(sm_results['Score_Status_Class_Prediction'], sm_results['Score_Status_Class_Prediction'])\n",
    "\n",
    "print(\"Source Model ROC AUC: \", sm_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg8hRySuZu1y"
   },
   "source": [
    "# **11. Saving the Finalised Source Model - Classification of \"score_status\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IHleWCAZxEZ",
    "outputId": "845aee11-0bac-46fd-ed57-ce7ca0e277d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "# Saving the Target Model 2 - Classification of \"Credit_Default\"\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "sm_model_adam.save('sm_adam_relu_retrain_1_10000_final.h5')\n",
    "\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cdPT4n7qFz2",
    "outputId": "90c3aa7b-dea8-48ea-ffdb-d94a7eaf477c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x7f884148c6d0>>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Model 2 Summarisation\n",
    "\n",
    "sm_model_adam.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkasX2tPhg59"
   },
   "source": [
    "# **12. Saving the Finalised Source Model Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_i8qDWLhtzW",
    "outputId": "4f705156-e58d-4cda-fff4-d5abb7ce2239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "# Saving the Model Weights\n",
    "\n",
    "sm_model_adam.save_weights(\"sm_adam_relu_retrain_1_10000_final_weights\")\n",
    "\n",
    "print(\"Model Weights Saved Successfully\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2qQ8EMyrR5sJ",
    "TR8cYEN_IWzm",
    "ML7ZvboLNbjk",
    "p8MGnNxRPQGC",
    "5ATESNKFTPnQ"
   ],
   "machine_shape": "hm",
   "name": "SM_Deep_Learning_Model_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
